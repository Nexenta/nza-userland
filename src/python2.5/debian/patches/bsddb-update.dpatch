#! /bin/sh -e

# All lines beginning with `# DPATCH:' are a description of the patch.
# DP: Copy the bsddb module from python2.6

dir=
if [ $# -eq 3 -a "$2" = '-d' ]; then
    pdir="-d $3"
    dir="$3/"
elif [ $# -ne 1 ]; then
    echo >&2 "usage: `basename $0`: -patch|-unpatch [-d <srcdir>]"
    exit 1
fi
case "$1" in
    -patch)
        patch $pdir -f --no-backup-if-mismatch -p1 < $0
        ;;
    -unpatch)
        patch $pdir -f --no-backup-if-mismatch -R -p1 < $0
        ;;
    *)
	echo >&2 "usage: `basename $0`: -patch|-unpatch [-d <srcdir>]"
        exit 1
esac
exit 0

# append the patch here and adjust the -p? flag in the patch calls.
From f1c25496178294b20e19108f32aa422db8af4b6f Mon Sep 17 00:00:00 2001
From: Julien Cristau <jcristau@debian.org>
Date: Fri, 24 Sep 2010 16:49:17 +0200
Subject: [PATCH 1/9] Copy the bsddb module from python2.6

---
 Lib/bsddb/__init__.py                           |  195 +-
 Lib/bsddb/db.py                                 |   31 +-
 Lib/bsddb/dbobj.py                              |  224 +-
 Lib/bsddb/dbshelve.py                           |   98 +-
 Lib/bsddb/dbtables.py                           |  298 ++-
 Lib/bsddb/dbutils.py                            |   12 +-
 Lib/bsddb/test/test_all.py                      |  466 +++-
 Lib/bsddb/test/test_associate.py                |  121 +-
 Lib/bsddb/test/test_basics.py                   |  364 ++-
 Lib/bsddb/test/test_compare.py                  |   70 +-
 Lib/bsddb/test/test_compat.py                   |   25 +-
 Lib/bsddb/test/test_cursor_pget_bug.py          |   21 +-
 Lib/bsddb/test/test_dbobj.py                    |   40 +-
 Lib/bsddb/test/test_dbshelve.py                 |  142 +-
 Lib/bsddb/test/test_dbtables.py                 |  159 +-
 Lib/bsddb/test/test_distributed_transactions.py |  163 +
 Lib/bsddb/test/test_early_close.py              |  195 ++
 Lib/bsddb/test/test_get_none.py                 |   35 +-
 Lib/bsddb/test/test_join.py                     |   39 +-
 Lib/bsddb/test/test_lock.py                     |  148 +-
 Lib/bsddb/test/test_misc.py                     |   81 +-
 Lib/bsddb/test/test_pickle.py                   |   23 +-
 Lib/bsddb/test/test_queue.py                    |   33 +-
 Lib/bsddb/test/test_recno.py                    |   85 +-
 Lib/bsddb/test/test_replication.py              |  475 +++
 Lib/bsddb/test/test_sequence.py                 |   72 +-
 Lib/bsddb/test/test_thread.py                   |  452 ++--
 Modules/_bsddb.c                                | 3642 ++++++++++++++++-------
 Modules/bsddb.h                                 |  273 ++
 Modules/bsddbmodule.c                           | 1292 ++++----
 30 files changed, 6344 insertions(+), 2930 deletions(-)
 create mode 100644 Lib/bsddb/test/test_distributed_transactions.py
 create mode 100644 Lib/bsddb/test/test_early_close.py
 create mode 100644 Lib/bsddb/test/test_replication.py
 create mode 100644 Modules/bsddb.h

diff --git a/Lib/bsddb/__init__.py b/Lib/bsddb/__init__.py
index 7eb625c..07c7c9d 100644
--- a/Lib/bsddb/__init__.py
+++ b/Lib/bsddb/__init__.py
@@ -33,18 +33,31 @@
 #----------------------------------------------------------------------
 
 
-"""Support for BerkeleyDB 3.3 through 4.4 with a simple interface.
+"""Support for Berkeley DB 4.0 through 4.7 with a simple interface.
 
 For the full featured object oriented interface use the bsddb.db module
-instead.  It mirrors the Sleepycat BerkeleyDB C API.
+instead.  It mirrors the Oracle Berkeley DB C API.
 """
 
+import sys
+absolute_import = (sys.version_info[0] >= 3)
+
+if sys.py3kwarning:
+    import warnings
+    warnings.warnpy3k("in 3.x, the bsddb module has been removed; "
+                      "please use the pybsddb project instead",
+                      DeprecationWarning, 2)
+
 try:
     if __name__ == 'bsddb3':
         # import _pybsddb binary as it should be the more recent version from
         # a standalone pybsddb addon package than the version included with
         # python as bsddb._bsddb.
-        import _pybsddb
+        if absolute_import :
+            # Because this syntaxis is not valid before Python 2.5
+            exec("from . import _pybsddb")
+        else :
+            import _pybsddb
         _bsddb = _pybsddb
         from bsddb3.dbutils import DeadlockWrap as _DeadlockWrap
     else:
@@ -66,14 +79,16 @@ error = db.DBError  # So bsddb.error will mean something...
 
 import sys, os
 
-# for backwards compatibility with python versions older than 2.3, the
-# iterator interface is dynamically defined and added using a mixin
-# class.  old python can't tokenize it due to the yield keyword.
-if sys.version >= '2.3':
+from weakref import ref
+
+if sys.version_info[0:2] <= (2, 5) :
     import UserDict
-    from weakref import ref
-    exec """
-class _iter_mixin(UserDict.DictMixin):
+    MutableMapping = UserDict.DictMixin
+else :
+    import collections
+    MutableMapping = collections.MutableMapping
+
+class _iter_mixin(MutableMapping):
     def _make_iter_cursor(self):
         cur = _DeadlockWrap(self.db.cursor)
         key = id(cur)
@@ -87,67 +102,88 @@ class _iter_mixin(UserDict.DictMixin):
         return lambda ref: self._cursor_refs.pop(key, None)
 
     def __iter__(self):
+        self._kill_iteration = False
+        self._in_iter += 1
         try:
-            cur = self._make_iter_cursor()
-
-            # FIXME-20031102-greg: race condition.  cursor could
-            # be closed by another thread before this call.
-
-            # since we're only returning keys, we call the cursor
-            # methods with flags=0, dlen=0, dofs=0
-            key = _DeadlockWrap(cur.first, 0,0,0)[0]
-            yield key
-
-            next = cur.next
-            while 1:
-                try:
-                    key = _DeadlockWrap(next, 0,0,0)[0]
-                    yield key
-                except _bsddb.DBCursorClosedError:
-                    cur = self._make_iter_cursor()
-                    # FIXME-20031101-greg: race condition.  cursor could
-                    # be closed by another thread before this call.
-                    _DeadlockWrap(cur.set, key,0,0,0)
-                    next = cur.next
-        except _bsddb.DBNotFoundError:
-            return
-        except _bsddb.DBCursorClosedError:
-            # the database was modified during iteration.  abort.
-            return
+            try:
+                cur = self._make_iter_cursor()
+
+                # FIXME-20031102-greg: race condition.  cursor could
+                # be closed by another thread before this call.
+
+                # since we're only returning keys, we call the cursor
+                # methods with flags=0, dlen=0, dofs=0
+                key = _DeadlockWrap(cur.first, 0,0,0)[0]
+                yield key
+
+                next = getattr(cur, "next")
+                while 1:
+                    try:
+                        key = _DeadlockWrap(next, 0,0,0)[0]
+                        yield key
+                    except _bsddb.DBCursorClosedError:
+                        if self._kill_iteration:
+                            raise RuntimeError('Database changed size '
+                                               'during iteration.')
+                        cur = self._make_iter_cursor()
+                        # FIXME-20031101-greg: race condition.  cursor could
+                        # be closed by another thread before this call.
+                        _DeadlockWrap(cur.set, key,0,0,0)
+                        next = getattr(cur, "next")
+            except _bsddb.DBNotFoundError:
+                pass
+            except _bsddb.DBCursorClosedError:
+                # the database was modified during iteration.  abort.
+                pass
+# When Python 2.3 not supported in bsddb3, we can change this to "finally"
+        except :
+            self._in_iter -= 1
+            raise
+
+        self._in_iter -= 1
 
     def iteritems(self):
         if not self.db:
             return
+        self._kill_iteration = False
+        self._in_iter += 1
         try:
-            cur = self._make_iter_cursor()
-
-            # FIXME-20031102-greg: race condition.  cursor could
-            # be closed by another thread before this call.
-
-            kv = _DeadlockWrap(cur.first)
-            key = kv[0]
-            yield kv
-
-            next = cur.next
-            while 1:
-                try:
-                    kv = _DeadlockWrap(next)
-                    key = kv[0]
-                    yield kv
-                except _bsddb.DBCursorClosedError:
-                    cur = self._make_iter_cursor()
-                    # FIXME-20031101-greg: race condition.  cursor could
-                    # be closed by another thread before this call.
-                    _DeadlockWrap(cur.set, key,0,0,0)
-                    next = cur.next
-        except _bsddb.DBNotFoundError:
-            return
-        except _bsddb.DBCursorClosedError:
-            # the database was modified during iteration.  abort.
-            return
-"""
-else:
-    class _iter_mixin: pass
+            try:
+                cur = self._make_iter_cursor()
+
+                # FIXME-20031102-greg: race condition.  cursor could
+                # be closed by another thread before this call.
+
+                kv = _DeadlockWrap(cur.first)
+                key = kv[0]
+                yield kv
+
+                next = getattr(cur, "next")
+                while 1:
+                    try:
+                        kv = _DeadlockWrap(next)
+                        key = kv[0]
+                        yield kv
+                    except _bsddb.DBCursorClosedError:
+                        if self._kill_iteration:
+                            raise RuntimeError('Database changed size '
+                                               'during iteration.')
+                        cur = self._make_iter_cursor()
+                        # FIXME-20031101-greg: race condition.  cursor could
+                        # be closed by another thread before this call.
+                        _DeadlockWrap(cur.set, key,0,0,0)
+                        next = getattr(cur, "next")
+            except _bsddb.DBNotFoundError:
+                pass
+            except _bsddb.DBCursorClosedError:
+                # the database was modified during iteration.  abort.
+                pass
+# When Python 2.3 not supported in bsddb3, we can change this to "finally"
+        except :
+            self._in_iter -= 1
+            raise
+
+        self._in_iter -= 1
 
 
 class _DBWithCursor(_iter_mixin):
@@ -176,6 +212,8 @@ class _DBWithCursor(_iter_mixin):
         # a collection of all DBCursor objects currently allocated
         # by the _iter_mixin interface.
         self._cursor_refs = {}
+        self._in_iter = 0
+        self._kill_iteration = False
 
     def __del__(self):
         self.close()
@@ -188,7 +226,7 @@ class _DBWithCursor(_iter_mixin):
                 self.saved_dbc_key = None
 
     # This method is needed for all non-cursor DB calls to avoid
-    # BerkeleyDB deadlocks (due to being opened with DB_INIT_LOCK
+    # Berkeley DB deadlocks (due to being opened with DB_INIT_LOCK
     # and DB_THREAD to be thread safe) when intermixing database
     # operations that use the cursor internally with those that don't.
     def _closeCursors(self, save=1):
@@ -218,6 +256,12 @@ class _DBWithCursor(_iter_mixin):
         self._checkOpen()
         return _DeadlockWrap(lambda: len(self.db))  # len(self.db)
 
+    if sys.version_info[0:2] >= (2, 6) :
+        def __repr__(self) :
+            if self.isOpen() :
+                return repr(dict(_DeadlockWrap(self.db.items)))
+            return repr(dict())
+
     def __getitem__(self, key):
         self._checkOpen()
         return _DeadlockWrap(lambda: self.db[key])  # self.db[key]
@@ -225,6 +269,8 @@ class _DBWithCursor(_iter_mixin):
     def __setitem__(self, key, value):
         self._checkOpen()
         self._closeCursors()
+        if self._in_iter and key not in self:
+            self._kill_iteration = True
         def wrapF():
             self.db[key] = value
         _DeadlockWrap(wrapF)  # self.db[key] = value
@@ -232,6 +278,8 @@ class _DBWithCursor(_iter_mixin):
     def __delitem__(self, key):
         self._checkOpen()
         self._closeCursors()
+        if self._in_iter and key in self:
+            self._kill_iteration = True
         def wrapF():
             del self.db[key]
         _DeadlockWrap(wrapF)  # del self.db[key]
@@ -260,12 +308,15 @@ class _DBWithCursor(_iter_mixin):
         self._checkCursor()
         return _DeadlockWrap(self.dbc.set_range, key)
 
-    def next(self):
+    def next(self):  # Renamed by "2to3"
         self._checkOpen()
         self._checkCursor()
-        rv = _DeadlockWrap(self.dbc.next)
+        rv = _DeadlockWrap(getattr(self.dbc, "next"))
         return rv
 
+    if sys.version_info[0] >= 3 :  # For "2to3" conversion
+        next = __next__
+
     def previous(self):
         self._checkOpen()
         self._checkCursor()
@@ -372,7 +423,7 @@ def _checkflag(flag, file):
     elif flag == 'n':
         flags = db.DB_CREATE
         #flags = db.DB_CREATE | db.DB_TRUNCATE
-        # we used db.DB_TRUNCATE flag for this before but BerkeleyDB
+        # we used db.DB_TRUNCATE flag for this before but Berkeley DB
         # 4.2.52 changed to disallowed truncate with txn environments.
         if file is not None and os.path.isfile(file):
             os.unlink(file)
@@ -385,16 +436,14 @@ def _checkflag(flag, file):
 
 # This is a silly little hack that allows apps to continue to use the
 # DB_THREAD flag even on systems without threads without freaking out
-# BerkeleyDB.
+# Berkeley DB.
 #
 # This assumes that if Python was built with thread support then
-# BerkeleyDB was too.
+# Berkeley DB was too.
 
 try:
     import thread
     del thread
-    if db.version() < (3, 3, 0):
-        db.DB_THREAD = 0
 except ImportError:
     db.DB_THREAD = 0
 
diff --git a/Lib/bsddb/db.py b/Lib/bsddb/db.py
index 3bd0c8b..c3aee30 100644
--- a/Lib/bsddb/db.py
+++ b/Lib/bsddb/db.py
@@ -37,15 +37,24 @@
 # case we ever want to augment the stuff in _db in any way.  For now
 # it just simply imports everything from _db.
 
-if __name__.startswith('bsddb3.'):
-    # import _pybsddb binary as it should be the more recent version from
-    # a standalone pybsddb addon package than the version included with
-    # python as bsddb._bsddb.
-    from _pybsddb import *
-    from _pybsddb import __version__
-else:
-    from _bsddb import *
-    from _bsddb import __version__
+import sys
+absolute_import = (sys.version_info[0] >= 3)
 
-if version() < (3, 2, 0):
-    raise ImportError, "correct BerkeleyDB symbols not found.  Perhaps python was statically linked with an older version?"
+if not absolute_import :
+    if __name__.startswith('bsddb3.') :
+        # import _pybsddb binary as it should be the more recent version from
+        # a standalone pybsddb addon package than the version included with
+        # python as bsddb._bsddb.
+        from _pybsddb import *
+        from _pybsddb import __version__
+    else:
+        from _bsddb import *
+        from _bsddb import __version__
+else :
+    # Because this syntaxis is not valid before Python 2.5
+    if __name__.startswith('bsddb3.') :
+        exec("from ._pybsddb import *")
+        exec("from ._pybsddb import __version__")
+    else :
+        exec("from ._bsddb import *")
+        exec("from ._bsddb import __version__")
diff --git a/Lib/bsddb/dbobj.py b/Lib/bsddb/dbobj.py
index b74ee72..1e42397 100644
--- a/Lib/bsddb/dbobj.py
+++ b/Lib/bsddb/dbobj.py
@@ -21,102 +21,112 @@
 # added to _bsddb.c.
 #
 
-import db
+import sys
+absolute_import = (sys.version_info[0] >= 3)
+if absolute_import :
+    # Because this syntaxis is not valid before Python 2.5
+    exec("from . import db")
+else :
+    import db
 
-try:
-    from UserDict import DictMixin
-except ImportError:
-    # DictMixin is new in Python 2.3
-    class DictMixin: pass
+if sys.version_info[0:2] <= (2, 5) :
+    try:
+        from UserDict import DictMixin
+    except ImportError:
+        # DictMixin is new in Python 2.3
+        class DictMixin: pass
+    MutableMapping = DictMixin
+else :
+    import collections
+    MutableMapping = collections.MutableMapping
 
 class DBEnv:
     def __init__(self, *args, **kwargs):
-        self._cobj = apply(db.DBEnv, args, kwargs)
+        self._cobj = db.DBEnv(*args, **kwargs)
 
     def close(self, *args, **kwargs):
-        return apply(self._cobj.close, args, kwargs)
+        return self._cobj.close(*args, **kwargs)
     def open(self, *args, **kwargs):
-        return apply(self._cobj.open, args, kwargs)
+        return self._cobj.open(*args, **kwargs)
     def remove(self, *args, **kwargs):
-        return apply(self._cobj.remove, args, kwargs)
+        return self._cobj.remove(*args, **kwargs)
     def set_shm_key(self, *args, **kwargs):
-        return apply(self._cobj.set_shm_key, args, kwargs)
+        return self._cobj.set_shm_key(*args, **kwargs)
     def set_cachesize(self, *args, **kwargs):
-        return apply(self._cobj.set_cachesize, args, kwargs)
+        return self._cobj.set_cachesize(*args, **kwargs)
     def set_data_dir(self, *args, **kwargs):
-        return apply(self._cobj.set_data_dir, args, kwargs)
+        return self._cobj.set_data_dir(*args, **kwargs)
     def set_flags(self, *args, **kwargs):
-        return apply(self._cobj.set_flags, args, kwargs)
+        return self._cobj.set_flags(*args, **kwargs)
     def set_lg_bsize(self, *args, **kwargs):
-        return apply(self._cobj.set_lg_bsize, args, kwargs)
+        return self._cobj.set_lg_bsize(*args, **kwargs)
     def set_lg_dir(self, *args, **kwargs):
-        return apply(self._cobj.set_lg_dir, args, kwargs)
+        return self._cobj.set_lg_dir(*args, **kwargs)
     def set_lg_max(self, *args, **kwargs):
-        return apply(self._cobj.set_lg_max, args, kwargs)
+        return self._cobj.set_lg_max(*args, **kwargs)
     def set_lk_detect(self, *args, **kwargs):
-        return apply(self._cobj.set_lk_detect, args, kwargs)
+        return self._cobj.set_lk_detect(*args, **kwargs)
     if db.version() < (4,5):
         def set_lk_max(self, *args, **kwargs):
-            return apply(self._cobj.set_lk_max, args, kwargs)
+            return self._cobj.set_lk_max(*args, **kwargs)
     def set_lk_max_locks(self, *args, **kwargs):
-        return apply(self._cobj.set_lk_max_locks, args, kwargs)
+        return self._cobj.set_lk_max_locks(*args, **kwargs)
     def set_lk_max_lockers(self, *args, **kwargs):
-        return apply(self._cobj.set_lk_max_lockers, args, kwargs)
+        return self._cobj.set_lk_max_lockers(*args, **kwargs)
     def set_lk_max_objects(self, *args, **kwargs):
-        return apply(self._cobj.set_lk_max_objects, args, kwargs)
+        return self._cobj.set_lk_max_objects(*args, **kwargs)
     def set_mp_mmapsize(self, *args, **kwargs):
-        return apply(self._cobj.set_mp_mmapsize, args, kwargs)
+        return self._cobj.set_mp_mmapsize(*args, **kwargs)
     def set_timeout(self, *args, **kwargs):
-        return apply(self._cobj.set_timeout, args, kwargs)
+        return self._cobj.set_timeout(*args, **kwargs)
     def set_tmp_dir(self, *args, **kwargs):
-        return apply(self._cobj.set_tmp_dir, args, kwargs)
+        return self._cobj.set_tmp_dir(*args, **kwargs)
     def txn_begin(self, *args, **kwargs):
-        return apply(self._cobj.txn_begin, args, kwargs)
+        return self._cobj.txn_begin(*args, **kwargs)
     def txn_checkpoint(self, *args, **kwargs):
-        return apply(self._cobj.txn_checkpoint, args, kwargs)
+        return self._cobj.txn_checkpoint(*args, **kwargs)
     def txn_stat(self, *args, **kwargs):
-        return apply(self._cobj.txn_stat, args, kwargs)
+        return self._cobj.txn_stat(*args, **kwargs)
     def set_tx_max(self, *args, **kwargs):
-        return apply(self._cobj.set_tx_max, args, kwargs)
+        return self._cobj.set_tx_max(*args, **kwargs)
     def set_tx_timestamp(self, *args, **kwargs):
-        return apply(self._cobj.set_tx_timestamp, args, kwargs)
+        return self._cobj.set_tx_timestamp(*args, **kwargs)
     def lock_detect(self, *args, **kwargs):
-        return apply(self._cobj.lock_detect, args, kwargs)
+        return self._cobj.lock_detect(*args, **kwargs)
     def lock_get(self, *args, **kwargs):
-        return apply(self._cobj.lock_get, args, kwargs)
+        return self._cobj.lock_get(*args, **kwargs)
     def lock_id(self, *args, **kwargs):
-        return apply(self._cobj.lock_id, args, kwargs)
+        return self._cobj.lock_id(*args, **kwargs)
     def lock_put(self, *args, **kwargs):
-        return apply(self._cobj.lock_put, args, kwargs)
+        return self._cobj.lock_put(*args, **kwargs)
     def lock_stat(self, *args, **kwargs):
-        return apply(self._cobj.lock_stat, args, kwargs)
+        return self._cobj.lock_stat(*args, **kwargs)
     def log_archive(self, *args, **kwargs):
-        return apply(self._cobj.log_archive, args, kwargs)
+        return self._cobj.log_archive(*args, **kwargs)
 
     def set_get_returns_none(self, *args, **kwargs):
-        return apply(self._cobj.set_get_returns_none, args, kwargs)
+        return self._cobj.set_get_returns_none(*args, **kwargs)
 
-    if db.version() >= (4,0):
-        def log_stat(self, *args, **kwargs):
-            return apply(self._cobj.log_stat, args, kwargs)
+    def log_stat(self, *args, **kwargs):
+        return self._cobj.log_stat(*args, **kwargs)
 
     if db.version() >= (4,1):
         def dbremove(self, *args, **kwargs):
-            return apply(self._cobj.dbremove, args, kwargs)
+            return self._cobj.dbremove(*args, **kwargs)
         def dbrename(self, *args, **kwargs):
-            return apply(self._cobj.dbrename, args, kwargs)
+            return self._cobj.dbrename(*args, **kwargs)
         def set_encrypt(self, *args, **kwargs):
-            return apply(self._cobj.set_encrypt, args, kwargs)
+            return self._cobj.set_encrypt(*args, **kwargs)
 
     if db.version() >= (4,4):
         def lsn_reset(self, *args, **kwargs):
-            return apply(self._cobj.lsn_reset, args, kwargs)
+            return self._cobj.lsn_reset(*args, **kwargs)
 
 
-class DB(DictMixin):
+class DB(MutableMapping):
     def __init__(self, dbenv, *args, **kwargs):
         # give it the proper DBEnv C object that its expecting
-        self._cobj = apply(db.DB, (dbenv._cobj,) + args, kwargs)
+        self._cobj = db.DB(*((dbenv._cobj,) + args), **kwargs)
 
     # TODO are there other dict methods that need to be overridden?
     def __len__(self):
@@ -128,127 +138,131 @@ class DB(DictMixin):
     def __delitem__(self, arg):
         del self._cobj[arg]
 
+    if sys.version_info[0:2] >= (2, 6) :
+        def __iter__(self) :
+            return self._cobj.__iter__()
+
     def append(self, *args, **kwargs):
-        return apply(self._cobj.append, args, kwargs)
+        return self._cobj.append(*args, **kwargs)
     def associate(self, *args, **kwargs):
-        return apply(self._cobj.associate, args, kwargs)
+        return self._cobj.associate(*args, **kwargs)
     def close(self, *args, **kwargs):
-        return apply(self._cobj.close, args, kwargs)
+        return self._cobj.close(*args, **kwargs)
     def consume(self, *args, **kwargs):
-        return apply(self._cobj.consume, args, kwargs)
+        return self._cobj.consume(*args, **kwargs)
     def consume_wait(self, *args, **kwargs):
-        return apply(self._cobj.consume_wait, args, kwargs)
+        return self._cobj.consume_wait(*args, **kwargs)
     def cursor(self, *args, **kwargs):
-        return apply(self._cobj.cursor, args, kwargs)
+        return self._cobj.cursor(*args, **kwargs)
     def delete(self, *args, **kwargs):
-        return apply(self._cobj.delete, args, kwargs)
+        return self._cobj.delete(*args, **kwargs)
     def fd(self, *args, **kwargs):
-        return apply(self._cobj.fd, args, kwargs)
+        return self._cobj.fd(*args, **kwargs)
     def get(self, *args, **kwargs):
-        return apply(self._cobj.get, args, kwargs)
+        return self._cobj.get(*args, **kwargs)
     def pget(self, *args, **kwargs):
-        return apply(self._cobj.pget, args, kwargs)
+        return self._cobj.pget(*args, **kwargs)
     def get_both(self, *args, **kwargs):
-        return apply(self._cobj.get_both, args, kwargs)
+        return self._cobj.get_both(*args, **kwargs)
     def get_byteswapped(self, *args, **kwargs):
-        return apply(self._cobj.get_byteswapped, args, kwargs)
+        return self._cobj.get_byteswapped(*args, **kwargs)
     def get_size(self, *args, **kwargs):
-        return apply(self._cobj.get_size, args, kwargs)
+        return self._cobj.get_size(*args, **kwargs)
     def get_type(self, *args, **kwargs):
-        return apply(self._cobj.get_type, args, kwargs)
+        return self._cobj.get_type(*args, **kwargs)
     def join(self, *args, **kwargs):
-        return apply(self._cobj.join, args, kwargs)
+        return self._cobj.join(*args, **kwargs)
     def key_range(self, *args, **kwargs):
-        return apply(self._cobj.key_range, args, kwargs)
+        return self._cobj.key_range(*args, **kwargs)
     def has_key(self, *args, **kwargs):
-        return apply(self._cobj.has_key, args, kwargs)
+        return self._cobj.has_key(*args, **kwargs)
     def items(self, *args, **kwargs):
-        return apply(self._cobj.items, args, kwargs)
+        return self._cobj.items(*args, **kwargs)
     def keys(self, *args, **kwargs):
-        return apply(self._cobj.keys, args, kwargs)
+        return self._cobj.keys(*args, **kwargs)
     def open(self, *args, **kwargs):
-        return apply(self._cobj.open, args, kwargs)
+        return self._cobj.open(*args, **kwargs)
     def put(self, *args, **kwargs):
-        return apply(self._cobj.put, args, kwargs)
+        return self._cobj.put(*args, **kwargs)
     def remove(self, *args, **kwargs):
-        return apply(self._cobj.remove, args, kwargs)
+        return self._cobj.remove(*args, **kwargs)
     def rename(self, *args, **kwargs):
-        return apply(self._cobj.rename, args, kwargs)
+        return self._cobj.rename(*args, **kwargs)
     def set_bt_minkey(self, *args, **kwargs):
-        return apply(self._cobj.set_bt_minkey, args, kwargs)
+        return self._cobj.set_bt_minkey(*args, **kwargs)
     def set_bt_compare(self, *args, **kwargs):
-        return apply(self._cobj.set_bt_compare, args, kwargs)
+        return self._cobj.set_bt_compare(*args, **kwargs)
     def set_cachesize(self, *args, **kwargs):
-        return apply(self._cobj.set_cachesize, args, kwargs)
+        return self._cobj.set_cachesize(*args, **kwargs)
     def set_flags(self, *args, **kwargs):
-        return apply(self._cobj.set_flags, args, kwargs)
+        return self._cobj.set_flags(*args, **kwargs)
     def set_h_ffactor(self, *args, **kwargs):
-        return apply(self._cobj.set_h_ffactor, args, kwargs)
+        return self._cobj.set_h_ffactor(*args, **kwargs)
     def set_h_nelem(self, *args, **kwargs):
-        return apply(self._cobj.set_h_nelem, args, kwargs)
+        return self._cobj.set_h_nelem(*args, **kwargs)
     def set_lorder(self, *args, **kwargs):
-        return apply(self._cobj.set_lorder, args, kwargs)
+        return self._cobj.set_lorder(*args, **kwargs)
     def set_pagesize(self, *args, **kwargs):
-        return apply(self._cobj.set_pagesize, args, kwargs)
+        return self._cobj.set_pagesize(*args, **kwargs)
     def set_re_delim(self, *args, **kwargs):
-        return apply(self._cobj.set_re_delim, args, kwargs)
+        return self._cobj.set_re_delim(*args, **kwargs)
     def set_re_len(self, *args, **kwargs):
-        return apply(self._cobj.set_re_len, args, kwargs)
+        return self._cobj.set_re_len(*args, **kwargs)
     def set_re_pad(self, *args, **kwargs):
-        return apply(self._cobj.set_re_pad, args, kwargs)
+        return self._cobj.set_re_pad(*args, **kwargs)
     def set_re_source(self, *args, **kwargs):
-        return apply(self._cobj.set_re_source, args, kwargs)
+        return self._cobj.set_re_source(*args, **kwargs)
     def set_q_extentsize(self, *args, **kwargs):
-        return apply(self._cobj.set_q_extentsize, args, kwargs)
+        return self._cobj.set_q_extentsize(*args, **kwargs)
     def stat(self, *args, **kwargs):
-        return apply(self._cobj.stat, args, kwargs)
+        return self._cobj.stat(*args, **kwargs)
     def sync(self, *args, **kwargs):
-        return apply(self._cobj.sync, args, kwargs)
+        return self._cobj.sync(*args, **kwargs)
     def type(self, *args, **kwargs):
-        return apply(self._cobj.type, args, kwargs)
+        return self._cobj.type(*args, **kwargs)
     def upgrade(self, *args, **kwargs):
-        return apply(self._cobj.upgrade, args, kwargs)
+        return self._cobj.upgrade(*args, **kwargs)
     def values(self, *args, **kwargs):
-        return apply(self._cobj.values, args, kwargs)
+        return self._cobj.values(*args, **kwargs)
     def verify(self, *args, **kwargs):
-        return apply(self._cobj.verify, args, kwargs)
+        return self._cobj.verify(*args, **kwargs)
     def set_get_returns_none(self, *args, **kwargs):
-        return apply(self._cobj.set_get_returns_none, args, kwargs)
+        return self._cobj.set_get_returns_none(*args, **kwargs)
 
     if db.version() >= (4,1):
         def set_encrypt(self, *args, **kwargs):
-            return apply(self._cobj.set_encrypt, args, kwargs)
+            return self._cobj.set_encrypt(*args, **kwargs)
 
 
 class DBSequence:
     def __init__(self, *args, **kwargs):
-        self._cobj = apply(db.DBSequence, args, kwargs)
+        self._cobj = db.DBSequence(*args, **kwargs)
 
     def close(self, *args, **kwargs):
-        return apply(self._cobj.close, args, kwargs)
+        return self._cobj.close(*args, **kwargs)
     def get(self, *args, **kwargs):
-        return apply(self._cobj.get, args, kwargs)
+        return self._cobj.get(*args, **kwargs)
     def get_dbp(self, *args, **kwargs):
-        return apply(self._cobj.get_dbp, args, kwargs)
+        return self._cobj.get_dbp(*args, **kwargs)
     def get_key(self, *args, **kwargs):
-        return apply(self._cobj.get_key, args, kwargs)
+        return self._cobj.get_key(*args, **kwargs)
     def init_value(self, *args, **kwargs):
-        return apply(self._cobj.init_value, args, kwargs)
+        return self._cobj.init_value(*args, **kwargs)
     def open(self, *args, **kwargs):
-        return apply(self._cobj.open, args, kwargs)
+        return self._cobj.open(*args, **kwargs)
     def remove(self, *args, **kwargs):
-        return apply(self._cobj.remove, args, kwargs)
+        return self._cobj.remove(*args, **kwargs)
     def stat(self, *args, **kwargs):
-        return apply(self._cobj.stat, args, kwargs)
+        return self._cobj.stat(*args, **kwargs)
     def set_cachesize(self, *args, **kwargs):
-        return apply(self._cobj.set_cachesize, args, kwargs)
+        return self._cobj.set_cachesize(*args, **kwargs)
     def set_flags(self, *args, **kwargs):
-        return apply(self._cobj.set_flags, args, kwargs)
+        return self._cobj.set_flags(*args, **kwargs)
     def set_range(self, *args, **kwargs):
-        return apply(self._cobj.set_range, args, kwargs)
+        return self._cobj.set_range(*args, **kwargs)
     def get_cachesize(self, *args, **kwargs):
-        return apply(self._cobj.get_cachesize, args, kwargs)
+        return self._cobj.get_cachesize(*args, **kwargs)
     def get_flags(self, *args, **kwargs):
-        return apply(self._cobj.get_flags, args, kwargs)
+        return self._cobj.get_flags(*args, **kwargs)
     def get_range(self, *args, **kwargs):
-        return apply(self._cobj.get_range, args, kwargs)
+        return self._cobj.get_range(*args, **kwargs)
diff --git a/Lib/bsddb/dbshelve.py b/Lib/bsddb/dbshelve.py
index 6fdc6de..7c875b4 100644
--- a/Lib/bsddb/dbshelve.py
+++ b/Lib/bsddb/dbshelve.py
@@ -30,12 +30,40 @@ storage.
 #------------------------------------------------------------------------
 
 import cPickle
+import sys
+
+import sys
+absolute_import = (sys.version_info[0] >= 3)
+if absolute_import :
+    # Because this syntaxis is not valid before Python 2.5
+    exec("from . import db")
+else :
+    import db
+
+#At version 2.3 cPickle switched to using protocol instead of bin
+if sys.version_info[:3] >= (2, 3, 0):
+    HIGHEST_PROTOCOL = cPickle.HIGHEST_PROTOCOL
+# In python 2.3.*, "cPickle.dumps" accepts no
+# named parameters. "pickle.dumps" accepts them,
+# so this seems a bug.
+    if sys.version_info[:3] < (2, 4, 0):
+        def _dumps(object, protocol):
+            return cPickle.dumps(object, protocol)
+    else :
+        def _dumps(object, protocol):
+            return cPickle.dumps(object, protocol=protocol)
+
+else:
+    HIGHEST_PROTOCOL = None
+    def _dumps(object, protocol):
+        return cPickle.dumps(object, bin=protocol)
+
+
 try:
     from UserDict import DictMixin
 except ImportError:
     # DictMixin is new in Python 2.3
     class DictMixin: pass
-import db
 
 #------------------------------------------------------------------------
 
@@ -84,7 +112,11 @@ class DBShelf(DictMixin):
     """
     def __init__(self, dbenv=None):
         self.db = db.DB(dbenv)
-        self.binary = 1
+        self._closed = True
+        if HIGHEST_PROTOCOL:
+            self.protocol = HIGHEST_PROTOCOL
+        else:
+            self.protocol = 1
 
 
     def __del__(self):
@@ -111,7 +143,7 @@ class DBShelf(DictMixin):
 
 
     def __setitem__(self, key, value):
-        data = cPickle.dumps(value, self.binary)
+        data = _dumps(value, self.protocol)
         self.db[key] = data
 
 
@@ -120,14 +152,31 @@ class DBShelf(DictMixin):
 
 
     def keys(self, txn=None):
-        if txn != None:
+        if txn is not None:
             return self.db.keys(txn)
         else:
             return self.db.keys()
 
 
+    def open(self, *args, **kwargs):
+        self.db.open(*args, **kwargs)
+        self._closed = False
+
+
+    def close(self, *args, **kwargs):
+        self.db.close(*args, **kwargs)
+        self._closed = True
+
+
+    def __repr__(self):
+        if self._closed:
+            return '<DBShelf @ 0x%x - closed>' % (id(self))
+        else:
+            return repr(dict(self.iteritems()))
+
+
     def items(self, txn=None):
-        if txn != None:
+        if txn is not None:
             items = self.db.items(txn)
         else:
             items = self.db.items()
@@ -138,7 +187,7 @@ class DBShelf(DictMixin):
         return newitems
 
     def values(self, txn=None):
-        if txn != None:
+        if txn is not None:
             values = self.db.values(txn)
         else:
             values = self.db.values()
@@ -149,7 +198,7 @@ class DBShelf(DictMixin):
     # Other methods
 
     def __append(self, value, txn=None):
-        data = cPickle.dumps(value, self.binary)
+        data = _dumps(value, self.protocol)
         return self.db.append(data, txn)
 
     def append(self, value, txn=None):
@@ -160,8 +209,13 @@ class DBShelf(DictMixin):
 
     def associate(self, secondaryDB, callback, flags=0):
         def _shelf_callback(priKey, priData, realCallback=callback):
-            data = cPickle.loads(priData)
+            # Safe in Python 2.x because expresion short circuit
+            if sys.version_info[0] < 3 or isinstance(priData, bytes) :
+                data = cPickle.loads(priData)
+            else :
+                data = cPickle.loads(bytes(priData, "iso8859-1"))  # 8 bits
             return realCallback(priKey, data)
+
         return self.db.associate(secondaryDB, _shelf_callback, flags)
 
 
@@ -171,27 +225,27 @@ class DBShelf(DictMixin):
         # given nothing is passed to the extension module.  That way
         # an exception can be raised if set_get_returns_none is turned
         # off.
-        data = apply(self.db.get, args, kw)
+        data = self.db.get(*args, **kw)
         try:
             return cPickle.loads(data)
-        except (TypeError, cPickle.UnpicklingError):
+        except (EOFError, TypeError, cPickle.UnpicklingError):
             return data  # we may be getting the default value, or None,
                          # so it doesn't need unpickled.
 
     def get_both(self, key, value, txn=None, flags=0):
-        data = cPickle.dumps(value, self.binary)
+        data = _dumps(value, self.protocol)
         data = self.db.get(key, data, txn, flags)
         return cPickle.loads(data)
 
 
     def cursor(self, txn=None, flags=0):
         c = DBShelfCursor(self.db.cursor(txn, flags))
-        c.binary = self.binary
+        c.protocol = self.protocol
         return c
 
 
     def put(self, key, value, txn=None, flags=0):
-        data = cPickle.dumps(value, self.binary)
+        data = _dumps(value, self.protocol)
         return self.db.put(key, data, txn, flags)
 
 
@@ -227,18 +281,20 @@ class DBShelfCursor:
     #----------------------------------------------
 
     def dup(self, flags=0):
-        return DBShelfCursor(self.dbc.dup(flags))
+        c = DBShelfCursor(self.dbc.dup(flags))
+        c.protocol = self.protocol
+        return c
 
 
     def put(self, key, value, flags=0):
-        data = cPickle.dumps(value, self.binary)
+        data = _dumps(value, self.protocol)
         return self.dbc.put(key, data, flags)
 
 
     def get(self, *args):
         count = len(args)  # a method overloading hack
         method = getattr(self, 'get_%d' % count)
-        apply(method, args)
+        method(*args)
 
     def get_1(self, flags):
         rec = self.dbc.get(flags)
@@ -249,7 +305,7 @@ class DBShelfCursor:
         return self._extract(rec)
 
     def get_3(self, key, value, flags):
-        data = cPickle.dumps(value, self.binary)
+        data = _dumps(value, self.protocol)
         rec = self.dbc.get(key, flags)
         return self._extract(rec)
 
@@ -266,7 +322,7 @@ class DBShelfCursor:
 
 
     def get_both(self, key, value, flags=0):
-        data = cPickle.dumps(value, self.binary)
+        data = _dumps(value, self.protocol)
         rec = self.dbc.get_both(key, flags)
         return self._extract(rec)
 
@@ -290,7 +346,11 @@ class DBShelfCursor:
             return None
         else:
             key, data = rec
-            return key, cPickle.loads(data)
+            # Safe in Python 2.x because expresion short circuit
+            if sys.version_info[0] < 3 or isinstance(data, bytes) :
+                return key, cPickle.loads(data)
+            else :
+                return key, cPickle.loads(bytes(data, "iso8859-1"))  # 8 bits
 
     #----------------------------------------------
     # Methods allowed to pass-through to self.dbc
diff --git a/Lib/bsddb/dbtables.py b/Lib/bsddb/dbtables.py
index 66b7d12..2a447c4 100644
--- a/Lib/bsddb/dbtables.py
+++ b/Lib/bsddb/dbtables.py
@@ -10,34 +10,32 @@
 #               software has been tested, but no warranty is expressed or
 #               implied.
 #
-#   --  Gregory P. Smith <greg@electricrain.com>
+#   --  Gregory P. Smith <greg@krypto.org>
 
 # This provides a simple database table interface built on top of
-# the Python BerkeleyDB 3 interface.
+# the Python Berkeley DB 3 interface.
 #
-_cvsid = '$Id: dbtables.py 58760 2007-11-01 21:22:40Z gregory.p.smith $'
+_cvsid = '$Id: dbtables.py 83624 2010-08-03 03:19:00Z ezio.melotti $'
 
 import re
 import sys
 import copy
-import struct
 import random
-from types import ListType, StringType
+import struct
 import cPickle as pickle
 
 try:
     # For Pythons w/distutils pybsddb
-    from bsddb3.db import *
+    from bsddb3 import db
 except ImportError:
     # For Python 2.3
-    from bsddb.db import *
+    from bsddb import db
 
 # XXX(nnorwitz): is this correct? DBIncompleteError is conditional in _bsddb.c
-try:
-    DBIncompleteError
-except NameError:
+if not hasattr(db,"DBIncompleteError") :
     class DBIncompleteError(Exception):
         pass
+    db.DBIncompleteError = DBIncompleteError
 
 class TableDBError(StandardError):
     pass
@@ -105,6 +103,7 @@ _rowid = '._ROWID_.' # this+rowid+this key contains a unique entry for each
                      # row in the table.  (no data is stored)
 _rowid_str_len = 8   # length in bytes of the unique rowid strings
 
+
 def _data_key(table, col, rowid):
     return table + _data + col + _data + rowid
 
@@ -139,41 +138,108 @@ class bsdTableDB :
                  recover=0, dbflags=0):
         """bsdTableDB(filename, dbhome, create=0, truncate=0, mode=0600)
 
-        Open database name in the dbhome BerkeleyDB directory.
+        Open database name in the dbhome Berkeley DB directory.
         Use keyword arguments when calling this constructor.
         """
         self.db = None
-        myflags = DB_THREAD
+        myflags = db.DB_THREAD
         if create:
-            myflags |= DB_CREATE
-        flagsforenv = (DB_INIT_MPOOL | DB_INIT_LOCK | DB_INIT_LOG |
-                       DB_INIT_TXN | dbflags)
+            myflags |= db.DB_CREATE
+        flagsforenv = (db.DB_INIT_MPOOL | db.DB_INIT_LOCK | db.DB_INIT_LOG |
+                       db.DB_INIT_TXN | dbflags)
         # DB_AUTO_COMMIT isn't a valid flag for env.open()
         try:
-            dbflags |= DB_AUTO_COMMIT
+            dbflags |= db.DB_AUTO_COMMIT
         except AttributeError:
             pass
         if recover:
-            flagsforenv = flagsforenv | DB_RECOVER
-        self.env = DBEnv()
+            flagsforenv = flagsforenv | db.DB_RECOVER
+        self.env = db.DBEnv()
         # enable auto deadlock avoidance
-        self.env.set_lk_detect(DB_LOCK_DEFAULT)
+        self.env.set_lk_detect(db.DB_LOCK_DEFAULT)
         self.env.open(dbhome, myflags | flagsforenv)
         if truncate:
-            myflags |= DB_TRUNCATE
-        self.db = DB(self.env)
+            myflags |= db.DB_TRUNCATE
+        self.db = db.DB(self.env)
         # this code relies on DBCursor.set* methods to raise exceptions
         # rather than returning None
         self.db.set_get_returns_none(1)
         # allow duplicate entries [warning: be careful w/ metadata]
-        self.db.set_flags(DB_DUP)
-        self.db.open(filename, DB_BTREE, dbflags | myflags, mode)
+        self.db.set_flags(db.DB_DUP)
+        self.db.open(filename, db.DB_BTREE, dbflags | myflags, mode)
         self.dbfilename = filename
+
+        if sys.version_info[0] >= 3 :
+            class cursor_py3k(object) :
+                def __init__(self, dbcursor) :
+                    self._dbcursor = dbcursor
+
+                def close(self) :
+                    return self._dbcursor.close()
+
+                def set_range(self, search) :
+                    v = self._dbcursor.set_range(bytes(search, "iso8859-1"))
+                    if v is not None :
+                        v = (v[0].decode("iso8859-1"),
+                                v[1].decode("iso8859-1"))
+                    return v
+
+                def __next__(self) :
+                    v = getattr(self._dbcursor, "next")()
+                    if v is not None :
+                        v = (v[0].decode("iso8859-1"),
+                                v[1].decode("iso8859-1"))
+                    return v
+
+            class db_py3k(object) :
+                def __init__(self, db) :
+                    self._db = db
+
+                def cursor(self, txn=None) :
+                    return cursor_py3k(self._db.cursor(txn=txn))
+
+                def has_key(self, key, txn=None) :
+                    return getattr(self._db,"has_key")(bytes(key, "iso8859-1"),
+                            txn=txn)
+
+                def put(self, key, value, flags=0, txn=None) :
+                    key = bytes(key, "iso8859-1")
+                    if value is not None :
+                        value = bytes(value, "iso8859-1")
+                    return self._db.put(key, value, flags=flags, txn=txn)
+
+                def put_bytes(self, key, value, txn=None) :
+                    key = bytes(key, "iso8859-1")
+                    return self._db.put(key, value, txn=txn)
+
+                def get(self, key, txn=None, flags=0) :
+                    key = bytes(key, "iso8859-1")
+                    v = self._db.get(key, txn=txn, flags=flags)
+                    if v is not None :
+                        v = v.decode("iso8859-1")
+                    return v
+
+                def get_bytes(self, key, txn=None, flags=0) :
+                    key = bytes(key, "iso8859-1")
+                    return self._db.get(key, txn=txn, flags=flags)
+
+                def delete(self, key, txn=None) :
+                    key = bytes(key, "iso8859-1")
+                    return self._db.delete(key, txn=txn)
+
+                def close (self) :
+                    return self._db.close()
+
+            self.db = db_py3k(self.db)
+        else :  # Python 2.x
+            pass
+
         # Initialize the table names list if this is a new database
         txn = self.env.txn_begin()
         try:
-            if not self.db.has_key(_table_names_key, txn):
-                self.db.put(_table_names_key, pickle.dumps([], 1), txn=txn)
+            if not getattr(self.db, "has_key")(_table_names_key, txn):
+                getattr(self.db, "put_bytes", self.db.put) \
+                        (_table_names_key, pickle.dumps([], 1), txn=txn)
         # Yes, bare except
         except:
             txn.abort()
@@ -197,13 +263,13 @@ class bsdTableDB :
     def checkpoint(self, mins=0):
         try:
             self.env.txn_checkpoint(mins)
-        except DBIncompleteError:
+        except db.DBIncompleteError:
             pass
 
     def sync(self):
         try:
             self.db.sync()
-        except DBIncompleteError:
+        except db.DBIncompleteError:
             pass
 
     def _db_print(self) :
@@ -220,7 +286,7 @@ class bsdTableDB :
                 else:
                     cur.close()
                     return
-        except DBNotFoundError:
+        except db.DBNotFoundError:
             cur.close()
 
 
@@ -229,7 +295,8 @@ class bsdTableDB :
 
         raises TableDBError if it already exists or for other DB errors.
         """
-        assert isinstance(columns, ListType)
+        assert isinstance(columns, list)
+
         txn = None
         try:
             # checking sanity of the table and column names here on
@@ -243,41 +310,47 @@ class bsdTableDB :
                         "bad column name: contains reserved metastrings")
 
             columnlist_key = _columns_key(table)
-            if self.db.has_key(columnlist_key):
+            if getattr(self.db, "has_key")(columnlist_key):
                 raise TableAlreadyExists, "table already exists"
 
             txn = self.env.txn_begin()
             # store the table's column info
-            self.db.put(columnlist_key, pickle.dumps(columns, 1), txn=txn)
+            getattr(self.db, "put_bytes", self.db.put)(columnlist_key,
+                    pickle.dumps(columns, 1), txn=txn)
 
             # add the table name to the tablelist
-            tablelist = pickle.loads(self.db.get(_table_names_key, txn=txn,
-                                                 flags=DB_RMW))
+            tablelist = pickle.loads(getattr(self.db, "get_bytes",
+                self.db.get) (_table_names_key, txn=txn, flags=db.DB_RMW))
             tablelist.append(table)
             # delete 1st, in case we opened with DB_DUP
-            self.db.delete(_table_names_key, txn)
-            self.db.put(_table_names_key, pickle.dumps(tablelist, 1), txn=txn)
+            self.db.delete(_table_names_key, txn=txn)
+            getattr(self.db, "put_bytes", self.db.put)(_table_names_key,
+                    pickle.dumps(tablelist, 1), txn=txn)
 
             txn.commit()
             txn = None
-        except DBError, dberror:
+        except db.DBError, dberror:
             if txn:
                 txn.abort()
-            raise TableDBError, dberror[1]
+            if sys.version_info < (2, 6) :
+                raise TableDBError, dberror[1]
+            else :
+                raise TableDBError, dberror.args[1]
 
 
     def ListTableColumns(self, table):
         """Return a list of columns in the given table.
         [] if the table doesn't exist.
         """
-        assert isinstance(table, StringType)
+        assert isinstance(table, str)
         if contains_metastrings(table):
             raise ValueError, "bad table name: contains reserved metastrings"
 
         columnlist_key = _columns_key(table)
-        if not self.db.has_key(columnlist_key):
+        if not getattr(self.db, "has_key")(columnlist_key):
             return []
-        pickledcolumnlist = self.db.get(columnlist_key)
+        pickledcolumnlist = getattr(self.db, "get_bytes",
+                self.db.get)(columnlist_key)
         if pickledcolumnlist:
             return pickle.loads(pickledcolumnlist)
         else:
@@ -285,7 +358,7 @@ class bsdTableDB :
 
     def ListTables(self):
         """Return a list of tables in this database."""
-        pickledtablelist = self.db.get(_table_names_key)
+        pickledtablelist = self.db.get_get(_table_names_key)
         if pickledtablelist:
             return pickle.loads(pickledtablelist)
         else:
@@ -300,7 +373,8 @@ class bsdTableDB :
         additional columns present in the given list as well as
         all of its current columns.
         """
-        assert isinstance(columns, ListType)
+        assert isinstance(columns, list)
+
         try:
             self.CreateTable(table, columns)
         except TableAlreadyExists:
@@ -312,7 +386,8 @@ class bsdTableDB :
 
                 # load the current column list
                 oldcolumnlist = pickle.loads(
-                    self.db.get(columnlist_key, txn=txn, flags=DB_RMW))
+                    getattr(self.db, "get_bytes",
+                        self.db.get)(columnlist_key, txn=txn, flags=db.DB_RMW))
                 # create a hash table for fast lookups of column names in the
                 # loop below
                 oldcolumnhash = {}
@@ -323,14 +398,14 @@ class bsdTableDB :
                 # column names
                 newcolumnlist = copy.copy(oldcolumnlist)
                 for c in columns:
-                    if not oldcolumnhash.has_key(c):
+                    if c not in oldcolumnhash:
                         newcolumnlist.append(c)
 
                 # store the table's new extended column list
                 if newcolumnlist != oldcolumnlist :
                     # delete the old one first since we opened with DB_DUP
-                    self.db.delete(columnlist_key, txn)
-                    self.db.put(columnlist_key,
+                    self.db.delete(columnlist_key, txn=txn)
+                    getattr(self.db, "put_bytes", self.db.put)(columnlist_key,
                                 pickle.dumps(newcolumnlist, 1),
                                 txn=txn)
 
@@ -338,18 +413,22 @@ class bsdTableDB :
                 txn = None
 
                 self.__load_column_info(table)
-            except DBError, dberror:
+            except db.DBError, dberror:
                 if txn:
                     txn.abort()
-                raise TableDBError, dberror[1]
+                if sys.version_info < (2, 6) :
+                    raise TableDBError, dberror[1]
+                else :
+                    raise TableDBError, dberror.args[1]
 
 
     def __load_column_info(self, table) :
         """initialize the self.__tablecolumns dict"""
         # check the column names
         try:
-            tcolpickles = self.db.get(_columns_key(table))
-        except DBNotFoundError:
+            tcolpickles = getattr(self.db, "get_bytes",
+                    self.db.get)(_columns_key(table))
+        except db.DBNotFoundError:
             raise TableDBError, "unknown table: %r" % (table,)
         if not tcolpickles:
             raise TableDBError, "unknown table: %r" % (table,)
@@ -367,11 +446,14 @@ class bsdTableDB :
                 blist.append(random.randint(0,255))
             newid = struct.pack('B'*_rowid_str_len, *blist)
 
+            if sys.version_info[0] >= 3 :
+                newid = newid.decode("iso8859-1")  # 8 bits
+
             # Guarantee uniqueness by adding this key to the database
             try:
                 self.db.put(_rowid_key(table, newid), None, txn=txn,
-                            flags=DB_NOOVERWRITE)
-            except DBKeyExistError:
+                            flags=db.DB_NOOVERWRITE)
+            except db.DBKeyExistError:
                 pass
             else:
                 unique = 1
@@ -383,13 +465,14 @@ class bsdTableDB :
         """Insert(table, datadict) - Insert a new row into the table
         using the keys+values from rowdict as the column values.
         """
+
         txn = None
         try:
-            if not self.db.has_key(_columns_key(table)):
+            if not getattr(self.db, "has_key")(_columns_key(table)):
                 raise TableDBError, "unknown table"
 
             # check the validity of each column name
-            if not self.__tablecolumns.has_key(table):
+            if not table in self.__tablecolumns:
                 self.__load_column_info(table)
             for column in rowdict.keys() :
                 if not self.__tablecolumns[table].count(column):
@@ -407,7 +490,7 @@ class bsdTableDB :
             txn.commit()
             txn = None
 
-        except DBError, dberror:
+        except db.DBError, dberror:
             # WIBNI we could just abort the txn and re-raise the exception?
             # But no, because TableDBError is not related to DBError via
             # inheritance, so it would be backwards incompatible.  Do the next
@@ -416,7 +499,10 @@ class bsdTableDB :
             if txn:
                 txn.abort()
                 self.db.delete(_rowid_key(table, rowid))
-            raise TableDBError, dberror[1], info[2]
+            if sys.version_info < (2, 6) :
+                raise TableDBError, dberror[1], info[2]
+            else :
+                raise TableDBError, dberror.args[1], info[2]
 
 
     def Modify(self, table, conditions={}, mappings={}):
@@ -430,6 +516,7 @@ class bsdTableDB :
           condition callable expecting the data string as an argument and
           returning the new string for that column.
         """
+
         try:
             matching_rowids = self.__Select(table, [], conditions)
 
@@ -447,13 +534,13 @@ class bsdTableDB :
                                 txn=txn)
                             self.db.delete(
                                 _data_key(table, column, rowid),
-                                txn)
-                        except DBNotFoundError:
+                                txn=txn)
+                        except db.DBNotFoundError:
                              # XXXXXXX row key somehow didn't exist, assume no
                              # error
                             dataitem = None
                         dataitem = mappings[column](dataitem)
-                        if dataitem <> None:
+                        if dataitem is not None:
                             self.db.put(
                                 _data_key(table, column, rowid),
                                 dataitem, txn=txn)
@@ -466,8 +553,11 @@ class bsdTableDB :
                         txn.abort()
                     raise
 
-        except DBError, dberror:
-            raise TableDBError, dberror[1]
+        except db.DBError, dberror:
+            if sys.version_info < (2, 6) :
+                raise TableDBError, dberror[1]
+            else :
+                raise TableDBError, dberror.args[1]
 
     def Delete(self, table, conditions={}):
         """Delete(table, conditions) - Delete items matching the given
@@ -477,6 +567,7 @@ class bsdTableDB :
           condition functions expecting the data string as an
           argument and returning a boolean.
         """
+
         try:
             matching_rowids = self.__Select(table, [], conditions)
 
@@ -490,24 +581,27 @@ class bsdTableDB :
                         # delete the data key
                         try:
                             self.db.delete(_data_key(table, column, rowid),
-                                           txn)
-                        except DBNotFoundError:
+                                           txn=txn)
+                        except db.DBNotFoundError:
                             # XXXXXXX column may not exist, assume no error
                             pass
 
                     try:
-                        self.db.delete(_rowid_key(table, rowid), txn)
-                    except DBNotFoundError:
+                        self.db.delete(_rowid_key(table, rowid), txn=txn)
+                    except db.DBNotFoundError:
                         # XXXXXXX row key somehow didn't exist, assume no error
                         pass
                     txn.commit()
                     txn = None
-                except DBError, dberror:
+                except db.DBError, dberror:
                     if txn:
                         txn.abort()
                     raise
-        except DBError, dberror:
-            raise TableDBError, dberror[1]
+        except db.DBError, dberror:
+            if sys.version_info < (2, 6) :
+                raise TableDBError, dberror[1]
+            else :
+                raise TableDBError, dberror.args[1]
 
 
     def Select(self, table, columns, conditions={}):
@@ -521,13 +615,16 @@ class bsdTableDB :
           argument and returning a boolean.
         """
         try:
-            if not self.__tablecolumns.has_key(table):
+            if table not in self.__tablecolumns:
                 self.__load_column_info(table)
             if columns is None:
                 columns = self.__tablecolumns[table]
             matching_rowids = self.__Select(table, columns, conditions)
-        except DBError, dberror:
-            raise TableDBError, dberror[1]
+        except db.DBError, dberror:
+            if sys.version_info < (2, 6) :
+                raise TableDBError, dberror[1]
+            else :
+                raise TableDBError, dberror.args[1]
         # return the matches as a list of dictionaries
         return matching_rowids.values()
 
@@ -542,7 +639,7 @@ class bsdTableDB :
         argument and returning a boolean.
         """
         # check the validity of each column name
-        if not self.__tablecolumns.has_key(table):
+        if not table in self.__tablecolumns:
             self.__load_column_info(table)
         if columns is None:
             columns = self.tablecolumns[table]
@@ -580,8 +677,19 @@ class bsdTableDB :
             # leave all unknown condition callables alone as equals
             return 0
 
-        conditionlist = conditions.items()
-        conditionlist.sort(cmp_conditions)
+        if sys.version_info < (2, 6) :
+            conditionlist = conditions.items()
+            conditionlist.sort(cmp_conditions)
+        else :  # Insertion Sort. Please, improve
+            conditionlist = []
+            for i in conditions.items() :
+                for j, k in enumerate(conditionlist) :
+                    r = cmp_conditions(k, i)
+                    if r == 1 :
+                        conditionlist.insert(j, i)
+                        break
+                else :
+                    conditionlist.append(i)
 
         # Apply conditions to column data to find what we want
         cur = self.db.cursor()
@@ -601,23 +709,23 @@ class bsdTableDB :
                     # extract the rowid from the key
                     rowid = key[-_rowid_str_len:]
 
-                    if not rejected_rowids.has_key(rowid):
+                    if not rowid in rejected_rowids:
                         # if no condition was specified or the condition
                         # succeeds, add row to our match list.
                         if not condition or condition(data):
-                            if not matching_rowids.has_key(rowid):
+                            if not rowid in matching_rowids:
                                 matching_rowids[rowid] = {}
                             if savethiscolumndata:
                                 matching_rowids[rowid][column] = data
                         else:
-                            if matching_rowids.has_key(rowid):
+                            if rowid in matching_rowids:
                                 del matching_rowids[rowid]
                             rejected_rowids[rowid] = rowid
 
                     key, data = cur.next()
 
-            except DBError, dberror:
-                if dberror[0] != DB_NOTFOUND:
+            except db.DBError, dberror:
+                if dberror.args[0] != db.DB_NOTFOUND:
                     raise
                 continue
 
@@ -631,14 +739,18 @@ class bsdTableDB :
         if len(columns) > 0:
             for rowid, rowdata in matching_rowids.items():
                 for column in columns:
-                    if rowdata.has_key(column):
+                    if column in rowdata:
                         continue
                     try:
                         rowdata[column] = self.db.get(
                             _data_key(table, column, rowid))
-                    except DBError, dberror:
-                        if dberror[0] != DB_NOTFOUND:
-                            raise
+                    except db.DBError, dberror:
+                        if sys.version_info < (2, 6) :
+                            if dberror[0] != db.DB_NOTFOUND:
+                                raise
+                        else :
+                            if dberror.args[0] != db.DB_NOTFOUND:
+                                raise
                         rowdata[column] = None
 
         # return the matches
@@ -652,7 +764,7 @@ class bsdTableDB :
             txn = self.env.txn_begin()
 
             # delete the column list
-            self.db.delete(_columns_key(table), txn)
+            self.db.delete(_columns_key(table), txn=txn)
 
             cur = self.db.cursor(txn)
 
@@ -661,7 +773,7 @@ class bsdTableDB :
             while 1:
                 try:
                     key, data = cur.set_range(table_key)
-                except DBNotFoundError:
+                except db.DBNotFoundError:
                     break
                 # only delete items in this table
                 if key[:len(table_key)] != table_key:
@@ -673,7 +785,7 @@ class bsdTableDB :
             while 1:
                 try:
                     key, data = cur.set_range(table_key)
-                except DBNotFoundError:
+                except db.DBNotFoundError:
                     break
                 # only delete items in this table
                 if key[:len(table_key)] != table_key:
@@ -684,23 +796,25 @@ class bsdTableDB :
 
             # delete the tablename from the table name list
             tablelist = pickle.loads(
-                self.db.get(_table_names_key, txn=txn, flags=DB_RMW))
+                getattr(self.db, "get_bytes", self.db.get)(_table_names_key,
+                    txn=txn, flags=db.DB_RMW))
             try:
                 tablelist.remove(table)
             except ValueError:
                 # hmm, it wasn't there, oh well, that's what we want.
                 pass
             # delete 1st, incase we opened with DB_DUP
-            self.db.delete(_table_names_key, txn)
-            self.db.put(_table_names_key, pickle.dumps(tablelist, 1), txn=txn)
+            self.db.delete(_table_names_key, txn=txn)
+            getattr(self.db, "put_bytes", self.db.put)(_table_names_key,
+                    pickle.dumps(tablelist, 1), txn=txn)
 
             txn.commit()
             txn = None
 
-            if self.__tablecolumns.has_key(table):
+            if table in self.__tablecolumns:
                 del self.__tablecolumns[table]
 
-        except DBError, dberror:
+        except db.DBError, dberror:
             if txn:
                 txn.abort()
-            raise TableDBError, dberror[1]
+            raise TableDBError(dberror.args[1])
diff --git a/Lib/bsddb/dbutils.py b/Lib/bsddb/dbutils.py
index 6dcfdd5..02a686f 100644
--- a/Lib/bsddb/dbutils.py
+++ b/Lib/bsddb/dbutils.py
@@ -9,7 +9,7 @@
 #               software has been tested, but no warranty is expressed or
 #               implied.
 #
-# Author: Gregory P. Smith <greg@electricrain.com>
+# Author: Gregory P. Smith <greg@krypto.org>
 #
 # Note: I don't know how useful this is in reality since when a
 #       DBLockDeadlockError happens the current transaction is supposed to be
@@ -26,7 +26,13 @@
 #
 from time import sleep as _sleep
 
-import db
+import sys
+absolute_import = (sys.version_info[0] >= 3)
+if absolute_import :
+    # Because this syntaxis is not valid before Python 2.5
+    exec("from . import db")
+else :
+    import db
 
 # always sleep at least N seconds between retrys
 _deadlock_MinSleepTime = 1.0/128
@@ -55,7 +61,7 @@ def DeadlockWrap(function, *_args, **_kwargs):
     """
     sleeptime = _deadlock_MinSleepTime
     max_retries = _kwargs.get('max_retries', -1)
-    if _kwargs.has_key('max_retries'):
+    if 'max_retries' in _kwargs:
         del _kwargs['max_retries']
     while True:
         try:
diff --git a/Lib/bsddb/test/test_all.py b/Lib/bsddb/test/test_all.py
index ad8b1e9..39231c6 100644
--- a/Lib/bsddb/test/test_all.py
+++ b/Lib/bsddb/test/test_all.py
@@ -6,10 +6,378 @@ import os
 import unittest
 try:
     # For Pythons w/distutils pybsddb
-    from bsddb3 import db
+    import bsddb3 as bsddb
 except ImportError:
     # For Python 2.3
-    from bsddb import db
+    import bsddb
+
+
+if sys.version_info[0] >= 3 :
+    charset = "iso8859-1"  # Full 8 bit
+
+    class cursor_py3k(object) :
+        def __init__(self, db, *args, **kwargs) :
+            self._dbcursor = db.cursor(*args, **kwargs)
+
+        def __getattr__(self, v) :
+            return getattr(self._dbcursor, v)
+
+        def _fix(self, v) :
+            if v is None : return None
+            key, value = v
+            if isinstance(key, bytes) :
+                key = key.decode(charset)
+            return (key, value.decode(charset))
+
+        def __next__(self) :
+            v = getattr(self._dbcursor, "next")()
+            return self._fix(v)
+
+        next = __next__
+
+        def previous(self) :
+            v = self._dbcursor.previous()
+            return self._fix(v)
+
+        def last(self) :
+            v = self._dbcursor.last()
+            return self._fix(v)
+
+        def set(self, k) :
+            if isinstance(k, str) :
+                k = bytes(k, charset)
+            v = self._dbcursor.set(k)
+            return self._fix(v)
+
+        def set_recno(self, num) :
+            v = self._dbcursor.set_recno(num)
+            return self._fix(v)
+
+        def set_range(self, k, dlen=-1, doff=-1) :
+            if isinstance(k, str) :
+                k = bytes(k, charset)
+            v = self._dbcursor.set_range(k, dlen=dlen, doff=doff)
+            return self._fix(v)
+
+        def dup(self, flags=0) :
+            cursor = self._dbcursor.dup(flags)
+            return dup_cursor_py3k(cursor)
+
+        def next_dup(self) :
+            v = self._dbcursor.next_dup()
+            return self._fix(v)
+
+        def next_nodup(self) :
+            v = self._dbcursor.next_nodup()
+            return self._fix(v)
+
+        def put(self, key, value, flags=0, dlen=-1, doff=-1) :
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            if isinstance(value, str) :
+                value = bytes(value, charset)
+            return self._dbcursor.put(key, value, flags=flags, dlen=dlen,
+                    doff=doff)
+
+        def current(self, flags=0, dlen=-1, doff=-1) :
+            v = self._dbcursor.current(flags=flags, dlen=dlen, doff=doff)
+            return self._fix(v)
+
+        def first(self) :
+            v = self._dbcursor.first()
+            return self._fix(v)
+
+        def pget(self, key=None, data=None, flags=0) :
+            # Incorrect because key can be a bare number,
+            # but enough to pass testsuite
+            if isinstance(key, int) and (data is None) and (flags == 0) :
+                flags = key
+                key = None
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            if isinstance(data, int) and (flags==0) :
+                flags = data
+                data = None
+            if isinstance(data, str) :
+                data = bytes(data, charset)
+            v=self._dbcursor.pget(key=key, data=data, flags=flags)
+            if v is not None :
+                v1, v2, v3 = v
+                if isinstance(v1, bytes) :
+                    v1 = v1.decode(charset)
+                if isinstance(v2, bytes) :
+                    v2 = v2.decode(charset)
+
+                v = (v1, v2, v3.decode(charset))
+
+            return v
+
+        def join_item(self) :
+            v = self._dbcursor.join_item()
+            if v is not None :
+                v = v.decode(charset)
+            return v
+
+        def get(self, *args, **kwargs) :
+            l = len(args)
+            if l == 2 :
+                k, f = args
+                if isinstance(k, str) :
+                    k = bytes(k, "iso8859-1")
+                args = (k, f)
+            elif l == 3 :
+                k, d, f = args
+                if isinstance(k, str) :
+                    k = bytes(k, charset)
+                if isinstance(d, str) :
+                    d = bytes(d, charset)
+                args =(k, d, f)
+
+            v = self._dbcursor.get(*args, **kwargs)
+            if v is not None :
+                k, v = v
+                if isinstance(k, bytes) :
+                    k = k.decode(charset)
+                v = (k, v.decode(charset))
+            return v
+
+        def get_both(self, key, value) :
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            if isinstance(value, str) :
+                value = bytes(value, charset)
+            v=self._dbcursor.get_both(key, value)
+            return self._fix(v)
+
+    class dup_cursor_py3k(cursor_py3k) :
+        def __init__(self, dbcursor) :
+            self._dbcursor = dbcursor
+
+    class DB_py3k(object) :
+        def __init__(self, *args, **kwargs) :
+            args2=[]
+            for i in args :
+                if isinstance(i, DBEnv_py3k) :
+                    i = i._dbenv
+                args2.append(i)
+            args = tuple(args2)
+            for k, v in kwargs.items() :
+                if isinstance(v, DBEnv_py3k) :
+                    kwargs[k] = v._dbenv
+
+            self._db = bsddb._db.DB_orig(*args, **kwargs)
+
+        def __contains__(self, k) :
+            if isinstance(k, str) :
+                k = bytes(k, charset)
+            return getattr(self._db, "has_key")(k)
+
+        def __getitem__(self, k) :
+            if isinstance(k, str) :
+                k = bytes(k, charset)
+            v = self._db[k]
+            if v is not None :
+                v = v.decode(charset)
+            return v
+
+        def __setitem__(self, k, v) :
+            if isinstance(k, str) :
+                k = bytes(k, charset)
+            if isinstance(v, str) :
+                v = bytes(v, charset)
+            self._db[k] = v
+
+        def __delitem__(self, k) :
+            if isinstance(k, str) :
+                k = bytes(k, charset)
+            del self._db[k]
+
+        def __getattr__(self, v) :
+            return getattr(self._db, v)
+
+        def __len__(self) :
+            return len(self._db)
+
+        def has_key(self, k, txn=None) :
+            if isinstance(k, str) :
+                k = bytes(k, charset)
+            return self._db.has_key(k, txn=txn)
+
+        def put(self, key, value, txn=None, flags=0, dlen=-1, doff=-1) :
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            if isinstance(value, str) :
+                value = bytes(value, charset)
+            return self._db.put(key, value, flags=flags, txn=txn, dlen=dlen,
+                    doff=doff)
+
+        def append(self, value, txn=None) :
+            if isinstance(value, str) :
+                value = bytes(value, charset)
+            return self._db.append(value, txn=txn)
+
+        def get_size(self, key) :
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            return self._db.get_size(key)
+
+        def get(self, key, default="MagicCookie", txn=None, flags=0, dlen=-1, doff=-1) :
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            if default != "MagicCookie" :  # Magic for 'test_get_none.py'
+                v=self._db.get(key, default=default, txn=txn, flags=flags,
+                        dlen=dlen, doff=doff)
+            else :
+                v=self._db.get(key, txn=txn, flags=flags,
+                        dlen=dlen, doff=doff)
+            if (v is not None) and isinstance(v, bytes) :
+                v = v.decode(charset)
+            return v
+
+        def pget(self, key, txn=None) :
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            v=self._db.pget(key, txn=txn)
+            if v is not None :
+                v1, v2 = v
+                if isinstance(v1, bytes) :
+                    v1 = v1.decode(charset)
+
+                v = (v1, v2.decode(charset))
+            return v
+
+        def get_both(self, key, value, txn=None, flags=0) :
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            if isinstance(value, str) :
+                value = bytes(value, charset)
+            v=self._db.get_both(key, value, txn=txn, flags=flags)
+            if v is not None :
+                v = v.decode(charset)
+            return v
+
+        def delete(self, key, txn=None) :
+            if isinstance(key, str) :
+                key = bytes(key, charset)
+            return self._db.delete(key, txn=txn)
+
+        def keys(self) :
+            k = self._db.keys()
+            if len(k) and isinstance(k[0], bytes) :
+                return [i.decode(charset) for i in self._db.keys()]
+            else :
+                return k
+
+        def items(self) :
+            data = self._db.items()
+            if not len(data) : return data
+            data2 = []
+            for k, v in data :
+                if isinstance(k, bytes) :
+                    k = k.decode(charset)
+                data2.append((k, v.decode(charset)))
+            return data2
+
+        def associate(self, secondarydb, callback, flags=0, txn=None) :
+            class associate_callback(object) :
+                def __init__(self, callback) :
+                    self._callback = callback
+
+                def callback(self, key, data) :
+                    if isinstance(key, str) :
+                        key = key.decode(charset)
+                    data = data.decode(charset)
+                    key = self._callback(key, data)
+                    if (key != bsddb._db.DB_DONOTINDEX) and isinstance(key,
+                            str) :
+                        key = bytes(key, charset)
+                    return key
+
+            return self._db.associate(secondarydb._db,
+                    associate_callback(callback).callback, flags=flags, txn=txn)
+
+        def cursor(self, txn=None, flags=0) :
+            return cursor_py3k(self._db, txn=txn, flags=flags)
+
+        def join(self, cursor_list) :
+            cursor_list = [i._dbcursor for i in cursor_list]
+            return dup_cursor_py3k(self._db.join(cursor_list))
+
+    class DBEnv_py3k(object) :
+        def __init__(self, *args, **kwargs) :
+            self._dbenv = bsddb._db.DBEnv_orig(*args, **kwargs)
+
+        def __getattr__(self, v) :
+            return getattr(self._dbenv, v)
+
+    class DBSequence_py3k(object) :
+        def __init__(self, db, *args, **kwargs) :
+            self._db=db
+            self._dbsequence = bsddb._db.DBSequence_orig(db._db, *args, **kwargs)
+
+        def __getattr__(self, v) :
+            return getattr(self._dbsequence, v)
+
+        def open(self, key, *args, **kwargs) :
+            return self._dbsequence.open(bytes(key, charset), *args, **kwargs)
+
+        def get_key(self) :
+            return  self._dbsequence.get_key().decode(charset)
+
+        def get_dbp(self) :
+            return self._db
+
+    import string
+    string.letters=[chr(i) for i in xrange(65,91)]
+
+    bsddb._db.DBEnv_orig = bsddb._db.DBEnv
+    bsddb._db.DB_orig = bsddb._db.DB
+    bsddb._db.DBSequence_orig = bsddb._db.DBSequence
+
+    def do_proxy_db_py3k(flag) :
+        flag2 = do_proxy_db_py3k.flag
+        do_proxy_db_py3k.flag = flag
+        if flag :
+            bsddb.DBEnv = bsddb.db.DBEnv = bsddb._db.DBEnv = DBEnv_py3k
+            bsddb.DB = bsddb.db.DB = bsddb._db.DB = DB_py3k
+            bsddb._db.DBSequence = DBSequence_py3k
+        else :
+            bsddb.DBEnv = bsddb.db.DBEnv = bsddb._db.DBEnv = bsddb._db.DBEnv_orig
+            bsddb.DB = bsddb.db.DB = bsddb._db.DB = bsddb._db.DB_orig
+            bsddb._db.DBSequence = bsddb._db.DBSequence_orig
+        return flag2
+
+    do_proxy_db_py3k.flag = False
+    do_proxy_db_py3k(True)
+
+try:
+    # For Pythons w/distutils pybsddb
+    from bsddb3 import db, dbtables, dbutils, dbshelve, \
+            hashopen, btopen, rnopen, dbobj
+except ImportError:
+    # For Python 2.3
+    from bsddb import db, dbtables, dbutils, dbshelve, \
+            hashopen, btopen, rnopen, dbobj
+
+try:
+    from bsddb3 import test_support
+except ImportError:
+    if sys.version_info[0] < 3 :
+        from test import test_support
+    else :
+        from test import support as test_support
+
+
+try:
+    if sys.version_info[0] < 3 :
+        from threading import Thread, currentThread
+        del Thread, currentThread
+    else :
+        from threading import Thread, current_thread
+        del Thread, current_thread
+    have_threads = True
+except ImportError:
+    have_threads = False
 
 verbose = 0
 if 'verbose' in sys.argv:
@@ -28,11 +396,71 @@ def print_versions():
     print 'bsddb.db.version():   %s' % (db.version(), )
     print 'bsddb.db.__version__: %s' % db.__version__
     print 'bsddb.db.cvsid:       %s' % db.cvsid
+    print 'py module:            %s' % bsddb.__file__
+    print 'extension module:     %s' % bsddb._bsddb.__file__
     print 'python version:       %s' % sys.version
     print 'My pid:               %s' % os.getpid()
     print '-=' * 38
 
 
+def get_new_path(name) :
+    get_new_path.mutex.acquire()
+    try :
+        import os
+        path=os.path.join(get_new_path.prefix,
+                name+"_"+str(os.getpid())+"_"+str(get_new_path.num))
+        get_new_path.num+=1
+    finally :
+        get_new_path.mutex.release()
+    return path
+
+def get_new_environment_path() :
+    path=get_new_path("environment")
+    import os
+    try:
+        os.makedirs(path,mode=0700)
+    except os.error:
+        test_support.rmtree(path)
+        os.makedirs(path)
+    return path
+
+def get_new_database_path() :
+    path=get_new_path("database")
+    import os
+    if os.path.exists(path) :
+        os.remove(path)
+    return path
+
+
+# This path can be overriden via "set_test_path_prefix()".
+import os, os.path
+get_new_path.prefix=os.path.join(os.sep,"tmp","z-Berkeley_DB")
+get_new_path.num=0
+
+def get_test_path_prefix() :
+    return get_new_path.prefix
+
+def set_test_path_prefix(path) :
+    get_new_path.prefix=path
+
+def remove_test_path_directory() :
+    test_support.rmtree(get_new_path.prefix)
+
+if have_threads :
+    import threading
+    get_new_path.mutex=threading.Lock()
+    del threading
+else :
+    class Lock(object) :
+        def acquire(self) :
+            pass
+        def release(self) :
+            pass
+    get_new_path.mutex=Lock()
+    del Lock
+
+
+
 class PrintInfoFakeTest(unittest.TestCase):
     def testPrintVersions(self):
         print_versions()
@@ -41,26 +469,26 @@ class PrintInfoFakeTest(unittest.TestCase):
 # This little hack is for when this module is run as main and all the
 # other modules import it so they will still be able to get the right
 # verbose setting.  It's confusing but it works.
-import test_all
-test_all.verbose = verbose
-
+if sys.version_info[0] < 3 :
+    import test_all
+    test_all.verbose = verbose
+else :
+    import sys
+    print >>sys.stderr, "Work to do!"
 
-def suite():
-    try:
-        # this is special, it used to segfault the interpreter
-        import test_1413192
-    except:
-        pass
 
+def suite(module_prefix='', timing_check=None):
     test_modules = [
         'test_associate',
         'test_basics',
-        'test_compat',
         'test_compare',
+        'test_compat',
+        'test_cursor_pget_bug',
         'test_dbobj',
         'test_dbshelve',
         'test_dbtables',
-        'test_env_close',
+        'test_distributed_transactions',
+        'test_early_close',
         'test_get_none',
         'test_join',
         'test_lock',
@@ -68,15 +496,21 @@ def suite():
         'test_pickle',
         'test_queue',
         'test_recno',
-        'test_thread',
+        'test_replication',
         'test_sequence',
-        'test_cursor_pget_bug',
+        'test_thread',
         ]
 
     alltests = unittest.TestSuite()
     for name in test_modules:
-        module = __import__(name)
+        #module = __import__(name)
+        # Do it this way so that suite may be called externally via
+        # python's Lib/test/test_bsddb3.
+        module = __import__(module_prefix+name, globals(), locals(), name)
+
         alltests.addTest(module.test_suite())
+        if timing_check:
+            alltests.addTest(unittest.makeSuite(timing_check))
     return alltests
 
 
diff --git a/Lib/bsddb/test/test_associate.py b/Lib/bsddb/test/test_associate.py
index 05ef83c..c0da3e8 100644
--- a/Lib/bsddb/test/test_associate.py
+++ b/Lib/bsddb/test/test_associate.py
@@ -3,25 +3,12 @@ TestCases for DB.associate.
 """
 
 import sys, os, string
-import tempfile
 import time
 from pprint import pprint
 
-try:
-    from threading import Thread, currentThread
-    have_threads = 1
-except ImportError:
-    have_threads = 0
-
 import unittest
-from test_all import verbose
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, dbshelve
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, dbshelve
+from test_all import db, dbshelve, test_support, verbose, have_threads, \
+        get_new_environment_path
 
 
 #----------------------------------------------------------------------
@@ -91,26 +78,14 @@ musicdata = {
 class AssociateErrorTestCase(unittest.TestCase):
     def setUp(self):
         self.filename = self.__class__.__name__ + '.db'
-        homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try:
-            os.mkdir(homeDir)
-        except os.error:
-            import glob
-            files = glob.glob(os.path.join(self.homeDir, '*'))
-            for file in files:
-                os.remove(file)
+        self.homeDir = get_new_environment_path()
         self.env = db.DBEnv()
-        self.env.open(homeDir, db.DB_CREATE | db.DB_INIT_MPOOL)
+        self.env.open(self.homeDir, db.DB_CREATE | db.DB_INIT_MPOOL)
 
     def tearDown(self):
         self.env.close()
         self.env = None
-        import glob
-        files = glob.glob(os.path.join(self.homeDir, '*'))
-        for file in files:
-            os.remove(file)
-
+        test_support.rmtree(self.homeDir)
 
     def test00_associateDBError(self):
         if verbose:
@@ -126,7 +101,7 @@ class AssociateErrorTestCase(unittest.TestCase):
         secDB.open(self.filename, "secondary", db.DB_BTREE, db.DB_CREATE)
 
         # dupDB has been configured to allow duplicates, it can't
-        # associate with a secondary.  BerkeleyDB will return an error.
+        # associate with a secondary.  Berkeley DB will return an error.
         try:
             def f(a,b): return a+b
             dupDB.associate(secDB, f)
@@ -151,33 +126,22 @@ class AssociateTestCase(unittest.TestCase):
 
     def setUp(self):
         self.filename = self.__class__.__name__ + '.db'
-        homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try:
-            os.mkdir(homeDir)
-        except os.error:
-            import glob
-            files = glob.glob(os.path.join(self.homeDir, '*'))
-            for file in files:
-                os.remove(file)
+        self.homeDir = get_new_environment_path()
         self.env = db.DBEnv()
-        self.env.open(homeDir, db.DB_CREATE | db.DB_INIT_MPOOL |
+        self.env.open(self.homeDir, db.DB_CREATE | db.DB_INIT_MPOOL |
                                db.DB_INIT_LOCK | db.DB_THREAD | self.envFlags)
 
     def tearDown(self):
         self.closeDB()
         self.env.close()
         self.env = None
-        import glob
-        files = glob.glob(os.path.join(self.homeDir, '*'))
-        for file in files:
-            os.remove(file)
+        test_support.rmtree(self.homeDir)
 
     def addDataToDB(self, d, txn=None):
         for key, value in musicdata.items():
             if type(self.keytype) == type(''):
                 key = "%02d" % key
-            d.put(key, string.join(value, '|'), txn=txn)
+            d.put(key, '|'.join(value), txn=txn)
 
     def createDB(self, txn=None):
         self.cur = None
@@ -248,10 +212,10 @@ class AssociateTestCase(unittest.TestCase):
     def finish_test(self, secDB, txn=None):
         # 'Blues' should not be in the secondary database
         vals = secDB.pget('Blues', txn=txn)
-        assert vals == None, vals
+        self.assertEqual(vals, None, vals)
 
         vals = secDB.pget('Unknown', txn=txn)
-        assert vals[0] == 99 or vals[0] == '99', vals
+        self.assert_(vals[0] == 99 or vals[0] == '99', vals)
         vals[1].index('Unknown')
         vals[1].index('Unnamed')
         vals[1].index('unknown')
@@ -263,14 +227,14 @@ class AssociateTestCase(unittest.TestCase):
         rec = self.cur.first()
         while rec is not None:
             if type(self.keytype) == type(''):
-                assert string.atoi(rec[0])  # for primary db, key is a number
+                self.assert_(int(rec[0]))  # for primary db, key is a number
             else:
-                assert rec[0] and type(rec[0]) == type(0)
+                self.assert_(rec[0] and type(rec[0]) == type(0))
             count = count + 1
             if verbose:
                 print rec
-            rec = self.cur.next()
-        assert count == len(musicdata) # all items accounted for
+            rec = getattr(self.cur, "next")()
+        self.assertEqual(count, len(musicdata))  # all items accounted for
 
 
         if verbose:
@@ -280,32 +244,34 @@ class AssociateTestCase(unittest.TestCase):
 
         # test cursor pget
         vals = self.cur.pget('Unknown', flags=db.DB_LAST)
-        assert vals[1] == 99 or vals[1] == '99', vals
-        assert vals[0] == 'Unknown'
+        self.assert_(vals[1] == 99 or vals[1] == '99', vals)
+        self.assertEqual(vals[0], 'Unknown')
         vals[2].index('Unknown')
         vals[2].index('Unnamed')
         vals[2].index('unknown')
 
         vals = self.cur.pget('Unknown', data='wrong value', flags=db.DB_GET_BOTH)
-        assert vals == None, vals
+        self.assertEqual(vals, None, vals)
 
         rec = self.cur.first()
-        assert rec[0] == "Jazz"
+        self.assertEqual(rec[0], "Jazz")
         while rec is not None:
             count = count + 1
             if verbose:
                 print rec
-            rec = self.cur.next()
+            rec = getattr(self.cur, "next")()
         # all items accounted for EXCEPT for 1 with "Blues" genre
-        assert count == len(musicdata)-1
+        self.assertEqual(count, len(musicdata)-1)
 
         self.cur = None
 
     def getGenre(self, priKey, priData):
-        assert type(priData) == type("")
+        self.assertEqual(type(priData), type(""))
+        genre = priData.split('|')[2]
+
         if verbose:
             print 'getGenre key: %r data: %r' % (priKey, priData)
-        genre = string.split(priData, '|')[2]
+
         if genre == 'Blues':
             return db.DB_DONOTINDEX
         else:
@@ -387,7 +353,7 @@ class ShelveAssociateTestCase(AssociateTestCase):
 
 
     def getGenre(self, priKey, priData):
-        assert type(priData) == type(())
+        self.assertEqual(type(priData), type(()))
         if verbose:
             print 'getGenre key: %r data: %r' % (priKey, priData)
         genre = priData[2]
@@ -418,6 +384,8 @@ class ThreadedAssociateTestCase(AssociateTestCase):
         t2 = Thread(target = self.writer2,
                     args = (d, ))
 
+        t1.setDaemon(True)
+        t2.setDaemon(True)
         t1.start()
         t2.start()
         t1.join()
@@ -427,13 +395,13 @@ class ThreadedAssociateTestCase(AssociateTestCase):
         for key, value in musicdata.items():
             if type(self.keytype) == type(''):
                 key = "%02d" % key
-            d.put(key, string.join(value, '|'))
+            d.put(key, '|'.join(value))
 
     def writer2(self, d):
         for x in range(100, 600):
             key = 'z%2d' % x
             value = [key] * 4
-            d.put(key, string.join(value, '|'))
+            d.put(key, '|'.join(value))
 
 
 class ThreadedAssociateHashTestCase(ShelveAssociateTestCase):
@@ -452,24 +420,23 @@ class ThreadedAssociateRecnoTestCase(ShelveAssociateTestCase):
 def test_suite():
     suite = unittest.TestSuite()
 
-    if db.version() >= (3, 3, 11):
-        suite.addTest(unittest.makeSuite(AssociateErrorTestCase))
+    suite.addTest(unittest.makeSuite(AssociateErrorTestCase))
 
-        suite.addTest(unittest.makeSuite(AssociateHashTestCase))
-        suite.addTest(unittest.makeSuite(AssociateBTreeTestCase))
-        suite.addTest(unittest.makeSuite(AssociateRecnoTestCase))
+    suite.addTest(unittest.makeSuite(AssociateHashTestCase))
+    suite.addTest(unittest.makeSuite(AssociateBTreeTestCase))
+    suite.addTest(unittest.makeSuite(AssociateRecnoTestCase))
 
-        if db.version() >= (4, 1):
-            suite.addTest(unittest.makeSuite(AssociateBTreeTxnTestCase))
+    if db.version() >= (4, 1):
+        suite.addTest(unittest.makeSuite(AssociateBTreeTxnTestCase))
 
-        suite.addTest(unittest.makeSuite(ShelveAssociateHashTestCase))
-        suite.addTest(unittest.makeSuite(ShelveAssociateBTreeTestCase))
-        suite.addTest(unittest.makeSuite(ShelveAssociateRecnoTestCase))
+    suite.addTest(unittest.makeSuite(ShelveAssociateHashTestCase))
+    suite.addTest(unittest.makeSuite(ShelveAssociateBTreeTestCase))
+    suite.addTest(unittest.makeSuite(ShelveAssociateRecnoTestCase))
 
-        if have_threads:
-            suite.addTest(unittest.makeSuite(ThreadedAssociateHashTestCase))
-            suite.addTest(unittest.makeSuite(ThreadedAssociateBTreeTestCase))
-            suite.addTest(unittest.makeSuite(ThreadedAssociateRecnoTestCase))
+    if have_threads:
+        suite.addTest(unittest.makeSuite(ThreadedAssociateHashTestCase))
+        suite.addTest(unittest.makeSuite(ThreadedAssociateBTreeTestCase))
+        suite.addTest(unittest.makeSuite(ThreadedAssociateRecnoTestCase))
 
     return suite
 
diff --git a/Lib/bsddb/test/test_basics.py b/Lib/bsddb/test/test_basics.py
index e6022ba..21b1f8f 100644
--- a/Lib/bsddb/test/test_basics.py
+++ b/Lib/bsddb/test/test_basics.py
@@ -4,23 +4,14 @@ various DB flags, etc.
 """
 
 import os
-import sys
 import errno
-import shutil
 import string
-import tempfile
 from pprint import pprint
 import unittest
 import time
 
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db
-except ImportError:
-    # For Python 2.3
-    from bsddb import db
-
-from test_all import verbose
+from test_all import db, test_support, verbose, get_new_environment_path, \
+        get_new_database_path
 
 DASH = '-'
 
@@ -35,8 +26,8 @@ class VersionTestCase(unittest.TestCase):
             print 'bsddb.db.version(): %s' % (info, )
             print db.DB_VERSION_STRING
             print '-=' * 20
-        assert info == (db.DB_VERSION_MAJOR, db.DB_VERSION_MINOR,
-                        db.DB_VERSION_PATCH)
+        self.assertEqual(info, (db.DB_VERSION_MAJOR, db.DB_VERSION_MINOR,
+                        db.DB_VERSION_PATCH))
 
 #----------------------------------------------------------------------
 
@@ -54,31 +45,22 @@ class BasicTestCase(unittest.TestCase):
 
     def setUp(self):
         if self.useEnv:
-            homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-            self.homeDir = homeDir
-            try:
-                shutil.rmtree(homeDir)
-            except OSError, e:
-                # unix returns ENOENT, windows returns ESRCH
-                if e.errno not in (errno.ENOENT, errno.ESRCH): raise
-            os.mkdir(homeDir)
+            self.homeDir=get_new_environment_path()
             try:
                 self.env = db.DBEnv()
                 self.env.set_lg_max(1024*1024)
                 self.env.set_tx_max(30)
                 self.env.set_tx_timestamp(int(time.time()))
                 self.env.set_flags(self.envsetflags, 1)
-                self.env.open(homeDir, self.envflags | db.DB_CREATE)
-                tempfile.tempdir = homeDir
-                self.filename = os.path.split(tempfile.mktemp())[1]
-                tempfile.tempdir = None
+                self.env.open(self.homeDir, self.envflags | db.DB_CREATE)
+                self.filename = "test"
             # Yes, a bare except is intended, since we're re-raising the exc.
             except:
-                shutil.rmtree(homeDir)
+                test_support.rmtree(self.homeDir)
                 raise
         else:
             self.env = None
-            self.filename = tempfile.mktemp()
+            self.filename = get_new_database_path()
 
         # create and open the DB
         self.d = db.DB(self.env)
@@ -99,13 +81,7 @@ class BasicTestCase(unittest.TestCase):
         self.d.close()
         if self.env is not None:
             self.env.close()
-            shutil.rmtree(self.homeDir)
-            ## Make a new DBEnv to remove the env files from the home dir.
-            ## (It can't be done while the env is open, nor after it has been
-            ## closed, so we make a new one to do it.)
-            #e = db.DBEnv()
-            #e.remove(self.homeDir)
-            #os.remove(os.path.join(self.homeDir, self.filename))
+            test_support.rmtree(self.homeDir)
         else:
             os.remove(self.filename)
 
@@ -114,14 +90,14 @@ class BasicTestCase(unittest.TestCase):
     def populateDB(self, _txn=None):
         d = self.d
 
-        for x in range(self._numKeys/2):
+        for x in range(self._numKeys//2):
             key = '%04d' % (self._numKeys - x)  # insert keys in reverse order
             data = self.makeData(key)
             d.put(key, data, _txn)
 
         d.put('empty value', '', _txn)
 
-        for x in range(self._numKeys/2-1):
+        for x in range(self._numKeys//2-1):
             key = '%04d' % x  # and now some in forward order
             data = self.makeData(key)
             d.put(key, data, _txn)
@@ -153,44 +129,44 @@ class BasicTestCase(unittest.TestCase):
             if verbose:
                 print data
 
-        assert d.get('0321') == '0321-0321-0321-0321-0321'
+        self.assertEqual(d.get('0321'), '0321-0321-0321-0321-0321')
 
-        # By default non-existant keys return None...
-        assert d.get('abcd') == None
+        # By default non-existent keys return None...
+        self.assertEqual(d.get('abcd'), None)
 
         # ...but they raise exceptions in other situations.  Call
         # set_get_returns_none() to change it.
         try:
             d.delete('abcd')
         except db.DBNotFoundError, val:
-            assert val[0] == db.DB_NOTFOUND
+            self.assertEqual(val.args[0], db.DB_NOTFOUND)
             if verbose: print val
         else:
             self.fail("expected exception")
 
 
         d.put('abcd', 'a new record')
-        assert d.get('abcd') == 'a new record'
+        self.assertEqual(d.get('abcd'), 'a new record')
 
         d.put('abcd', 'same key')
         if self.dbsetflags & db.DB_DUP:
-            assert d.get('abcd') == 'a new record'
+            self.assertEqual(d.get('abcd'), 'a new record')
         else:
-            assert d.get('abcd') == 'same key'
+            self.assertEqual(d.get('abcd'), 'same key')
 
 
         try:
             d.put('abcd', 'this should fail', flags=db.DB_NOOVERWRITE)
         except db.DBKeyExistError, val:
-            assert val[0] == db.DB_KEYEXIST
+            self.assertEqual(val.args[0], db.DB_KEYEXIST)
             if verbose: print val
         else:
             self.fail("expected exception")
 
         if self.dbsetflags & db.DB_DUP:
-            assert d.get('abcd') == 'a new record'
+            self.assertEqual(d.get('abcd'), 'a new record')
         else:
-            assert d.get('abcd') == 'same key'
+            self.assertEqual(d.get('abcd'), 'same key')
 
 
         d.sync()
@@ -204,28 +180,28 @@ class BasicTestCase(unittest.TestCase):
             self.d.open(self.filename)
         d = self.d
 
-        assert d.get('0321') == '0321-0321-0321-0321-0321'
+        self.assertEqual(d.get('0321'), '0321-0321-0321-0321-0321')
         if self.dbsetflags & db.DB_DUP:
-            assert d.get('abcd') == 'a new record'
+            self.assertEqual(d.get('abcd'), 'a new record')
         else:
-            assert d.get('abcd') == 'same key'
+            self.assertEqual(d.get('abcd'), 'same key')
 
         rec = d.get_both('0555', '0555-0555-0555-0555-0555')
         if verbose:
             print rec
 
-        assert d.get_both('0555', 'bad data') == None
+        self.assertEqual(d.get_both('0555', 'bad data'), None)
 
         # test default value
         data = d.get('bad key', 'bad data')
-        assert data == 'bad data'
+        self.assertEqual(data, 'bad data')
 
         # any object can pass through
         data = d.get('bad key', self)
-        assert data == self
+        self.assertEqual(data, self)
 
         s = d.stat()
-        assert type(s) == type({})
+        self.assertEqual(type(s), type({}))
         if verbose:
             print 'd.stat() returned this dictionary:'
             pprint(s)
@@ -243,47 +219,49 @@ class BasicTestCase(unittest.TestCase):
 
         for key in ['0002', '0101', '0401', '0701', '0998']:
             data = d[key]
-            assert data == self.makeData(key)
+            self.assertEqual(data, self.makeData(key))
             if verbose:
                 print data
 
-        assert len(d) == self._numKeys
+        self.assertEqual(len(d), self._numKeys)
         keys = d.keys()
-        assert len(keys) == self._numKeys
-        assert type(keys) == type([])
+        self.assertEqual(len(keys), self._numKeys)
+        self.assertEqual(type(keys), type([]))
 
         d['new record'] = 'a new record'
-        assert len(d) == self._numKeys+1
+        self.assertEqual(len(d), self._numKeys+1)
         keys = d.keys()
-        assert len(keys) == self._numKeys+1
+        self.assertEqual(len(keys), self._numKeys+1)
 
         d['new record'] = 'a replacement record'
-        assert len(d) == self._numKeys+1
+        self.assertEqual(len(d), self._numKeys+1)
         keys = d.keys()
-        assert len(keys) == self._numKeys+1
+        self.assertEqual(len(keys), self._numKeys+1)
 
         if verbose:
             print "the first 10 keys are:"
             pprint(keys[:10])
 
-        assert d['new record'] == 'a replacement record'
+        self.assertEqual(d['new record'], 'a replacement record')
 
-        assert d.has_key('0001') == 1
-        assert d.has_key('spam') == 0
+# We check also the positional parameter
+        self.assertEqual(d.has_key('0001', None), 1)
+# We check also the keyword parameter
+        self.assertEqual(d.has_key('spam', txn=None), 0)
 
         items = d.items()
-        assert len(items) == self._numKeys+1
-        assert type(items) == type([])
-        assert type(items[0]) == type(())
-        assert len(items[0]) == 2
+        self.assertEqual(len(items), self._numKeys+1)
+        self.assertEqual(type(items), type([]))
+        self.assertEqual(type(items[0]), type(()))
+        self.assertEqual(len(items[0]), 2)
 
         if verbose:
             print "the first 10 items are:"
             pprint(items[:10])
 
         values = d.values()
-        assert len(values) == self._numKeys+1
-        assert type(values) == type([])
+        self.assertEqual(len(values), self._numKeys+1)
+        self.assertEqual(type(values), type([]))
 
         if verbose:
             print "the first 10 values are:"
@@ -315,14 +293,15 @@ class BasicTestCase(unittest.TestCase):
                 rec = c.next()
             except db.DBNotFoundError, val:
                 if get_raises_error:
-                    assert val[0] == db.DB_NOTFOUND
+                    self.assertEqual(val.args[0], db.DB_NOTFOUND)
                     if verbose: print val
                     rec = None
                 else:
                     self.fail("unexpected DBNotFoundError")
-            assert c.get_current_size() == len(c.current()[1]), "%s != len(%r)" % (c.get_current_size(), c.current()[1])
+            self.assertEqual(c.get_current_size(), len(c.current()[1]),
+                    "%s != len(%r)" % (c.get_current_size(), c.current()[1]))
 
-        assert count == self._numKeys
+        self.assertEqual(count, self._numKeys)
 
 
         rec = c.last()
@@ -335,49 +314,49 @@ class BasicTestCase(unittest.TestCase):
                 rec = c.prev()
             except db.DBNotFoundError, val:
                 if get_raises_error:
-                    assert val[0] == db.DB_NOTFOUND
+                    self.assertEqual(val.args[0], db.DB_NOTFOUND)
                     if verbose: print val
                     rec = None
                 else:
                     self.fail("unexpected DBNotFoundError")
 
-        assert count == self._numKeys
+        self.assertEqual(count, self._numKeys)
 
         rec = c.set('0505')
         rec2 = c.current()
-        assert rec == rec2
-        assert rec[0] == '0505'
-        assert rec[1] == self.makeData('0505')
-        assert c.get_current_size() == len(rec[1])
+        self.assertEqual(rec, rec2)
+        self.assertEqual(rec[0], '0505')
+        self.assertEqual(rec[1], self.makeData('0505'))
+        self.assertEqual(c.get_current_size(), len(rec[1]))
 
         # make sure we get empty values properly
         rec = c.set('empty value')
-        assert rec[1] == ''
-        assert c.get_current_size() == 0
+        self.assertEqual(rec[1], '')
+        self.assertEqual(c.get_current_size(), 0)
 
         try:
             n = c.set('bad key')
         except db.DBNotFoundError, val:
-            assert val[0] == db.DB_NOTFOUND
+            self.assertEqual(val.args[0], db.DB_NOTFOUND)
             if verbose: print val
         else:
             if set_raises_error:
                 self.fail("expected exception")
-            if n != None:
+            if n is not None:
                 self.fail("expected None: %r" % (n,))
 
         rec = c.get_both('0404', self.makeData('0404'))
-        assert rec == ('0404', self.makeData('0404'))
+        self.assertEqual(rec, ('0404', self.makeData('0404')))
 
         try:
             n = c.get_both('0404', 'bad data')
         except db.DBNotFoundError, val:
-            assert val[0] == db.DB_NOTFOUND
+            self.assertEqual(val.args[0], db.DB_NOTFOUND)
             if verbose: print val
         else:
             if get_raises_error:
                 self.fail("expected exception")
-            if n != None:
+            if n is not None:
                 self.fail("expected None: %r" % (n,))
 
         if self.d.get_type() == db.DB_BTREE:
@@ -401,7 +380,7 @@ class BasicTestCase(unittest.TestCase):
             rec = c.current()
         except db.DBKeyEmptyError, val:
             if get_raises_error:
-                assert val[0] == db.DB_KEYEMPTY
+                self.assertEqual(val.args[0], db.DB_KEYEMPTY)
                 if verbose: print val
             else:
                 self.fail("unexpected DBKeyEmptyError")
@@ -411,14 +390,14 @@ class BasicTestCase(unittest.TestCase):
 
         c.next()
         c2 = c.dup(db.DB_POSITION)
-        assert c.current() == c2.current()
+        self.assertEqual(c.current(), c2.current())
 
         c2.put('', 'a new value', db.DB_CURRENT)
-        assert c.current() == c2.current()
-        assert c.current()[1] == 'a new value'
+        self.assertEqual(c.current(), c2.current())
+        self.assertEqual(c.current()[1], 'a new value')
 
         c2.put('', 'er', db.DB_CURRENT, dlen=0, doff=5)
-        assert c2.current()[1] == 'a newer value'
+        self.assertEqual(c2.current()[1], 'a newer value')
 
         c.close()
         c2.close()
@@ -444,9 +423,9 @@ class BasicTestCase(unittest.TestCase):
                     print "attempting to use a closed cursor's %s method" % \
                           method
                 # a bug may cause a NULL pointer dereference...
-                apply(getattr(c, method), args)
+                getattr(c, method)(*args)
             except db.DBError, val:
-                assert val[0] == 0
+                self.assertEqual(val.args[0], 0)
                 if verbose: print val
             else:
                 self.fail("no exception raised when using a buggy cursor's"
@@ -471,7 +450,7 @@ class BasicTestCase(unittest.TestCase):
                   self.__class__.__name__
 
         old = self.d.set_get_returns_none(0)
-        assert old == 2
+        self.assertEqual(old, 2)
         self.test03_SimpleCursorStuff(get_raises_error=1, set_raises_error=1)
 
     def test03b_SimpleCursorWithGetReturnsNone1(self):
@@ -493,9 +472,9 @@ class BasicTestCase(unittest.TestCase):
                   self.__class__.__name__
 
         old = self.d.set_get_returns_none(1)
-        assert old == 2
+        self.assertEqual(old, 2)
         old = self.d.set_get_returns_none(2)
-        assert old == 1
+        self.assertEqual(old, 1)
         self.test03_SimpleCursorStuff(get_raises_error=0, set_raises_error=0)
 
     #----------------------------------------
@@ -510,23 +489,24 @@ class BasicTestCase(unittest.TestCase):
         key = "partialTest"
         data = "1" * 1000 + "2" * 1000
         d.put(key, data)
-        assert d.get(key) == data
-        assert d.get(key, dlen=20, doff=990) == ("1" * 10) + ("2" * 10)
+        self.assertEqual(d.get(key), data)
+        self.assertEqual(d.get(key, dlen=20, doff=990),
+                ("1" * 10) + ("2" * 10))
 
         d.put("partialtest2", ("1" * 30000) + "robin" )
-        assert d.get("partialtest2", dlen=5, doff=30000) == "robin"
+        self.assertEqual(d.get("partialtest2", dlen=5, doff=30000), "robin")
 
         # There seems to be a bug in DB here...  Commented out the test for
         # now.
-        ##assert d.get("partialtest2", dlen=5, doff=30010) == ""
+        ##self.assertEqual(d.get("partialtest2", dlen=5, doff=30010), "")
 
         if self.dbsetflags != db.DB_DUP:
             # Partial put with duplicate records requires a cursor
             d.put(key, "0000", dlen=2000, doff=0)
-            assert d.get(key) == "0000"
+            self.assertEqual(d.get(key), "0000")
 
             d.put(key, "1111", dlen=1, doff=2)
-            assert d.get(key) == "0011110"
+            self.assertEqual(d.get(key), "0011110")
 
     #----------------------------------------
 
@@ -541,16 +521,12 @@ class BasicTestCase(unittest.TestCase):
             #print "before ", i,
             d.put(key, "1" * i)
             #print "after",
-            assert d.get_size(key) == i
+            self.assertEqual(d.get_size(key), i)
             #print "done"
 
     #----------------------------------------
 
     def test06_Truncate(self):
-        if db.version() < (3,3):
-            # truncate is a feature of BerkeleyDB 3.3 and above
-            return
-
         d = self.d
         if verbose:
             print '\n', '-=' * 30
@@ -558,9 +534,19 @@ class BasicTestCase(unittest.TestCase):
 
         d.put("abcde", "ABCDE");
         num = d.truncate()
-        assert num >= 1, "truncate returned <= 0 on non-empty database"
+        self.assert_(num >= 1, "truncate returned <= 0 on non-empty database")
         num = d.truncate()
-        assert num == 0, "truncate on empty DB returned nonzero (%r)" % (num,)
+        self.assertEqual(num, 0,
+                "truncate on empty DB returned nonzero (%r)" % (num,))
+
+    #----------------------------------------
+
+    def test07_verify(self):
+        # Verify bug solved in 4.7.3pre8
+        self.d.close()
+        d = db.DB(self.env)
+        d.verify(self.filename)
+
 
     #----------------------------------------
 
@@ -593,13 +579,13 @@ class BasicWithEnvTestCase(BasicTestCase):
 
     #----------------------------------------
 
-    def test07_EnvRemoveAndRename(self):
+    def test08_EnvRemoveAndRename(self):
         if not self.env:
             return
 
         if verbose:
             print '\n', '-=' * 30
-            print "Running %s.test07_EnvRemoveAndRename..." % self.__class__.__name__
+            print "Running %s.test08_EnvRemoveAndRename..." % self.__class__.__name__
 
         # can't rename or remove an open DB
         self.d.close()
@@ -610,7 +596,7 @@ class BasicWithEnvTestCase(BasicTestCase):
 
     # dbremove and dbrename are in 4.1 and later
     if db.version() < (4,1):
-        del test07_EnvRemoveAndRename
+        del test08_EnvRemoveAndRename
 
     #----------------------------------------
 
@@ -625,6 +611,11 @@ class BasicHashWithEnvTestCase(BasicWithEnvTestCase):
 #----------------------------------------------------------------------
 
 class BasicTransactionTestCase(BasicTestCase):
+    import sys
+    if sys.version_info[:3] < (2, 4, 0):
+        def assertTrue(self, expr, msg=None):
+            self.failUnless(expr,msg=msg)
+
     dbopenflags = db.DB_THREAD | db.DB_AUTO_COMMIT
     useEnv = 1
     envflags = (db.DB_THREAD | db.DB_INIT_MPOOL | db.DB_INIT_LOCK |
@@ -650,19 +641,21 @@ class BasicTransactionTestCase(BasicTestCase):
             print '\n', '-=' * 30
             print "Running %s.test06_Transactions..." % self.__class__.__name__
 
-        assert d.get('new rec', txn=self.txn) == None
+        self.assertEqual(d.get('new rec', txn=self.txn), None)
         d.put('new rec', 'this is a new record', self.txn)
-        assert d.get('new rec', txn=self.txn) == 'this is a new record'
+        self.assertEqual(d.get('new rec', txn=self.txn),
+                'this is a new record')
         self.txn.abort()
-        assert d.get('new rec') == None
+        self.assertEqual(d.get('new rec'), None)
 
         self.txn = self.env.txn_begin()
 
-        assert d.get('new rec', txn=self.txn) == None
+        self.assertEqual(d.get('new rec', txn=self.txn), None)
         d.put('new rec', 'this is a new record', self.txn)
-        assert d.get('new rec', txn=self.txn) == 'this is a new record'
+        self.assertEqual(d.get('new rec', txn=self.txn),
+                'this is a new record')
         self.txn.commit()
-        assert d.get('new rec') == 'this is a new record'
+        self.assertEqual(d.get('new rec'), 'this is a new record')
 
         self.txn = self.env.txn_begin()
         c = d.cursor(self.txn)
@@ -673,7 +666,7 @@ class BasicTransactionTestCase(BasicTestCase):
             if verbose and count % 100 == 0:
                 print rec
             rec = c.next()
-        assert count == self._numKeys+1
+        self.assertEqual(count, self._numKeys+1)
 
         c.close()                # Cursors *MUST* be closed before commit!
         self.txn.commit()
@@ -684,48 +677,44 @@ class BasicTransactionTestCase(BasicTestCase):
         except db.DBIncompleteError:
             pass
 
-        if db.version() >= (4,0):
-            statDict = self.env.log_stat(0);
-            assert statDict.has_key('magic')
-            assert statDict.has_key('version')
-            assert statDict.has_key('cur_file')
-            assert statDict.has_key('region_nowait')
+        statDict = self.env.log_stat(0);
+        self.assertTrue('magic' in statDict)
+        self.assertTrue('version' in statDict)
+        self.assertTrue('cur_file' in statDict)
+        self.assertTrue('region_nowait' in statDict)
 
         # must have at least one log file present:
         logs = self.env.log_archive(db.DB_ARCH_ABS | db.DB_ARCH_LOG)
-        assert logs != None
+        self.assertNotEqual(logs, None)
         for log in logs:
             if verbose:
                 print 'log file: ' + log
         if db.version() >= (4,2):
             logs = self.env.log_archive(db.DB_ARCH_REMOVE)
-            assert not logs
+            self.assertTrue(not logs)
 
         self.txn = self.env.txn_begin()
 
     #----------------------------------------
 
-    def test07_TxnTruncate(self):
-        if db.version() < (3,3):
-            # truncate is a feature of BerkeleyDB 3.3 and above
-            return
-
+    def test08_TxnTruncate(self):
         d = self.d
         if verbose:
             print '\n', '-=' * 30
-            print "Running %s.test07_TxnTruncate..." % self.__class__.__name__
+            print "Running %s.test08_TxnTruncate..." % self.__class__.__name__
 
         d.put("abcde", "ABCDE");
         txn = self.env.txn_begin()
         num = d.truncate(txn)
-        assert num >= 1, "truncate returned <= 0 on non-empty database"
+        self.assert_(num >= 1, "truncate returned <= 0 on non-empty database")
         num = d.truncate(txn)
-        assert num == 0, "truncate on empty DB returned nonzero (%r)" % (num,)
+        self.assertEqual(num, 0,
+                "truncate on empty DB returned nonzero (%r)" % (num,))
         txn.commit()
 
     #----------------------------------------
 
-    def test08_TxnLateUse(self):
+    def test09_TxnLateUse(self):
         txn = self.env.txn_begin()
         txn.abort()
         try:
@@ -759,27 +748,27 @@ class BTreeRecnoTestCase(BasicTestCase):
     dbtype     = db.DB_BTREE
     dbsetflags = db.DB_RECNUM
 
-    def test07_RecnoInBTree(self):
+    def test08_RecnoInBTree(self):
         d = self.d
         if verbose:
             print '\n', '-=' * 30
-            print "Running %s.test07_RecnoInBTree..." % self.__class__.__name__
+            print "Running %s.test08_RecnoInBTree..." % self.__class__.__name__
 
         rec = d.get(200)
-        assert type(rec) == type(())
-        assert len(rec) == 2
+        self.assertEqual(type(rec), type(()))
+        self.assertEqual(len(rec), 2)
         if verbose:
             print "Record #200 is ", rec
 
         c = d.cursor()
         c.set('0200')
         num = c.get_recno()
-        assert type(num) == type(1)
+        self.assertEqual(type(num), type(1))
         if verbose:
             print "recno of d['0200'] is ", num
 
         rec = c.current()
-        assert c.set_recno(num) == rec
+        self.assertEqual(c.set_recno(num), rec)
 
         c.close()
 
@@ -793,11 +782,11 @@ class BTreeRecnoWithThreadFlagTestCase(BTreeRecnoTestCase):
 class BasicDUPTestCase(BasicTestCase):
     dbsetflags = db.DB_DUP
 
-    def test08_DuplicateKeys(self):
+    def test09_DuplicateKeys(self):
         d = self.d
         if verbose:
             print '\n', '-=' * 30
-            print "Running %s.test08_DuplicateKeys..." % \
+            print "Running %s.test09_DuplicateKeys..." % \
                   self.__class__.__name__
 
         d.put("dup0", "before")
@@ -806,23 +795,23 @@ class BasicDUPTestCase(BasicTestCase):
         d.put("dup2", "after")
 
         data = d.get("dup1")
-        assert data == "The"
+        self.assertEqual(data, "The")
         if verbose:
             print data
 
         c = d.cursor()
         rec = c.set("dup1")
-        assert rec == ('dup1', 'The')
+        self.assertEqual(rec, ('dup1', 'The'))
 
-        next = c.next()
-        assert next == ('dup1', 'quick')
+        next_reg = c.next()
+        self.assertEqual(next_reg, ('dup1', 'quick'))
 
         rec = c.set("dup1")
         count = c.count()
-        assert count == 9
+        self.assertEqual(count, 9)
 
         next_dup = c.next_dup()
-        assert next_dup == ('dup1', 'quick')
+        self.assertEqual(next_dup, ('dup1', 'quick'))
 
         rec = c.set('dup1')
         while rec is not None:
@@ -832,7 +821,7 @@ class BasicDUPTestCase(BasicTestCase):
 
         c.set('dup1')
         rec = c.next_nodup()
-        assert rec[0] != 'dup1'
+        self.assertNotEqual(rec[0], 'dup1')
         if verbose:
             print rec
 
@@ -866,11 +855,11 @@ class BasicMultiDBTestCase(BasicTestCase):
         else:
             return db.DB_BTREE
 
-    def test09_MultiDB(self):
+    def test10_MultiDB(self):
         d1 = self.d
         if verbose:
             print '\n', '-=' * 30
-            print "Running %s.test09_MultiDB..." % self.__class__.__name__
+            print "Running %s.test10_MultiDB..." % self.__class__.__name__
 
         d2 = db.DB(self.env)
         d2.open(self.filename, "second", self.dbtype,
@@ -912,7 +901,7 @@ class BasicMultiDBTestCase(BasicTestCase):
             if verbose and (count % 50) == 0:
                 print rec
             rec = c1.next()
-        assert count == self._numKeys
+        self.assertEqual(count, self._numKeys)
 
         count = 0
         rec = c2.first()
@@ -921,7 +910,7 @@ class BasicMultiDBTestCase(BasicTestCase):
             if verbose:
                 print rec
             rec = c2.next()
-        assert count == 9
+        self.assertEqual(count, 9)
 
         count = 0
         rec = c3.first()
@@ -930,7 +919,7 @@ class BasicMultiDBTestCase(BasicTestCase):
             if verbose:
                 print rec
             rec = c3.next()
-        assert count == 52
+        self.assertEqual(count, len(string.letters))
 
 
         c1.close()
@@ -958,6 +947,66 @@ class HashMultiDBTestCase(BasicMultiDBTestCase):
     envflags = db.DB_THREAD | db.DB_INIT_MPOOL | db.DB_INIT_LOCK
 
 
+class PrivateObject(unittest.TestCase) :
+    import sys
+    if sys.version_info[:3] < (2, 4, 0):
+        def assertTrue(self, expr, msg=None):
+            self.failUnless(expr,msg=msg)
+
+    def tearDown(self) :
+        del self.obj
+
+    def test01_DefaultIsNone(self) :
+        self.assertEqual(self.obj.get_private(), None)
+
+    def test02_assignment(self) :
+        a = "example of private object"
+        self.obj.set_private(a)
+        b = self.obj.get_private()
+        self.assertTrue(a is b)  # Object identity
+
+    def test03_leak_assignment(self) :
+        import sys
+        a = "example of private object"
+        refcount = sys.getrefcount(a)
+        self.obj.set_private(a)
+        self.assertEqual(refcount+1, sys.getrefcount(a))
+        self.obj.set_private(None)
+        self.assertEqual(refcount, sys.getrefcount(a))
+
+    def test04_leak_GC(self) :
+        import sys
+        a = "example of private object"
+        refcount = sys.getrefcount(a)
+        self.obj.set_private(a)
+        self.obj = None
+        self.assertEqual(refcount, sys.getrefcount(a))
+
+class DBEnvPrivateObject(PrivateObject) :
+    def setUp(self) :
+        self.obj = db.DBEnv()
+
+class DBPrivateObject(PrivateObject) :
+    def setUp(self) :
+        self.obj = db.DB()
+
+class CrashAndBurn(unittest.TestCase) :
+    import sys
+    if sys.version_info[:3] < (2, 4, 0):
+        def assertTrue(self, expr, msg=None):
+            self.failUnless(expr,msg=msg)
+
+    #def test01_OpenCrash(self) :
+    #    # See http://bugs.python.org/issue3307
+    #    self.assertRaises(db.DBInvalidArgError, db.DB, None, 65535)
+
+    def test02_DBEnv_dealloc(self):
+        # http://bugs.python.org/issue3885
+        import gc
+        self.assertRaises(db.DBInvalidArgError, db.DBEnv, ~db.DB_RPCCLIENT)
+        gc.collect()
+
+
 #----------------------------------------------------------------------
 #----------------------------------------------------------------------
 
@@ -981,6 +1030,9 @@ def test_suite():
     suite.addTest(unittest.makeSuite(HashDUPWithThreadTestCase))
     suite.addTest(unittest.makeSuite(BTreeMultiDBTestCase))
     suite.addTest(unittest.makeSuite(HashMultiDBTestCase))
+    suite.addTest(unittest.makeSuite(DBEnvPrivateObject))
+    suite.addTest(unittest.makeSuite(DBPrivateObject))
+    suite.addTest(unittest.makeSuite(CrashAndBurn))
 
     return suite
 
diff --git a/Lib/bsddb/test/test_compare.py b/Lib/bsddb/test/test_compare.py
index 59a45ec..ce3728a 100644
--- a/Lib/bsddb/test/test_compare.py
+++ b/Lib/bsddb/test/test_compare.py
@@ -7,12 +7,10 @@ import test_all
 from cStringIO import StringIO
 
 import unittest
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, dbshelve
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, dbshelve
+
+from test_all import db, dbshelve, test_support, \
+        get_new_environment_path, get_new_database_path
+
 
 lexical_cmp = cmp
 
@@ -30,8 +28,26 @@ _expected_lowercase_test_data = ['', 'a', 'aaa', 'b', 'c', 'CC', 'cccce', 'ccccf
 class ComparatorTests (unittest.TestCase):
     def comparator_test_helper (self, comparator, expected_data):
         data = expected_data[:]
-        data.sort (comparator)
-        self.failUnless (data == expected_data,
+
+        import sys
+        if sys.version_info[:3] < (2, 6, 0):
+            if sys.version_info[:3] < (2, 4, 0):
+                data.sort(comparator)
+            else :
+                data.sort(cmp=comparator)
+        else :  # Insertion Sort. Please, improve
+            data2 = []
+            for i in data :
+                for j, k in enumerate(data2) :
+                    r = comparator(k, i)
+                    if r == 1 :
+                        data2.insert(j, i)
+                        break
+                else :
+                    data2.append(i)
+            data = data2
+
+        self.assertEqual (data, expected_data,
                          "comparator `%s' is not right: %s vs. %s"
                          % (comparator, expected_data, data))
     def test_lexical_comparator (self):
@@ -51,26 +67,19 @@ class AbstractBtreeKeyCompareTestCase (unittest.TestCase):
 
     def setUp (self):
         self.filename = self.__class__.__name__ + '.db'
-        homeDir = os.path.join (os.path.dirname (sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try:
-            os.mkdir (homeDir)
-        except os.error:
-            pass
-
-        env = db.DBEnv ()
-        env.open (homeDir,
+        self.homeDir = get_new_environment_path()
+        env = db.DBEnv()
+        env.open (self.homeDir,
                   db.DB_CREATE | db.DB_INIT_MPOOL
                   | db.DB_INIT_LOCK | db.DB_THREAD)
         self.env = env
 
     def tearDown (self):
-        self.closeDB ()
+        self.closeDB()
         if self.env is not None:
-            self.env.close ()
+            self.env.close()
             self.env = None
-        import glob
-        map (os.remove, glob.glob (os.path.join (self.homeDir, '*')))
+        test_support.rmtree(self.homeDir)
 
     def addDataToDB (self, data):
         i = 0
@@ -106,14 +115,14 @@ class AbstractBtreeKeyCompareTestCase (unittest.TestCase):
             rec = curs.first ()
             while rec:
                 key, ignore = rec
-                self.failUnless (index < len (expected),
+                self.assertTrue (index < len (expected),
                                  "to many values returned from cursor")
-                self.failUnless (expected[index] == key,
+                self.assertEqual (expected[index], key,
                                  "expected value `%s' at %d but got `%s'"
                                  % (expected[index], index, key))
                 index = index + 1
                 rec = curs.next ()
-            self.failUnless (index == len (expected),
+            self.assertEqual (index, len (expected),
                              "not enough values returned from cursor")
         finally:
             curs.close ()
@@ -184,6 +193,7 @@ class BtreeExceptionsTestCase (AbstractBtreeKeyCompareTestCase):
             errorOut = temp.getvalue()
             if not successRe.search(errorOut):
                 self.fail("unexpected stderr output:\n"+errorOut)
+        sys.exc_traceback = sys.last_traceback = None
 
     def _test_compare_function_exception (self):
         self.startTest ()
@@ -229,20 +239,14 @@ class BtreeExceptionsTestCase (AbstractBtreeKeyCompareTestCase):
 
         self.startTest ()
         self.createDB (my_compare)
-        try:
-            self.db.set_bt_compare (my_compare)
-            assert False, "this set should fail"
-
-        except RuntimeError, msg:
-            pass
+        self.assertRaises (RuntimeError, self.db.set_bt_compare, my_compare)
 
 def test_suite ():
     res = unittest.TestSuite ()
 
     res.addTest (unittest.makeSuite (ComparatorTests))
-    if db.version () >= (3, 3, 11):
-        res.addTest (unittest.makeSuite (BtreeExceptionsTestCase))
-        res.addTest (unittest.makeSuite (BtreeKeyCompareTestCase))
+    res.addTest (unittest.makeSuite (BtreeExceptionsTestCase))
+    res.addTest (unittest.makeSuite (BtreeKeyCompareTestCase))
     return res
 
 if __name__ == '__main__':
diff --git a/Lib/bsddb/test/test_compat.py b/Lib/bsddb/test/test_compat.py
index b108db4..0b0fa70 100644
--- a/Lib/bsddb/test/test_compat.py
+++ b/Lib/bsddb/test/test_compat.py
@@ -3,23 +3,16 @@ Test cases adapted from the test_bsddb.py module in Python's
 regression test suite.
 """
 
-import sys, os, string
+import os, string
 import unittest
-import tempfile
 
-from test_all import verbose
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, hashopen, btopen, rnopen
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, hashopen, btopen, rnopen
+from test_all import db, hashopen, btopen, rnopen, verbose, \
+        get_new_database_path
 
 
 class CompatibilityTestCase(unittest.TestCase):
     def setUp(self):
-        self.filename = tempfile.mktemp()
+        self.filename = get_new_database_path()
 
     def tearDown(self):
         try:
@@ -35,7 +28,7 @@ class CompatibilityTestCase(unittest.TestCase):
         self.do_bthash_test(hashopen, 'hashopen')
 
     def test03_rnopen(self):
-        data = string.split("The quick brown fox jumped over the lazy dog.")
+        data = "The quick brown fox jumped over the lazy dog.".split()
         if verbose:
             print "\nTesting: rnopen"
 
@@ -47,7 +40,7 @@ class CompatibilityTestCase(unittest.TestCase):
         if verbose:
             print '%s %s %s' % getTest
 
-        assert getTest[1] == 'quick', 'data mismatch!'
+        self.assertEqual(getTest[1], 'quick', 'data mismatch!')
 
         rv = f.set_location(3)
         if rv != (3, 'brown'):
@@ -120,13 +113,13 @@ class CompatibilityTestCase(unittest.TestCase):
             try:
                 rec = f.next()
             except KeyError:
-                assert rec == f.last(), 'Error, last <> last!'
+                self.assertEqual(rec, f.last(), 'Error, last <> last!')
                 f.previous()
                 break
             if verbose:
                 print rec
 
-        assert f.has_key('f'), 'Error, missing key!'
+        self.assert_(f.has_key('f'), 'Error, missing key!')
 
         # test that set_location() returns the next nearest key, value
         # on btree databases and raises KeyError on others.
@@ -140,7 +133,7 @@ class CompatibilityTestCase(unittest.TestCase):
             except KeyError:
                 pass
             else:
-                self.fail("set_location on non-existant key did not raise KeyError")
+                self.fail("set_location on non-existent key did not raise KeyError")
 
         f.sync()
         f.close()
diff --git a/Lib/bsddb/test/test_cursor_pget_bug.py b/Lib/bsddb/test/test_cursor_pget_bug.py
index de47e6d..68b6a87 100644
--- a/Lib/bsddb/test/test_cursor_pget_bug.py
+++ b/Lib/bsddb/test/test_cursor_pget_bug.py
@@ -1,13 +1,8 @@
 import unittest
-import sys, os, glob
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db
-except ImportError:
-    # For Python 2.3
-    from bsddb import db
+import os, glob
 
+from test_all import db, test_support, get_new_environment_path, \
+        get_new_database_path
 
 #----------------------------------------------------------------------
 
@@ -16,11 +11,7 @@ class pget_bugTestCase(unittest.TestCase):
     db_name = 'test-cursor_pget.db'
 
     def setUp(self):
-        self.homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        try:
-            os.mkdir(self.homeDir)
-        except os.error:
-            pass
+        self.homeDir = get_new_environment_path()
         self.env = db.DBEnv()
         self.env.open(self.homeDir, db.DB_CREATE | db.DB_INIT_MPOOL)
         self.primary_db = db.DB(self.env)
@@ -41,9 +32,7 @@ class pget_bugTestCase(unittest.TestCase):
         del self.secondary_db
         del self.primary_db
         del self.env
-        for file in glob.glob(os.path.join(self.homeDir, '*')):
-            os.remove(file)
-        os.removedirs(self.homeDir)
+        test_support.rmtree(self.homeDir)
 
     def test_pget(self):
         cursor = self.secondary_db.cursor()
diff --git a/Lib/bsddb/test/test_dbobj.py b/Lib/bsddb/test/test_dbobj.py
index 1ef382e..e301a5a 100644
--- a/Lib/bsddb/test/test_dbobj.py
+++ b/Lib/bsddb/test/test_dbobj.py
@@ -1,54 +1,42 @@
 
-import sys, os, string
+import os, string
 import unittest
-import glob
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, dbobj
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, dbobj
 
+from test_all import db, dbobj, test_support, get_new_environment_path, \
+        get_new_database_path
 
 #----------------------------------------------------------------------
 
 class dbobjTestCase(unittest.TestCase):
     """Verify that dbobj.DB and dbobj.DBEnv work properly"""
-    db_home = 'db_home'
     db_name = 'test-dbobj.db'
 
     def setUp(self):
-        homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try: os.mkdir(homeDir)
-        except os.error: pass
+        self.homeDir = get_new_environment_path()
 
     def tearDown(self):
         if hasattr(self, 'db'):
             del self.db
         if hasattr(self, 'env'):
             del self.env
-        files = glob.glob(os.path.join(self.homeDir, '*'))
-        for file in files:
-            os.remove(file)
+        test_support.rmtree(self.homeDir)
 
     def test01_both(self):
         class TestDBEnv(dbobj.DBEnv): pass
         class TestDB(dbobj.DB):
             def put(self, key, *args, **kwargs):
-                key = string.upper(key)
+                key = key.upper()
                 # call our parent classes put method with an upper case key
-                return apply(dbobj.DB.put, (self, key) + args, kwargs)
+                return dbobj.DB.put(self, key, *args, **kwargs)
         self.env = TestDBEnv()
         self.env.open(self.homeDir, db.DB_CREATE | db.DB_INIT_MPOOL)
         self.db = TestDB(self.env)
         self.db.open(self.db_name, db.DB_HASH, db.DB_CREATE)
         self.db.put('spam', 'eggs')
-        assert self.db.get('spam') == None, \
-               "overridden dbobj.DB.put() method failed [1]"
-        assert self.db.get('SPAM') == 'eggs', \
-               "overridden dbobj.DB.put() method failed [2]"
+        self.assertEqual(self.db.get('spam'), None,
+               "overridden dbobj.DB.put() method failed [1]")
+        self.assertEqual(self.db.get('SPAM'), 'eggs',
+               "overridden dbobj.DB.put() method failed [2]")
         self.db.close()
         self.env.close()
 
@@ -60,12 +48,12 @@ class dbobjTestCase(unittest.TestCase):
         # __setitem__
         self.db['spam'] = 'eggs'
         # __len__
-        assert len(self.db) == 1
+        self.assertEqual(len(self.db), 1)
         # __getitem__
-        assert self.db['spam'] == 'eggs'
+        self.assertEqual(self.db['spam'], 'eggs')
         # __del__
         del self.db['spam']
-        assert self.db.get('spam') == None, "dbobj __del__ failed"
+        self.assertEqual(self.db.get('spam'), None, "dbobj __del__ failed")
         self.db.close()
         self.env.close()
 
diff --git a/Lib/bsddb/test/test_dbshelve.py b/Lib/bsddb/test/test_dbshelve.py
index e3b8997..13f9cd2 100644
--- a/Lib/bsddb/test/test_dbshelve.py
+++ b/Lib/bsddb/test/test_dbshelve.py
@@ -2,20 +2,15 @@
 TestCases for checking dbShelve objects.
 """
 
-import sys, os, string
-import tempfile, random
-from pprint import pprint
-from types import *
+import os, string
+import random
 import unittest
+import warnings
 
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, dbshelve
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, dbshelve
 
-from test_all import verbose
+from test_all import db, dbshelve, test_support, verbose, \
+        get_new_environment_path, get_new_database_path
+
 
 
 #----------------------------------------------------------------------
@@ -26,25 +21,38 @@ class DataClass:
     def __init__(self):
         self.value = random.random()
 
-    def __cmp__(self, other):
+    def __repr__(self) :  # For Python 3.0 comparison
+        return "DataClass %f" %self.value
+
+    def __cmp__(self, other):  # For Python 2.x comparison
         return cmp(self.value, other)
 
+
 class DBShelveTestCase(unittest.TestCase):
     def setUp(self):
-        self.filename = tempfile.mktemp()
+        import sys
+        if sys.version_info[0] >= 3 :
+            from test_all import do_proxy_db_py3k
+            self._flag_proxy_db_py3k = do_proxy_db_py3k(False)
+        self.filename = get_new_database_path()
         self.do_open()
 
     def tearDown(self):
+        import sys
+        if sys.version_info[0] >= 3 :
+            from test_all import do_proxy_db_py3k
+            do_proxy_db_py3k(self._flag_proxy_db_py3k)
         self.do_close()
-        try:
-            os.remove(self.filename)
-        except os.error:
-            pass
+        test_support.unlink(self.filename)
 
     def mk(self, key):
         """Turn key into an appropriate key type for this db"""
         # override in child class for RECNO
-        return key
+        import sys
+        if sys.version_info[0] < 3 :
+            return key
+        else :
+            return bytes(key, "iso8859-1")  # 8 bits
 
     def populateDB(self, d):
         for x in string.letters:
@@ -90,15 +98,15 @@ class DBShelveTestCase(unittest.TestCase):
             print "keys:", k
             print "stats:", s
 
-        assert 0 == d.has_key(self.mk('bad key'))
-        assert 1 == d.has_key(self.mk('IA'))
-        assert 1 == d.has_key(self.mk('OA'))
+        self.assertEqual(0, d.has_key(self.mk('bad key')))
+        self.assertEqual(1, d.has_key(self.mk('IA')))
+        self.assertEqual(1, d.has_key(self.mk('OA')))
 
         d.delete(self.mk('IA'))
         del d[self.mk('OA')]
-        assert 0 == d.has_key(self.mk('IA'))
-        assert 0 == d.has_key(self.mk('OA'))
-        assert len(d) == l-2
+        self.assertEqual(0, d.has_key(self.mk('IA')))
+        self.assertEqual(0, d.has_key(self.mk('OA')))
+        self.assertEqual(len(d), l-2)
 
         values = []
         for key in d.keys():
@@ -109,29 +117,31 @@ class DBShelveTestCase(unittest.TestCase):
             self.checkrec(key, value)
 
         dbvalues = d.values()
-        assert len(dbvalues) == len(d.keys())
-        values.sort()
-        dbvalues.sort()
-        assert values == dbvalues
+        self.assertEqual(len(dbvalues), len(d.keys()))
+        with warnings.catch_warnings():
+            warnings.filterwarnings('ignore',
+                                    'comparing unequal types not supported',
+                                    DeprecationWarning)
+            self.assertEqual(sorted(values), sorted(dbvalues))
 
         items = d.items()
-        assert len(items) == len(values)
+        self.assertEqual(len(items), len(values))
 
         for key, value in items:
             self.checkrec(key, value)
 
-        assert d.get(self.mk('bad key')) == None
-        assert d.get(self.mk('bad key'), None) == None
-        assert d.get(self.mk('bad key'), 'a string') == 'a string'
-        assert d.get(self.mk('bad key'), [1, 2, 3]) == [1, 2, 3]
+        self.assertEqual(d.get(self.mk('bad key')), None)
+        self.assertEqual(d.get(self.mk('bad key'), None), None)
+        self.assertEqual(d.get(self.mk('bad key'), 'a string'), 'a string')
+        self.assertEqual(d.get(self.mk('bad key'), [1, 2, 3]), [1, 2, 3])
 
         d.set_get_returns_none(0)
         self.assertRaises(db.DBNotFoundError, d.get, self.mk('bad key'))
         d.set_get_returns_none(1)
 
         d.put(self.mk('new key'), 'new data')
-        assert d.get(self.mk('new key')) == 'new data'
-        assert d[self.mk('new key')] == 'new data'
+        self.assertEqual(d.get(self.mk('new key')), 'new data')
+        self.assertEqual(d[self.mk('new key')], 'new data')
 
 
 
@@ -152,10 +162,11 @@ class DBShelveTestCase(unittest.TestCase):
                 print rec
             key, value = rec
             self.checkrec(key, value)
-            rec = c.next()
+            # Hack to avoid conversion by 2to3 tool
+            rec = getattr(c, "next")()
         del c
 
-        assert count == len(d)
+        self.assertEqual(count, len(d))
 
         count = 0
         c = d.cursor()
@@ -168,7 +179,7 @@ class DBShelveTestCase(unittest.TestCase):
             self.checkrec(key, value)
             rec = c.prev()
 
-        assert count == len(d)
+        self.assertEqual(count, len(d))
 
         c.set(self.mk('SS'))
         key, value = c.current()
@@ -188,27 +199,39 @@ class DBShelveTestCase(unittest.TestCase):
 
     def checkrec(self, key, value):
         # override this in a subclass if the key type is different
+
+        import sys
+        if sys.version_info[0] >= 3 :
+            if isinstance(key, bytes) :
+                key = key.decode("iso8859-1")  # 8 bits
+
         x = key[1]
         if key[0] == 'S':
-            assert type(value) == StringType
-            assert value == 10 * x
+            self.assertEqual(type(value), str)
+            self.assertEqual(value, 10 * x)
 
         elif key[0] == 'I':
-            assert type(value) == IntType
-            assert value == ord(x)
+            self.assertEqual(type(value), int)
+            self.assertEqual(value, ord(x))
 
         elif key[0] == 'L':
-            assert type(value) == ListType
-            assert value == [x] * 10
+            self.assertEqual(type(value), list)
+            self.assertEqual(value, [x] * 10)
 
         elif key[0] == 'O':
-            assert type(value) == InstanceType
-            assert value.S == 10 * x
-            assert value.I == ord(x)
-            assert value.L == [x] * 10
+            import sys
+            if sys.version_info[0] < 3 :
+                from types import InstanceType
+                self.assertEqual(type(value), InstanceType)
+            else :
+                self.assertEqual(type(value), DataClass)
+
+            self.assertEqual(value.S, 10 * x)
+            self.assertEqual(value.I, ord(x))
+            self.assertEqual(value.L, [x] * 10)
 
         else:
-            raise AssertionError, 'Unknown key type, fix the test'
+            self.assert_(0, 'Unknown key type, fix the test')
 
 #----------------------------------------------------------------------
 
@@ -245,12 +268,9 @@ class ThreadHashShelveTestCase(BasicShelveTestCase):
 
 class BasicEnvShelveTestCase(DBShelveTestCase):
     def do_open(self):
-        self.homeDir = homeDir = os.path.join(
-            os.path.dirname(sys.argv[0]), 'db_home')
-        try: os.mkdir(homeDir)
-        except os.error: pass
         self.env = db.DBEnv()
-        self.env.open(homeDir, self.envflags | db.DB_INIT_MPOOL | db.DB_CREATE)
+        self.env.open(self.homeDir,
+                self.envflags | db.DB_INIT_MPOOL | db.DB_CREATE)
 
         self.filename = os.path.split(self.filename)[1]
         self.d = dbshelve.DBShelf(self.env)
@@ -262,13 +282,17 @@ class BasicEnvShelveTestCase(DBShelveTestCase):
         self.env.close()
 
 
+    def setUp(self) :
+        self.homeDir = get_new_environment_path()
+        DBShelveTestCase.setUp(self)
+
     def tearDown(self):
+        import sys
+        if sys.version_info[0] >= 3 :
+            from test_all import do_proxy_db_py3k
+            do_proxy_db_py3k(self._flag_proxy_db_py3k)
         self.do_close()
-        import glob
-        files = glob.glob(os.path.join(self.homeDir, '*'))
-        for file in files:
-            os.remove(file)
-
+        test_support.rmtree(self.homeDir)
 
 
 class EnvBTreeShelveTestCase(BasicEnvShelveTestCase):
diff --git a/Lib/bsddb/test/test_dbtables.py b/Lib/bsddb/test/test_dbtables.py
index 2adda18..1d0489d 100644
--- a/Lib/bsddb/test/test_dbtables.py
+++ b/Lib/bsddb/test/test_dbtables.py
@@ -16,44 +16,43 @@
 #               software has been tested, but no warranty is expressed or
 #               implied.
 #
-#   --  Gregory P. Smith <greg@electricrain.com>
+#   --  Gregory P. Smith <greg@krypto.org>
 #
-# $Id: test_dbtables.py 58536 2007-10-18 17:15:20Z gregory.p.smith $
+# $Id: test_dbtables.py 83562 2010-08-02 20:19:21Z ezio.melotti $
 
-import sys, os, re
-import shutil
-import tempfile
+import os, re
 try:
-    import cPickle as pickle
+    import cPickle
+    pickle = cPickle
 except ImportError:
     import pickle
 
 import unittest
-from test_all import verbose
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, dbtables
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, dbtables
-
-
+from test_all import db, dbtables, test_support, verbose, \
+        get_new_environment_path, get_new_database_path
 
 #----------------------------------------------------------------------
 
 class TableDBTestCase(unittest.TestCase):
+    db_name = 'test-table.db'
+
     def setUp(self):
-        homeDir = tempfile.mkdtemp()
-        self.testHomeDir = homeDir
-        try: os.mkdir(homeDir)
-        except os.error: pass
+        import sys
+        if sys.version_info[0] >= 3 :
+            from test_all import do_proxy_db_py3k
+            self._flag_proxy_db_py3k = do_proxy_db_py3k(False)
+
+        self.testHomeDir = get_new_environment_path()
         self.tdb = dbtables.bsdTableDB(
-            filename='tabletest.db', dbhome=homeDir, create=1)
+            filename='tabletest.db', dbhome=self.testHomeDir, create=1)
 
     def tearDown(self):
         self.tdb.close()
-        shutil.rmtree(self.testHomeDir)
+        import sys
+        if sys.version_info[0] >= 3 :
+            from test_all import do_proxy_db_py3k
+            do_proxy_db_py3k(self._flag_proxy_db_py3k)
+        test_support.rmtree(self.testHomeDir)
 
     def test01(self):
         tabname = "test01"
@@ -63,7 +62,12 @@ class TableDBTestCase(unittest.TestCase):
         except dbtables.TableDBError:
             pass
         self.tdb.CreateTable(tabname, [colname])
-        self.tdb.Insert(tabname, {colname: pickle.dumps(3.14159, 1)})
+        import sys
+        if sys.version_info[0] < 3 :
+            self.tdb.Insert(tabname, {colname: pickle.dumps(3.14159, 1)})
+        else :
+            self.tdb.Insert(tabname, {colname: pickle.dumps(3.14159,
+                1).decode("iso8859-1")})  # 8 bits
 
         if verbose:
             self.tdb._db_print()
@@ -71,8 +75,13 @@ class TableDBTestCase(unittest.TestCase):
         values = self.tdb.Select(
             tabname, [colname], conditions={colname: None})
 
-        colval = pickle.loads(values[0][colname])
-        assert(colval > 3.141 and colval < 3.142)
+        import sys
+        if sys.version_info[0] < 3 :
+            colval = pickle.loads(values[0][colname])
+        else :
+            colval = pickle.loads(bytes(values[0][colname], "iso8859-1"))
+        self.assert_(colval > 3.141)
+        self.assert_(colval < 3.142)
 
 
     def test02(self):
@@ -80,11 +89,23 @@ class TableDBTestCase(unittest.TestCase):
         col0 = 'coolness factor'
         col1 = 'but can it fly?'
         col2 = 'Species'
-        testinfo = [
-            {col0: pickle.dumps(8, 1), col1: 'no', col2: 'Penguin'},
-            {col0: pickle.dumps(-1, 1), col1: 'no', col2: 'Turkey'},
-            {col0: pickle.dumps(9, 1), col1: 'yes', col2: 'SR-71A Blackbird'}
-        ]
+
+        import sys
+        if sys.version_info[0] < 3 :
+            testinfo = [
+                {col0: pickle.dumps(8, 1), col1: 'no', col2: 'Penguin'},
+                {col0: pickle.dumps(-1, 1), col1: 'no', col2: 'Turkey'},
+                {col0: pickle.dumps(9, 1), col1: 'yes', col2: 'SR-71A Blackbird'}
+            ]
+        else :
+            testinfo = [
+                {col0: pickle.dumps(8, 1).decode("iso8859-1"),
+                    col1: 'no', col2: 'Penguin'},
+                {col0: pickle.dumps(-1, 1).decode("iso8859-1"),
+                    col1: 'no', col2: 'Turkey'},
+                {col0: pickle.dumps(9, 1).decode("iso8859-1"),
+                    col1: 'yes', col2: 'SR-71A Blackbird'}
+            ]
 
         try:
             self.tdb.Drop(tabname)
@@ -94,18 +115,24 @@ class TableDBTestCase(unittest.TestCase):
         for row in testinfo :
             self.tdb.Insert(tabname, row)
 
-        values = self.tdb.Select(tabname, [col2],
-            conditions={col0: lambda x: pickle.loads(x) >= 8})
+        import sys
+        if sys.version_info[0] < 3 :
+            values = self.tdb.Select(tabname, [col2],
+                conditions={col0: lambda x: pickle.loads(x) >= 8})
+        else :
+            values = self.tdb.Select(tabname, [col2],
+                conditions={col0: lambda x:
+                    pickle.loads(bytes(x, "iso8859-1")) >= 8})
 
-        assert len(values) == 2
+        self.assertEqual(len(values), 2)
         if values[0]['Species'] == 'Penguin' :
-            assert values[1]['Species'] == 'SR-71A Blackbird'
+            self.assertEqual(values[1]['Species'], 'SR-71A Blackbird')
         elif values[0]['Species'] == 'SR-71A Blackbird' :
-            assert values[1]['Species'] == 'Penguin'
+            self.assertEqual(values[1]['Species'], 'Penguin')
         else :
             if verbose:
                 print "values= %r" % (values,)
-            raise "Wrong values returned!"
+            raise RuntimeError("Wrong values returned!")
 
     def test03(self):
         tabname = "test03"
@@ -131,13 +158,13 @@ class TableDBTestCase(unittest.TestCase):
                             {'a': "",
                              'e': pickle.dumps([{4:5, 6:7}, 'foo'], 1),
                              'f': "Zero"})
-            assert 0
+            self.fail('Expected an exception')
         except dbtables.TableDBError:
             pass
 
         try:
             self.tdb.Select(tabname, [], conditions={'foo': '123'})
-            assert 0
+            self.fail('Expected an exception')
         except dbtables.TableDBError:
             pass
 
@@ -166,20 +193,20 @@ class TableDBTestCase(unittest.TestCase):
         values = self.tdb.Select(tabname, ['b', 'a', 'd'],
             conditions={'e': re.compile('wuzzy').search,
                         'a': re.compile('^[0-9]+$').match})
-        assert len(values) == 2
+        self.assertEqual(len(values), 2)
 
         # now lets delete one of them and try again
         self.tdb.Delete(tabname, conditions={'b': dbtables.ExactCond('good')})
         values = self.tdb.Select(
             tabname, ['a', 'd', 'b'],
             conditions={'e': dbtables.PrefixCond('Fuzzy')})
-        assert len(values) == 1
-        assert values[0]['d'] == None
+        self.assertEqual(len(values), 1)
+        self.assertEqual(values[0]['d'], None)
 
         values = self.tdb.Select(tabname, ['b'],
             conditions={'c': lambda c: c == 'meep'})
-        assert len(values) == 1
-        assert values[0]['b'] == "bad"
+        self.assertEqual(len(values), 1)
+        self.assertEqual(values[0]['b'], "bad")
 
 
     def test04_MultiCondSelect(self):
@@ -195,7 +222,7 @@ class TableDBTestCase(unittest.TestCase):
                             {'a': "",
                              'e': pickle.dumps([{4:5, 6:7}, 'foo'], 1),
                              'f': "Zero"})
-            assert 0
+            self.fail('Expected an exception')
         except dbtables.TableDBError:
             pass
 
@@ -219,7 +246,7 @@ class TableDBTestCase(unittest.TestCase):
                         'a': dbtables.ExactCond('A'),
                         'd': dbtables.PrefixCond('-')
                        } )
-        assert len(values) == 0, values
+        self.assertEqual(len(values), 0, values)
 
 
     def test_CreateOrExtend(self):
@@ -232,7 +259,7 @@ class TableDBTestCase(unittest.TestCase):
                             {'taste': 'crap',
                              'filling': 'no',
                              'is it Guinness?': 'no'})
-            assert 0, "Insert should've failed due to bad column name"
+            self.fail("Insert should've failed due to bad column name")
         except:
             pass
         self.tdb.CreateOrExtendTable(tabname,
@@ -266,16 +293,16 @@ class TableDBTestCase(unittest.TestCase):
         values = self.tdb.Select(
             tabname, ['p', 'e'],
             conditions={'e': dbtables.PrefixCond('the l')})
-        assert len(values) == 2, values
-        assert values[0]['e'] == values[1]['e'], values
-        assert values[0]['p'] != values[1]['p'], values
+        self.assertEqual(len(values), 2, values)
+        self.assertEqual(values[0]['e'], values[1]['e'], values)
+        self.assertNotEqual(values[0]['p'], values[1]['p'], values)
 
         values = self.tdb.Select(
             tabname, ['d', 'a'],
             conditions={'a': dbtables.LikeCond('%aardvark%')})
-        assert len(values) == 1, values
-        assert values[0]['d'] == "is for dog", values
-        assert values[0]['a'] == "is for aardvark", values
+        self.assertEqual(len(values), 1, values)
+        self.assertEqual(values[0]['d'], "is for dog", values)
+        self.assertEqual(values[0]['a'], "is for aardvark", values)
 
         values = self.tdb.Select(tabname, None,
                                  {'b': dbtables.Cond(),
@@ -284,9 +311,9 @@ class TableDBTestCase(unittest.TestCase):
                                   'd':dbtables.ExactCond('is for dog'),
                                   'c':dbtables.PrefixCond('is for'),
                                   'p':lambda s: not s})
-        assert len(values) == 1, values
-        assert values[0]['d'] == "is for dog", values
-        assert values[0]['a'] == "is for aardvark", values
+        self.assertEqual(len(values), 1, values)
+        self.assertEqual(values[0]['d'], "is for dog", values)
+        self.assertEqual(values[0]['a'], "is for aardvark", values)
 
     def test_Delete(self):
         tabname = "test_Delete"
@@ -302,7 +329,7 @@ class TableDBTestCase(unittest.TestCase):
         self.tdb.Delete(tabname, conditions={'x': dbtables.PrefixCond('X')})
         values = self.tdb.Select(tabname, ['y'],
                                  conditions={'x': dbtables.PrefixCond('X')})
-        assert len(values) == 0
+        self.assertEqual(len(values), 0)
 
     def test_Modify(self):
         tabname = "test_Modify"
@@ -314,7 +341,7 @@ class TableDBTestCase(unittest.TestCase):
         self.tdb.Insert(tabname, {'Type': 'Unknown', 'Access': '0'})
 
         def set_type(type):
-            if type == None:
+            if type is None:
                 return 'MP3'
             return type
 
@@ -348,24 +375,24 @@ class TableDBTestCase(unittest.TestCase):
         values = self.tdb.Select(
             tabname, None,
             conditions={'Type': dbtables.ExactCond('Unknown')})
-        assert len(values) == 1, values
-        assert values[0]['Name'] == None, values
-        assert values[0]['Access'] == None, values
+        self.assertEqual(len(values), 1, values)
+        self.assertEqual(values[0]['Name'], None, values)
+        self.assertEqual(values[0]['Access'], None, values)
 
         # Modify value by select conditions
         values = self.tdb.Select(
             tabname, None,
             conditions={'Name': dbtables.ExactCond('Nifty.MP3')})
-        assert len(values) == 1, values
-        assert values[0]['Type'] == "MP3", values
-        assert values[0]['Access'] == "2", values
+        self.assertEqual(len(values), 1, values)
+        self.assertEqual(values[0]['Type'], "MP3", values)
+        self.assertEqual(values[0]['Access'], "2", values)
 
         # Make sure change applied only to select conditions
         values = self.tdb.Select(
             tabname, None, conditions={'Name': dbtables.LikeCond('%doc%')})
-        assert len(values) == 1, values
-        assert values[0]['Type'] == "Word", values
-        assert values[0]['Access'] == "9", values
+        self.assertEqual(len(values), 1, values)
+        self.assertEqual(values[0]['Type'], "Word", values)
+        self.assertEqual(values[0]['Access'], "9", values)
 
 
 def test_suite():
diff --git a/Lib/bsddb/test/test_distributed_transactions.py b/Lib/bsddb/test/test_distributed_transactions.py
new file mode 100644
index 0000000..f864b88
--- /dev/null
+++ b/Lib/bsddb/test/test_distributed_transactions.py
@@ -0,0 +1,163 @@
+"""TestCases for distributed transactions.
+"""
+
+import os
+import unittest
+
+from test_all import db, test_support, get_new_environment_path, \
+        get_new_database_path
+
+try :
+    a=set()
+except : # Python 2.3
+    from sets import Set as set
+else :
+    del a
+
+from test_all import verbose
+
+#----------------------------------------------------------------------
+
+class DBTxn_distributed(unittest.TestCase):
+    num_txns=1234
+    nosync=True
+    must_open_db=False
+    def _create_env(self, must_open_db) :
+        self.dbenv = db.DBEnv()
+        self.dbenv.set_tx_max(self.num_txns)
+        self.dbenv.set_lk_max_lockers(self.num_txns*2)
+        self.dbenv.set_lk_max_locks(self.num_txns*2)
+        self.dbenv.set_lk_max_objects(self.num_txns*2)
+        if self.nosync :
+            self.dbenv.set_flags(db.DB_TXN_NOSYNC,True)
+        self.dbenv.open(self.homeDir, db.DB_CREATE | db.DB_THREAD |
+                db.DB_RECOVER |
+                db.DB_INIT_TXN | db.DB_INIT_LOG | db.DB_INIT_MPOOL |
+                db.DB_INIT_LOCK, 0666)
+        self.db = db.DB(self.dbenv)
+        self.db.set_re_len(db.DB_XIDDATASIZE)
+        if must_open_db :
+            if db.version() > (4,1) :
+                txn=self.dbenv.txn_begin()
+                self.db.open(self.filename,
+                        db.DB_QUEUE, db.DB_CREATE | db.DB_THREAD, 0666,
+                        txn=txn)
+                txn.commit()
+            else :
+                self.db.open(self.filename,
+                        db.DB_QUEUE, db.DB_CREATE | db.DB_THREAD, 0666)
+
+    def setUp(self) :
+        self.homeDir = get_new_environment_path()
+        self.filename = "test"
+        return self._create_env(must_open_db=True)
+
+    def _destroy_env(self):
+        if self.nosync or (db.version()[:2] == (4,6)):  # Known bug
+            self.dbenv.log_flush()
+        self.db.close()
+        self.dbenv.close()
+
+    def tearDown(self):
+        self._destroy_env()
+        test_support.rmtree(self.homeDir)
+
+    def _recreate_env(self,must_open_db) :
+        self._destroy_env()
+        self._create_env(must_open_db)
+
+    def test01_distributed_transactions(self) :
+        txns=set()
+        adapt = lambda x : x
+        import sys
+        if sys.version_info[0] >= 3 :
+            adapt = lambda x : bytes(x, "ascii")
+    # Create transactions, "prepare" them, and
+    # let them be garbage collected.
+        for i in xrange(self.num_txns) :
+            txn = self.dbenv.txn_begin()
+            gid = "%%%dd" %db.DB_XIDDATASIZE
+            gid = adapt(gid %i)
+            self.db.put(i, gid, txn=txn, flags=db.DB_APPEND)
+            txns.add(gid)
+            txn.prepare(gid)
+        del txn
+
+        self._recreate_env(self.must_open_db)
+
+    # Get "to be recovered" transactions but
+    # let them be garbage collected.
+        recovered_txns=self.dbenv.txn_recover()
+        self.assertEquals(self.num_txns,len(recovered_txns))
+        for gid,txn in recovered_txns :
+            self.assert_(gid in txns)
+        del txn
+        del recovered_txns
+
+        self._recreate_env(self.must_open_db)
+
+    # Get "to be recovered" transactions. Commit, abort and
+    # discard them.
+        recovered_txns=self.dbenv.txn_recover()
+        self.assertEquals(self.num_txns,len(recovered_txns))
+        discard_txns=set()
+        committed_txns=set()
+        state=0
+        for gid,txn in recovered_txns :
+            if state==0 or state==1:
+                committed_txns.add(gid)
+                txn.commit()
+            elif state==2 :
+                txn.abort()
+            elif state==3 :
+                txn.discard()
+                discard_txns.add(gid)
+                state=-1
+            state+=1
+        del txn
+        del recovered_txns
+
+        self._recreate_env(self.must_open_db)
+
+    # Verify the discarded transactions are still
+    # around, and dispose them.
+        recovered_txns=self.dbenv.txn_recover()
+        self.assertEquals(len(discard_txns),len(recovered_txns))
+        for gid,txn in recovered_txns :
+            txn.abort()
+        del txn
+        del recovered_txns
+
+        self._recreate_env(must_open_db=True)
+
+    # Be sure there are not pending transactions.
+    # Check also database size.
+        recovered_txns=self.dbenv.txn_recover()
+        self.assert_(len(recovered_txns)==0)
+        self.assertEquals(len(committed_txns),self.db.stat()["nkeys"])
+
+class DBTxn_distributedSYNC(DBTxn_distributed):
+    nosync=False
+
+class DBTxn_distributed_must_open_db(DBTxn_distributed):
+    must_open_db=True
+
+class DBTxn_distributedSYNC_must_open_db(DBTxn_distributed):
+    nosync=False
+    must_open_db=True
+
+#----------------------------------------------------------------------
+
+def test_suite():
+    suite = unittest.TestSuite()
+    if db.version() >= (4,5) :
+        suite.addTest(unittest.makeSuite(DBTxn_distributed))
+        suite.addTest(unittest.makeSuite(DBTxn_distributedSYNC))
+    if db.version() >= (4,6) :
+        suite.addTest(unittest.makeSuite(DBTxn_distributed_must_open_db))
+        suite.addTest(unittest.makeSuite(DBTxn_distributedSYNC_must_open_db))
+    return suite
+
+
+if __name__ == '__main__':
+    unittest.main(defaultTest='test_suite')
diff --git a/Lib/bsddb/test/test_early_close.py b/Lib/bsddb/test/test_early_close.py
new file mode 100644
index 0000000..cc69e47
--- /dev/null
+++ b/Lib/bsddb/test/test_early_close.py
@@ -0,0 +1,195 @@
+"""TestCases for checking that it does not segfault when a DBEnv object
+is closed before its DB objects.
+"""
+
+import os
+import unittest
+
+from test_all import db, test_support, verbose, get_new_environment_path, get_new_database_path
+
+# We're going to get warnings in this module about trying to close the db when
+# its env is already closed.  Let's just ignore those.
+try:
+    import warnings
+except ImportError:
+    pass
+else:
+    warnings.filterwarnings('ignore',
+                            message='DB could not be closed in',
+                            category=RuntimeWarning)
+
+
+#----------------------------------------------------------------------
+
+class DBEnvClosedEarlyCrash(unittest.TestCase):
+    def setUp(self):
+        self.homeDir = get_new_environment_path()
+        self.filename = "test"
+
+    def tearDown(self):
+        test_support.rmtree(self.homeDir)
+
+    def test01_close_dbenv_before_db(self):
+        dbenv = db.DBEnv()
+        dbenv.open(self.homeDir,
+                   db.DB_INIT_CDB| db.DB_CREATE |db.DB_THREAD|db.DB_INIT_MPOOL,
+                   0666)
+
+        d = db.DB(dbenv)
+        d2 = db.DB(dbenv)
+        d.open(self.filename, db.DB_BTREE, db.DB_CREATE | db.DB_THREAD, 0666)
+
+        self.assertRaises(db.DBNoSuchFileError, d2.open,
+                self.filename+"2", db.DB_BTREE, db.DB_THREAD, 0666)
+
+        d.put("test","this is a test")
+        self.assertEqual(d.get("test"), "this is a test", "put!=get")
+        dbenv.close()  # This "close" should close the child db handle also
+        self.assertRaises(db.DBError, d.get, "test")
+
+    def test02_close_dbenv_before_dbcursor(self):
+        dbenv = db.DBEnv()
+        dbenv.open(self.homeDir,
+                   db.DB_INIT_CDB| db.DB_CREATE |db.DB_THREAD|db.DB_INIT_MPOOL,
+                   0666)
+
+        d = db.DB(dbenv)
+        d.open(self.filename, db.DB_BTREE, db.DB_CREATE | db.DB_THREAD, 0666)
+
+        d.put("test","this is a test")
+        d.put("test2","another test")
+        d.put("test3","another one")
+        self.assertEqual(d.get("test"), "this is a test", "put!=get")
+        c=d.cursor()
+        c.first()
+        c.next()
+        d.close()  # This "close" should close the child db handle also
+     # db.close should close the child cursor
+        self.assertRaises(db.DBError,c.next)
+
+        d = db.DB(dbenv)
+        d.open(self.filename, db.DB_BTREE, db.DB_CREATE | db.DB_THREAD, 0666)
+        c=d.cursor()
+        c.first()
+        c.next()
+        dbenv.close()
+    # The "close" should close the child db handle also, with cursors
+        self.assertRaises(db.DBError, c.next)
+
+    def test03_close_db_before_dbcursor_without_env(self):
+        import os.path
+        path=os.path.join(self.homeDir,self.filename)
+        d = db.DB()
+        d.open(path, db.DB_BTREE, db.DB_CREATE | db.DB_THREAD, 0666)
+
+        d.put("test","this is a test")
+        d.put("test2","another test")
+        d.put("test3","another one")
+        self.assertEqual(d.get("test"), "this is a test", "put!=get")
+        c=d.cursor()
+        c.first()
+        c.next()
+        d.close()
+    # The "close" should close the child db handle also
+        self.assertRaises(db.DBError, c.next)
+
+    def test04_close_massive(self):
+        dbenv = db.DBEnv()
+        dbenv.open(self.homeDir,
+                   db.DB_INIT_CDB| db.DB_CREATE |db.DB_THREAD|db.DB_INIT_MPOOL,
+                   0666)
+
+        dbs=[db.DB(dbenv) for i in xrange(16)]
+        cursors=[]
+        for i in dbs :
+            i.open(self.filename, db.DB_BTREE, db.DB_CREATE | db.DB_THREAD, 0666)
+
+        dbs[10].put("test","this is a test")
+        dbs[10].put("test2","another test")
+        dbs[10].put("test3","another one")
+        self.assertEqual(dbs[4].get("test"), "this is a test", "put!=get")
+
+        for i in dbs :
+            cursors.extend([i.cursor() for j in xrange(32)])
+
+        for i in dbs[::3] :
+            i.close()
+        for i in cursors[::3] :
+            i.close()
+
+    # Check for missing exception in DB! (after DB close)
+        self.assertRaises(db.DBError, dbs[9].get, "test")
+
+    # Check for missing exception in DBCursor! (after DB close)
+        self.assertRaises(db.DBError, cursors[101].first)
+
+        cursors[80].first()
+        cursors[80].next()
+        dbenv.close()  # This "close" should close the child db handle also
+    # Check for missing exception! (after DBEnv close)
+        self.assertRaises(db.DBError, cursors[80].next)
+
+    def test05_close_dbenv_delete_db_success(self):
+        dbenv = db.DBEnv()
+        dbenv.open(self.homeDir,
+                   db.DB_INIT_CDB| db.DB_CREATE |db.DB_THREAD|db.DB_INIT_MPOOL,
+                   0666)
+
+        d = db.DB(dbenv)
+        d.open(self.filename, db.DB_BTREE, db.DB_CREATE | db.DB_THREAD, 0666)
+
+        dbenv.close()  # This "close" should close the child db handle also
+
+        del d
+        try:
+            import gc
+        except ImportError:
+            gc = None
+        if gc:
+            # force d.__del__ [DB_dealloc] to be called
+            gc.collect()
+
+    def test06_close_txn_before_dup_cursor(self) :
+        dbenv = db.DBEnv()
+        dbenv.open(self.homeDir,db.DB_INIT_TXN | db.DB_INIT_MPOOL |
+                db.DB_INIT_LOG | db.DB_CREATE)
+        d = db.DB(dbenv)
+        txn = dbenv.txn_begin()
+        if db.version() < (4,1) :
+            d.open(self.filename, dbtype = db.DB_HASH, flags = db.DB_CREATE)
+        else :
+            d.open(self.filename, dbtype = db.DB_HASH, flags = db.DB_CREATE,
+                    txn=txn)
+        d.put("XXX", "yyy", txn=txn)
+        txn.commit()
+        txn = dbenv.txn_begin()
+        c1 = d.cursor(txn)
+        c2 = c1.dup()
+        self.assertEquals(("XXX", "yyy"), c1.first())
+        import warnings
+        # Not interested in warnings about implicit close.
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            txn.commit()
+        self.assertRaises(db.DBCursorClosedError, c2.first)
+
+    if db.version() > (4,3,0) :
+        def test07_close_db_before_sequence(self):
+            import os.path
+            path=os.path.join(self.homeDir,self.filename)
+            d = db.DB()
+            d.open(path, db.DB_BTREE, db.DB_CREATE | db.DB_THREAD, 0666)
+            dbs=db.DBSequence(d)
+            d.close()  # This "close" should close the child DBSequence also
+            dbs.close()  # If not closed, core dump (in Berkeley DB 4.6.*)
+
+#----------------------------------------------------------------------
+
+def test_suite():
+    suite = unittest.TestSuite()
+    suite.addTest(unittest.makeSuite(DBEnvClosedEarlyCrash))
+    return suite
+
+
+if __name__ == '__main__':
+    unittest.main(defaultTest='test_suite')
diff --git a/Lib/bsddb/test/test_get_none.py b/Lib/bsddb/test/test_get_none.py
index 5f09cec..4aaf2fd 100644
--- a/Lib/bsddb/test/test_get_none.py
+++ b/Lib/bsddb/test/test_get_none.py
@@ -2,26 +2,17 @@
 TestCases for checking set_get_returns_none.
 """
 
-import sys, os, string
-import tempfile
-from pprint import pprint
+import os, string
 import unittest
 
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db
-except ImportError:
-    # For Python 2.3
-    from bsddb import db
-
-from test_all import verbose
+from test_all import db, verbose, get_new_database_path
 
 
 #----------------------------------------------------------------------
 
 class GetReturnsNoneTestCase(unittest.TestCase):
     def setUp(self):
-        self.filename = tempfile.mktemp()
+        self.filename = get_new_database_path()
 
     def tearDown(self):
         try:
@@ -39,10 +30,10 @@ class GetReturnsNoneTestCase(unittest.TestCase):
             d.put(x, x * 40)
 
         data = d.get('bad key')
-        assert data == None
+        self.assertEqual(data, None)
 
-        data = d.get('a')
-        assert data == 'a'*40
+        data = d.get(string.letters[0])
+        self.assertEqual(data, string.letters[0]*40)
 
         count = 0
         c = d.cursor()
@@ -51,8 +42,8 @@ class GetReturnsNoneTestCase(unittest.TestCase):
             count = count + 1
             rec = c.next()
 
-        assert rec == None
-        assert count == 52
+        self.assertEqual(rec, None)
+        self.assertEqual(count, len(string.letters))
 
         c.close()
         d.close()
@@ -69,8 +60,8 @@ class GetReturnsNoneTestCase(unittest.TestCase):
         self.assertRaises(db.DBNotFoundError, d.get, 'bad key')
         self.assertRaises(KeyError, d.get, 'bad key')
 
-        data = d.get('a')
-        assert data == 'a'*40
+        data = d.get(string.letters[0])
+        self.assertEqual(data, string.letters[0]*40)
 
         count = 0
         exceptionHappened = 0
@@ -84,9 +75,9 @@ class GetReturnsNoneTestCase(unittest.TestCase):
                 exceptionHappened = 1
                 break
 
-        assert rec != None
-        assert exceptionHappened
-        assert count == 52
+        self.assertNotEqual(rec, None)
+        self.assert_(exceptionHappened)
+        self.assertEqual(count, len(string.letters))
 
         c.close()
         d.close()
diff --git a/Lib/bsddb/test/test_join.py b/Lib/bsddb/test/test_join.py
index 73edd11..9b45df8 100644
--- a/Lib/bsddb/test/test_join.py
+++ b/Lib/bsddb/test/test_join.py
@@ -1,27 +1,12 @@
 """TestCases for using the DB.join and DBCursor.join_item methods.
 """
 
-import sys, os, string
-import tempfile
-import time
-from pprint import pprint
-
-try:
-    from threading import Thread, currentThread
-    have_threads = 1
-except ImportError:
-    have_threads = 0
+import os
 
 import unittest
-from test_all import verbose
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, dbshelve
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, dbshelve
 
+from test_all import db, dbshelve, test_support, verbose, \
+        get_new_environment_path, get_new_database_path
 
 #----------------------------------------------------------------------
 
@@ -49,19 +34,13 @@ class JoinTestCase(unittest.TestCase):
 
     def setUp(self):
         self.filename = self.__class__.__name__ + '.db'
-        homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try: os.mkdir(homeDir)
-        except os.error: pass
+        self.homeDir = get_new_environment_path()
         self.env = db.DBEnv()
-        self.env.open(homeDir, db.DB_CREATE | db.DB_INIT_MPOOL | db.DB_INIT_LOCK )
+        self.env.open(self.homeDir, db.DB_CREATE | db.DB_INIT_MPOOL | db.DB_INIT_LOCK )
 
     def tearDown(self):
         self.env.close()
-        import glob
-        files = glob.glob(os.path.join(self.homeDir, '*'))
-        for file in files:
-            os.remove(file)
+        test_support.rmtree(self.homeDir)
 
     def test01_join(self):
         if verbose:
@@ -72,13 +51,13 @@ class JoinTestCase(unittest.TestCase):
         # create and populate primary index
         priDB = db.DB(self.env)
         priDB.open(self.filename, "primary", db.DB_BTREE, db.DB_CREATE)
-        map(lambda t, priDB=priDB: apply(priDB.put, t), ProductIndex)
+        map(lambda t, priDB=priDB: priDB.put(*t), ProductIndex)
 
         # create and populate secondary index
         secDB = db.DB(self.env)
         secDB.set_flags(db.DB_DUP | db.DB_DUPSORT)
         secDB.open(self.filename, "secondary", db.DB_BTREE, db.DB_CREATE)
-        map(lambda t, secDB=secDB: apply(secDB.put, t), ColorIndex)
+        map(lambda t, secDB=secDB: secDB.put(*t), ColorIndex)
 
         sCursor = None
         jCursor = None
@@ -88,7 +67,7 @@ class JoinTestCase(unittest.TestCase):
             # Don't do the .set() in an assert, or you can get a bogus failure
             # when running python -O
             tmp = sCursor.set('red')
-            assert tmp
+            self.assert_(tmp)
 
             # FIXME: jCursor doesn't properly hold a reference to its
             # cursors, if they are closed before jcursor is used it
diff --git a/Lib/bsddb/test/test_lock.py b/Lib/bsddb/test/test_lock.py
index 7d77798..47da392 100644
--- a/Lib/bsddb/test/test_lock.py
+++ b/Lib/bsddb/test/test_lock.py
@@ -2,49 +2,39 @@
 TestCases for testing the locking sub-system.
 """
 
-import sys, os, string
-import tempfile
 import time
-from pprint import pprint
-
-try:
-    from threading import Thread, currentThread
-    have_threads = 1
-except ImportError:
-    have_threads = 0
-
 
 import unittest
-from test_all import verbose
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db
-except ImportError:
-    # For Python 2.3
-    from bsddb import db
+from test_all import db, test_support, verbose, have_threads, \
+        get_new_environment_path, get_new_database_path
 
+if have_threads :
+    from threading import Thread
+    import sys
+    if sys.version_info[0] < 3 :
+        from threading import currentThread
+    else :
+        from threading import current_thread as currentThread
 
 #----------------------------------------------------------------------
 
 class LockingTestCase(unittest.TestCase):
+    import sys
+    if sys.version_info[:3] < (2, 4, 0):
+        def assertTrue(self, expr, msg=None):
+            self.failUnless(expr,msg=msg)
+
 
     def setUp(self):
-        homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try: os.mkdir(homeDir)
-        except os.error: pass
+        self.homeDir = get_new_environment_path()
         self.env = db.DBEnv()
-        self.env.open(homeDir, db.DB_THREAD | db.DB_INIT_MPOOL |
-                      db.DB_INIT_LOCK | db.DB_CREATE)
+        self.env.open(self.homeDir, db.DB_THREAD | db.DB_INIT_MPOOL |
+                                    db.DB_INIT_LOCK | db.DB_CREATE)
 
 
     def tearDown(self):
         self.env.close()
-        import glob
-        files = glob.glob(os.path.join(self.homeDir, '*'))
-        for file in files:
-            os.remove(file)
+        test_support.rmtree(self.homeDir)
 
 
     def test01_simple(self):
@@ -58,12 +48,10 @@ class LockingTestCase(unittest.TestCase):
         lock = self.env.lock_get(anID, "some locked thing", db.DB_LOCK_WRITE)
         if verbose:
             print "Aquired lock: %s" % lock
-        time.sleep(1)
         self.env.lock_put(lock)
         if verbose:
             print "Released lock: %s" % lock
-
-
+        self.env.lock_id_free(anID)
 
 
     def test02_threaded(self):
@@ -73,39 +61,86 @@ class LockingTestCase(unittest.TestCase):
 
         threads = []
         threads.append(Thread(target = self.theThread,
-                              args=(5, db.DB_LOCK_WRITE)))
+                              args=(db.DB_LOCK_WRITE,)))
         threads.append(Thread(target = self.theThread,
-                              args=(1, db.DB_LOCK_READ)))
+                              args=(db.DB_LOCK_READ,)))
         threads.append(Thread(target = self.theThread,
-                              args=(1, db.DB_LOCK_READ)))
+                              args=(db.DB_LOCK_READ,)))
         threads.append(Thread(target = self.theThread,
-                              args=(1, db.DB_LOCK_WRITE)))
+                              args=(db.DB_LOCK_WRITE,)))
         threads.append(Thread(target = self.theThread,
-                              args=(1, db.DB_LOCK_READ)))
+                              args=(db.DB_LOCK_READ,)))
         threads.append(Thread(target = self.theThread,
-                              args=(1, db.DB_LOCK_READ)))
+                              args=(db.DB_LOCK_READ,)))
         threads.append(Thread(target = self.theThread,
-                              args=(1, db.DB_LOCK_WRITE)))
+                              args=(db.DB_LOCK_WRITE,)))
         threads.append(Thread(target = self.theThread,
-                              args=(1, db.DB_LOCK_WRITE)))
+                              args=(db.DB_LOCK_WRITE,)))
         threads.append(Thread(target = self.theThread,
-                              args=(1, db.DB_LOCK_WRITE)))
+                              args=(db.DB_LOCK_WRITE,)))
 
         for t in threads:
+            import sys
+            if sys.version_info[0] < 3 :
+                t.setDaemon(True)
+            else :
+                t.daemon = True
             t.start()
         for t in threads:
             t.join()
 
-    def test03_set_timeout(self):
-        # test that the set_timeout call works
-        if hasattr(self.env, 'set_timeout'):
-            self.env.set_timeout(0, db.DB_SET_LOCK_TIMEOUT)
-            self.env.set_timeout(0, db.DB_SET_TXN_TIMEOUT)
-            self.env.set_timeout(123456, db.DB_SET_LOCK_TIMEOUT)
-            self.env.set_timeout(7890123, db.DB_SET_TXN_TIMEOUT)
+    def test03_lock_timeout(self):
+        self.env.set_timeout(0, db.DB_SET_LOCK_TIMEOUT)
+        self.env.set_timeout(0, db.DB_SET_TXN_TIMEOUT)
+        self.env.set_timeout(123456, db.DB_SET_LOCK_TIMEOUT)
+        self.env.set_timeout(7890123, db.DB_SET_TXN_TIMEOUT)
+
+        def deadlock_detection() :
+            while not deadlock_detection.end :
+                deadlock_detection.count = \
+                    self.env.lock_detect(db.DB_LOCK_EXPIRE)
+                if deadlock_detection.count :
+                    while not deadlock_detection.end :
+                        pass
+                    break
+                time.sleep(0.01)
+
+        deadlock_detection.end=False
+        deadlock_detection.count=0
+        t=Thread(target=deadlock_detection)
+        import sys
+        if sys.version_info[0] < 3 :
+            t.setDaemon(True)
+        else :
+            t.daemon = True
+        t.start()
+        self.env.set_timeout(100000, db.DB_SET_LOCK_TIMEOUT)
+        anID = self.env.lock_id()
+        anID2 = self.env.lock_id()
+        self.assertNotEqual(anID, anID2)
+        lock = self.env.lock_get(anID, "shared lock", db.DB_LOCK_WRITE)
+        start_time=time.time()
+        self.assertRaises(db.DBLockNotGrantedError,
+                self.env.lock_get,anID2, "shared lock", db.DB_LOCK_READ)
+        end_time=time.time()
+        deadlock_detection.end=True
+        self.assertTrue((end_time-start_time) >= 0.0999)
+        self.env.lock_put(lock)
+        t.join()
+
+        self.env.lock_id_free(anID)
+        self.env.lock_id_free(anID2)
+
+        if db.version() >= (4,6):
+            self.assertTrue(deadlock_detection.count>0)
+
+    def theThread(self, lockType):
+        import sys
+        if sys.version_info[0] < 3 :
+            name = currentThread().getName()
+        else :
+            name = currentThread().name
 
-    def theThread(self, sleepTime, lockType):
-        name = currentThread().getName()
         if lockType ==  db.DB_LOCK_WRITE:
             lt = "write"
         else:
@@ -115,15 +150,16 @@ class LockingTestCase(unittest.TestCase):
         if verbose:
             print "%s: locker ID: %s" % (name, anID)
 
-        lock = self.env.lock_get(anID, "some locked thing", lockType)
-        if verbose:
-            print "%s: Aquired %s lock: %s" % (name, lt, lock)
+        for i in xrange(1000) :
+            lock = self.env.lock_get(anID, "some locked thing", lockType)
+            if verbose:
+                print "%s: Aquired %s lock: %s" % (name, lt, lock)
 
-        time.sleep(sleepTime)
+            self.env.lock_put(lock)
+            if verbose:
+                print "%s: Released %s lock: %s" % (name, lt, lock)
 
-        self.env.lock_put(lock)
-        if verbose:
-            print "%s: Released %s lock: %s" % (name, lt, lock)
+        self.env.lock_id_free(anID)
 
 
 #----------------------------------------------------------------------
diff --git a/Lib/bsddb/test/test_misc.py b/Lib/bsddb/test/test_misc.py
index 01b3699..0cf75e9 100644
--- a/Lib/bsddb/test/test_misc.py
+++ b/Lib/bsddb/test/test_misc.py
@@ -2,35 +2,20 @@
 """
 
 import os
-import sys
 import unittest
 
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, dbshelve, hashopen
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, dbshelve, hashopen
+from test_all import db, dbshelve, hashopen, test_support, get_new_environment_path, get_new_database_path
 
 #----------------------------------------------------------------------
 
 class MiscTestCase(unittest.TestCase):
     def setUp(self):
-        self.filename = self.__class__.__name__ + '.db'
-        homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try:
-            os.mkdir(homeDir)
-        except OSError:
-            pass
+        self.filename = get_new_database_path()
+        self.homeDir = get_new_environment_path()
 
     def tearDown(self):
-        try:
-            os.remove(self.filename)
-        except OSError:
-            pass
-        import shutil
-        shutil.rmtree(self.homeDir)
+        test_support.unlink(self.filename)
+        test_support.rmtree(self.homeDir)
 
     def test01_badpointer(self):
         dbs = dbshelve.open(self.filename)
@@ -40,9 +25,13 @@ class MiscTestCase(unittest.TestCase):
     def test02_db_home(self):
         env = db.DBEnv()
         # check for crash fixed when db_home is used before open()
-        assert env.db_home is None
+        self.assert_(env.db_home is None)
         env.open(self.homeDir, db.DB_CREATE)
-        assert self.homeDir == env.db_home
+        import sys
+        if sys.version_info[0] < 3 :
+            self.assertEqual(self.homeDir, env.db_home)
+        else :
+            self.assertEqual(bytes(self.homeDir, "ascii"), env.db_home)
 
     def test03_repr_closed_db(self):
         db = hashopen(self.filename)
@@ -50,6 +39,18 @@ class MiscTestCase(unittest.TestCase):
         rp = repr(db)
         self.assertEquals(rp, "{}")
 
+    def test04_repr_db(self) :
+        db = hashopen(self.filename)
+        d = {}
+        for i in xrange(100) :
+            db[repr(i)] = repr(100*i)
+            d[repr(i)] = repr(100*i)
+        db.close()
+        db = hashopen(self.filename)
+        rp = repr(db)
+        self.assertEquals(rp, repr(d))
+        db.close()
+
     # http://sourceforge.net/tracker/index.php?func=detail&aid=1708868&group_id=13900&atid=313900
     #
     # See the bug report for details.
@@ -57,7 +58,7 @@ class MiscTestCase(unittest.TestCase):
     # The problem was that make_key_dbt() was not allocating a copy of
     # string keys but FREE_DBT() was always being told to free it when the
     # database was opened with DB_THREAD.
-    def test04_double_free_make_key_dbt(self):
+    def test05_double_free_make_key_dbt(self):
         try:
             db1 = db.DB()
             db1.open(self.filename, None, db.DB_BTREE,
@@ -68,9 +69,9 @@ class MiscTestCase(unittest.TestCase):
             # double free happened during exit from DBC_get
         finally:
             db1.close()
-            os.unlink(self.filename)
+            test_support.unlink(self.filename)
 
-    def test05_key_with_null_bytes(self):
+    def test06_key_with_null_bytes(self):
         try:
             db1 = db.DB()
             db1.open(self.filename, None, db.DB_HASH, db.DB_CREATE)
@@ -87,7 +88,35 @@ class MiscTestCase(unittest.TestCase):
             self.assertEqual(db1['aaa'], 'eh eh eh!')
         finally:
             db1.close()
-            os.unlink(self.filename)
+            test_support.unlink(self.filename)
+
+    def test07_DB_set_flags_persists(self):
+        if db.version() < (4,2):
+            # The get_flags API required for this to work is only available
+            # in Berkeley DB >= 4.2
+            return
+        try:
+            db1 = db.DB()
+            db1.set_flags(db.DB_DUPSORT)
+            db1.open(self.filename, db.DB_HASH, db.DB_CREATE)
+            db1['a'] = 'eh'
+            db1['a'] = 'A'
+            self.assertEqual([('a', 'A')], db1.items())
+            db1.put('a', 'Aa')
+            self.assertEqual([('a', 'A'), ('a', 'Aa')], db1.items())
+            db1.close()
+            db1 = db.DB()
+            # no set_flags call, we're testing that it reads and obeys
+            # the flags on open.
+            db1.open(self.filename, db.DB_HASH)
+            self.assertEqual([('a', 'A'), ('a', 'Aa')], db1.items())
+            # if it read the flags right this will replace all values
+            # for key 'a' instead of adding a new one.  (as a dict should)
+            db1['a'] = 'new A'
+            self.assertEqual([('a', 'new A')], db1.items())
+        finally:
+            db1.close()
+            test_support.unlink(self.filename)
 
 
 #----------------------------------------------------------------------
diff --git a/Lib/bsddb/test/test_pickle.py b/Lib/bsddb/test/test_pickle.py
index 3916e5c..489c093 100644
--- a/Lib/bsddb/test/test_pickle.py
+++ b/Lib/bsddb/test/test_pickle.py
@@ -1,42 +1,29 @@
 
-import sys, os, string
+import os
 import pickle
 try:
     import cPickle
 except ImportError:
     cPickle = None
 import unittest
-import glob
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db
-except ImportError, e:
-    # For Python 2.3
-    from bsddb import db
 
+from test_all import db, test_support, get_new_environment_path, get_new_database_path
 
 #----------------------------------------------------------------------
 
 class pickleTestCase(unittest.TestCase):
     """Verify that DBError can be pickled and unpickled"""
-    db_home = 'db_home'
     db_name = 'test-dbobj.db'
 
     def setUp(self):
-        homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try: os.mkdir(homeDir)
-        except os.error: pass
+        self.homeDir = get_new_environment_path()
 
     def tearDown(self):
         if hasattr(self, 'db'):
             del self.db
         if hasattr(self, 'env'):
             del self.env
-        files = glob.glob(os.path.join(self.homeDir, '*'))
-        for file in files:
-            os.remove(file)
+        test_support.rmtree(self.homeDir)
 
     def _base_test_pickle_DBError(self, pickle):
         self.env = db.DBEnv()
@@ -44,7 +31,7 @@ class pickleTestCase(unittest.TestCase):
         self.db = db.DB(self.env)
         self.db.open(self.db_name, db.DB_HASH, db.DB_CREATE)
         self.db.put('spam', 'eggs')
-        assert self.db['spam'] == 'eggs'
+        self.assertEqual(self.db['spam'], 'eggs')
         try:
             self.db.put('spam', 'ham', flags=db.DB_NOOVERWRITE)
         except db.DBError, egg:
diff --git a/Lib/bsddb/test/test_queue.py b/Lib/bsddb/test/test_queue.py
index 95cf20d..251a8cf 100644
--- a/Lib/bsddb/test/test_queue.py
+++ b/Lib/bsddb/test/test_queue.py
@@ -2,26 +2,17 @@
 TestCases for exercising a Queue DB.
 """
 
-import sys, os, string
-import tempfile
+import os, string
 from pprint import pprint
 import unittest
 
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db
-except ImportError:
-    # For Python 2.3
-    from bsddb import db
-
-from test_all import verbose
-
+from test_all import db, verbose, get_new_database_path
 
 #----------------------------------------------------------------------
 
 class SimpleQueueTestCase(unittest.TestCase):
     def setUp(self):
-        self.filename = tempfile.mktemp()
+        self.filename = get_new_database_path()
 
     def tearDown(self):
         try:
@@ -48,14 +39,14 @@ class SimpleQueueTestCase(unittest.TestCase):
         for x in string.letters:
             d.append(x * 40)
 
-        assert len(d) == 52
+        self.assertEqual(len(d), len(string.letters))
 
         d.put(100, "some more data")
         d.put(101, "and some more ")
         d.put(75,  "out of order")
         d.put(1,   "replacement data")
 
-        assert len(d) == 55
+        self.assertEqual(len(d), len(string.letters)+3)
 
         if verbose:
             print "before close" + '-' * 30
@@ -70,7 +61,11 @@ class SimpleQueueTestCase(unittest.TestCase):
             print "after open" + '-' * 30
             pprint(d.stat())
 
-        d.append("one more")
+        # Test "txn" as a positional parameter
+        d.append("one more", None)
+        # Test "txn" as a keyword parameter
+        d.append("another one", txn=None)
+
         c = d.cursor()
 
         if verbose:
@@ -88,9 +83,9 @@ class SimpleQueueTestCase(unittest.TestCase):
             print "after consume loop" + '-' * 30
             pprint(d.stat())
 
-        assert len(d) == 0, \
+        self.assertEqual(len(d), 0, \
                "if you see this message then you need to rebuild " \
-               "BerkeleyDB 3.1.17 with the patch in patches/qam_stat.diff"
+               "Berkeley DB 3.1.17 with the patch in patches/qam_stat.diff")
 
         d.close()
 
@@ -120,14 +115,14 @@ class SimpleQueueTestCase(unittest.TestCase):
         for x in string.letters:
             d.append(x * 40)
 
-        assert len(d) == 52
+        self.assertEqual(len(d), len(string.letters))
 
         d.put(100, "some more data")
         d.put(101, "and some more ")
         d.put(75,  "out of order")
         d.put(1,   "replacement data")
 
-        assert len(d) == 55
+        self.assertEqual(len(d), len(string.letters)+3)
 
         if verbose:
             print "before close" + '-' * 30
diff --git a/Lib/bsddb/test/test_recno.py b/Lib/bsddb/test/test_recno.py
index 4b36a40..d332497 100644
--- a/Lib/bsddb/test/test_recno.py
+++ b/Lib/bsddb/test/test_recno.py
@@ -2,20 +2,11 @@
 """
 
 import os
-import sys
 import errno
-import tempfile
 from pprint import pprint
 import unittest
 
-from test_all import verbose
-
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db
-except ImportError:
-    # For Python 2.3
-    from bsddb import db
+from test_all import db, test_support, verbose, get_new_environment_path, get_new_database_path
 
 letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
 
@@ -23,14 +14,19 @@ letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
 #----------------------------------------------------------------------
 
 class SimpleRecnoTestCase(unittest.TestCase):
+    import sys
+    if sys.version_info[:3] < (2, 4, 0):
+        def assertFalse(self, expr, msg=None):
+            self.failIf(expr,msg=msg)
+
     def setUp(self):
-        self.filename = tempfile.mktemp()
+        self.filename = get_new_database_path()
+        self.homeDir = None
 
     def tearDown(self):
-        try:
-            os.remove(self.filename)
-        except OSError, e:
-            if e.errno <> errno.EEXIST: raise
+        test_support.unlink(self.filename)
+        if self.homeDir:
+            test_support.rmtree(self.homeDir)
 
     def test01_basic(self):
         d = db.DB()
@@ -42,8 +38,8 @@ class SimpleRecnoTestCase(unittest.TestCase):
 
         for x in letters:
             recno = d.append(x * 60)
-            assert type(recno) == type(0)
-            assert recno >= 1
+            self.assertTrue(isinstance(recno, int))
+            self.assertTrue(recno >= 1)
             if verbose:
                 print recno,
 
@@ -58,13 +54,13 @@ class SimpleRecnoTestCase(unittest.TestCase):
             if verbose:
                 print data
 
-            assert type(data) == type("")
-            assert data == d.get(recno)
+            self.assertTrue(isinstance(data, str))
+            self.assertEqual(data, d.get(recno))
 
         try:
             data = d[0]  # This should raise a KeyError!?!?!
         except db.DBInvalidArgError, val:
-            assert val[0] == db.EINVAL
+            self.assertEqual(val.args[0], db.EINVAL)
             if verbose: print val
         else:
             self.fail("expected exception")
@@ -90,35 +86,35 @@ class SimpleRecnoTestCase(unittest.TestCase):
             if get_returns_none:
                 self.fail("unexpected exception")
         else:
-            assert data == None
+            self.assertEqual(data, None)
 
         keys = d.keys()
         if verbose:
             print keys
-        assert type(keys) == type([])
-        assert type(keys[0]) == type(123)
-        assert len(keys) == len(d)
+        self.assertTrue(isinstance(keys, list))
+        self.assertTrue(isinstance(keys[0], int))
+        self.assertEqual(len(keys), len(d))
 
         items = d.items()
         if verbose:
             pprint(items)
-        assert type(items) == type([])
-        assert type(items[0]) == type(())
-        assert len(items[0]) == 2
-        assert type(items[0][0]) == type(123)
-        assert type(items[0][1]) == type("")
-        assert len(items) == len(d)
+        self.assertTrue(isinstance(items, list))
+        self.assertTrue(isinstance(items[0], tuple))
+        self.assertEqual(len(items[0]), 2)
+        self.assertTrue(isinstance(items[0][0], int))
+        self.assertTrue(isinstance(items[0][1], str))
+        self.assertEqual(len(items), len(d))
 
-        assert d.has_key(25)
+        self.assertTrue(d.has_key(25))
 
         del d[25]
-        assert not d.has_key(25)
+        self.assertFalse(d.has_key(25))
 
         d.delete(13)
-        assert not d.has_key(13)
+        self.assertFalse(d.has_key(13))
 
         data = d.get_both(26, "z" * 60)
-        assert data == "z" * 60, 'was %r' % data
+        self.assertEqual(data, "z" * 60, 'was %r' % data)
         if verbose:
             print data
 
@@ -142,7 +138,7 @@ class SimpleRecnoTestCase(unittest.TestCase):
 
         c.set(50)
         rec = c.current()
-        assert rec == (50, "a replacement record")
+        self.assertEqual(rec, (50, "a replacement record"))
         if verbose:
             print rec
 
@@ -150,10 +146,10 @@ class SimpleRecnoTestCase(unittest.TestCase):
         if verbose:
             print rec
 
-        # test that non-existant key lookups work (and that
+        # test that non-existent key lookups work (and that
         # DBC_set_range doesn't have a memleak under valgrind)
         rec = c.set_range(999999)
-        assert rec == None
+        self.assertEqual(rec, None)
         if verbose:
             print rec
 
@@ -166,7 +162,7 @@ class SimpleRecnoTestCase(unittest.TestCase):
 
         # put a record beyond the consecutive end of the recno's
         d[100] = "way out there"
-        assert d[100] == "way out there"
+        self.assertEqual(d[100], "way out there")
 
         try:
             data = d[99]
@@ -181,7 +177,7 @@ class SimpleRecnoTestCase(unittest.TestCase):
             if get_returns_none:
                 self.fail("unexpected DBKeyEmptyError exception")
             else:
-                assert val[0] == db.DB_KEYEMPTY
+                self.assertEqual(val.args[0], db.DB_KEYEMPTY)
                 if verbose: print val
         else:
             if not get_returns_none:
@@ -203,7 +199,8 @@ class SimpleRecnoTestCase(unittest.TestCase):
         just a line in the file, but you can set a different record delimiter
         if needed.
         """
-        homeDir = os.path.join(tempfile.gettempdir(), 'db_home')
+        homeDir = get_new_environment_path()
+        self.homeDir = homeDir
         source = os.path.join(homeDir, 'test_recno.txt')
         if not os.path.isdir(homeDir):
             os.mkdir(homeDir)
@@ -231,7 +228,7 @@ class SimpleRecnoTestCase(unittest.TestCase):
             print data
             print text.split('\n')
 
-        assert text.split('\n') == data
+        self.assertEqual(text.split('\n'), data)
 
         # open as a DB again
         d = db.DB()
@@ -250,8 +247,8 @@ class SimpleRecnoTestCase(unittest.TestCase):
             print text
             print text.split('\n')
 
-        assert text.split('\n') == \
-             "The quick reddish-brown fox jumped over the comatose dog".split()
+        self.assertEqual(text.split('\n'),
+           "The quick reddish-brown fox jumped over the comatose dog".split())
 
     def test03_FixedLength(self):
         d = db.DB()
@@ -268,7 +265,7 @@ class SimpleRecnoTestCase(unittest.TestCase):
         try:                    # this one will fail
             d.append('bad' * 20)
         except db.DBInvalidArgError, val:
-            assert val[0] == db.EINVAL
+            self.assertEqual(val.args[0], db.EINVAL)
             if verbose: print val
         else:
             self.fail("expected exception")
diff --git a/Lib/bsddb/test/test_replication.py b/Lib/bsddb/test/test_replication.py
new file mode 100644
index 0000000..fabc165
--- /dev/null
+++ b/Lib/bsddb/test/test_replication.py
@@ -0,0 +1,475 @@
+"""TestCases for distributed transactions.
+"""
+
+import os
+import time
+import unittest
+import weakref
+
+from test_all import db, test_support, have_threads, verbose, \
+        get_new_environment_path, get_new_database_path
+
+
+#----------------------------------------------------------------------
+
+class DBReplicationManager(unittest.TestCase):
+    import sys
+    if sys.version_info[:3] < (2, 4, 0):
+        def assertTrue(self, expr, msg=None):
+            self.failUnless(expr,msg=msg)
+
+    def setUp(self) :
+        self.homeDirMaster = get_new_environment_path()
+        self.homeDirClient = get_new_environment_path()
+
+        self.dbenvMaster = db.DBEnv()
+        self.dbenvClient = db.DBEnv()
+
+        # Must use "DB_THREAD" because the Replication Manager will
+        # be executed in other threads but will use the same environment.
+        # http://forums.oracle.com/forums/thread.jspa?threadID=645788&tstart=0
+        self.dbenvMaster.open(self.homeDirMaster, db.DB_CREATE | db.DB_INIT_TXN
+                | db.DB_INIT_LOG | db.DB_INIT_MPOOL | db.DB_INIT_LOCK |
+                db.DB_INIT_REP | db.DB_RECOVER | db.DB_THREAD, 0666)
+        self.dbenvClient.open(self.homeDirClient, db.DB_CREATE | db.DB_INIT_TXN
+                | db.DB_INIT_LOG | db.DB_INIT_MPOOL | db.DB_INIT_LOCK |
+                db.DB_INIT_REP | db.DB_RECOVER | db.DB_THREAD, 0666)
+
+        wr = weakref.ref(self)
+        self.confirmed_master=self.client_startupdone=False
+        def confirmed_master(a,b,c) :
+            if b==db.DB_EVENT_REP_MASTER :
+                self = wr()
+                self.confirmed_master=True
+
+        def client_startupdone(a,b,c) :
+            if b==db.DB_EVENT_REP_STARTUPDONE :
+                self = wr()
+                self.client_startupdone=True
+
+        self.dbenvMaster.set_event_notify(confirmed_master)
+        self.dbenvClient.set_event_notify(client_startupdone)
+
+        #self.dbenvMaster.set_verbose(db.DB_VERB_REPLICATION, True)
+        #self.dbenvMaster.set_verbose(db.DB_VERB_FILEOPS_ALL, True)
+        #self.dbenvClient.set_verbose(db.DB_VERB_REPLICATION, True)
+        #self.dbenvClient.set_verbose(db.DB_VERB_FILEOPS_ALL, True)
+
+        self.dbMaster = self.dbClient = None
+
+
+    def tearDown(self):
+        if self.dbClient :
+            self.dbClient.close()
+        if self.dbMaster :
+            self.dbMaster.close()
+        self.dbenvClient.close()
+        self.dbenvMaster.close()
+        test_support.rmtree(self.homeDirClient)
+        test_support.rmtree(self.homeDirMaster)
+
+    def test01_basic_replication(self) :
+        master_port = test_support.find_unused_port()
+        self.dbenvMaster.repmgr_set_local_site("127.0.0.1", master_port)
+        client_port = test_support.find_unused_port()
+        self.dbenvClient.repmgr_set_local_site("127.0.0.1", client_port)
+        self.dbenvMaster.repmgr_add_remote_site("127.0.0.1", client_port)
+        self.dbenvClient.repmgr_add_remote_site("127.0.0.1", master_port)
+        self.dbenvMaster.rep_set_nsites(2)
+        self.dbenvClient.rep_set_nsites(2)
+        self.dbenvMaster.rep_set_priority(10)
+        self.dbenvClient.rep_set_priority(0)
+
+        self.dbenvMaster.rep_set_timeout(db.DB_REP_CONNECTION_RETRY,100123)
+        self.dbenvClient.rep_set_timeout(db.DB_REP_CONNECTION_RETRY,100321)
+        self.assertEquals(self.dbenvMaster.rep_get_timeout(
+            db.DB_REP_CONNECTION_RETRY), 100123)
+        self.assertEquals(self.dbenvClient.rep_get_timeout(
+            db.DB_REP_CONNECTION_RETRY), 100321)
+
+        self.dbenvMaster.rep_set_timeout(db.DB_REP_ELECTION_TIMEOUT, 100234)
+        self.dbenvClient.rep_set_timeout(db.DB_REP_ELECTION_TIMEOUT, 100432)
+        self.assertEquals(self.dbenvMaster.rep_get_timeout(
+            db.DB_REP_ELECTION_TIMEOUT), 100234)
+        self.assertEquals(self.dbenvClient.rep_get_timeout(
+            db.DB_REP_ELECTION_TIMEOUT), 100432)
+
+        self.dbenvMaster.rep_set_timeout(db.DB_REP_ELECTION_RETRY, 100345)
+        self.dbenvClient.rep_set_timeout(db.DB_REP_ELECTION_RETRY, 100543)
+        self.assertEquals(self.dbenvMaster.rep_get_timeout(
+            db.DB_REP_ELECTION_RETRY), 100345)
+        self.assertEquals(self.dbenvClient.rep_get_timeout(
+            db.DB_REP_ELECTION_RETRY), 100543)
+
+        self.dbenvMaster.repmgr_set_ack_policy(db.DB_REPMGR_ACKS_ALL)
+        self.dbenvClient.repmgr_set_ack_policy(db.DB_REPMGR_ACKS_ALL)
+
+        self.dbenvMaster.repmgr_start(1, db.DB_REP_MASTER);
+        self.dbenvClient.repmgr_start(1, db.DB_REP_CLIENT);
+
+        self.assertEquals(self.dbenvMaster.rep_get_nsites(),2)
+        self.assertEquals(self.dbenvClient.rep_get_nsites(),2)
+        self.assertEquals(self.dbenvMaster.rep_get_priority(),10)
+        self.assertEquals(self.dbenvClient.rep_get_priority(),0)
+        self.assertEquals(self.dbenvMaster.repmgr_get_ack_policy(),
+                db.DB_REPMGR_ACKS_ALL)
+        self.assertEquals(self.dbenvClient.repmgr_get_ack_policy(),
+                db.DB_REPMGR_ACKS_ALL)
+
+        # The timeout is necessary in BDB 4.5, since DB_EVENT_REP_STARTUPDONE
+        # is not generated if the master has no new transactions.
+        # This is solved in BDB 4.6 (#15542).
+        import time
+        timeout = time.time()+60
+        while (time.time()<timeout) and not (self.confirmed_master and self.client_startupdone) :
+            time.sleep(0.02)
+        # self.client_startupdone does not always get set to True within
+        # the timeout.  On windows this may be a deep issue, on other
+        # platforms it is likely just a timing issue, especially on slow
+        # virthost buildbots (see issue 3892 for more).  Even though
+        # the timeout triggers, the rest of this test method usually passes
+        # (but not all of it always, see below).  So we just note the
+        # timeout on stderr and keep soldering on.
+        if time.time()>timeout:
+            import sys
+            print >> sys.stderr, ("XXX: timeout happened before"
+                "startup was confirmed - see issue 3892")
+            startup_timeout = True
+
+        d = self.dbenvMaster.repmgr_site_list()
+        self.assertEquals(len(d), 1)
+        self.assertEquals(d[0][0], "127.0.0.1")
+        self.assertEquals(d[0][1], client_port)
+        self.assertTrue((d[0][2]==db.DB_REPMGR_CONNECTED) or \
+                (d[0][2]==db.DB_REPMGR_DISCONNECTED))
+
+        d = self.dbenvClient.repmgr_site_list()
+        self.assertEquals(len(d), 1)
+        self.assertEquals(d[0][0], "127.0.0.1")
+        self.assertEquals(d[0][1], master_port)
+        self.assertTrue((d[0][2]==db.DB_REPMGR_CONNECTED) or \
+                (d[0][2]==db.DB_REPMGR_DISCONNECTED))
+
+        if db.version() >= (4,6) :
+            d = self.dbenvMaster.repmgr_stat(flags=db.DB_STAT_CLEAR);
+            self.assertTrue("msgs_queued" in d)
+
+        self.dbMaster=db.DB(self.dbenvMaster)
+        txn=self.dbenvMaster.txn_begin()
+        self.dbMaster.open("test", db.DB_HASH, db.DB_CREATE, 0666, txn=txn)
+        txn.commit()
+
+        import time,os.path
+        timeout=time.time()+10
+        while (time.time()<timeout) and \
+          not (os.path.exists(os.path.join(self.homeDirClient,"test"))) :
+            time.sleep(0.01)
+
+        self.dbClient=db.DB(self.dbenvClient)
+        while True :
+            txn=self.dbenvClient.txn_begin()
+            try :
+                self.dbClient.open("test", db.DB_HASH, flags=db.DB_RDONLY,
+                        mode=0666, txn=txn)
+            except db.DBRepHandleDeadError :
+                txn.abort()
+                self.dbClient.close()
+                self.dbClient=db.DB(self.dbenvClient)
+                continue
+
+            txn.commit()
+            break
+
+        txn=self.dbenvMaster.txn_begin()
+        self.dbMaster.put("ABC", "123", txn=txn)
+        txn.commit()
+        import time
+        timeout=time.time()+10
+        v=None
+        while (time.time()<timeout) and (v is None) :
+            txn=self.dbenvClient.txn_begin()
+            v=self.dbClient.get("ABC", txn=txn)
+            txn.commit()
+            if v is None :
+                time.sleep(0.02)
+        # If startup did not happen before the timeout above, then this test
+        # sometimes fails.  This happens randomly, which causes buildbot
+        # instability, but all the other bsddb tests pass.  Since bsddb3 in the
+        # stdlib is currently not getting active maintenance, and is gone in
+        # py3k, we just skip the end of the test in that case.
+        if time.time()>=timeout and startup_timeout:
+            self.skipTest("replication test skipped due to random failure, "
+                "see issue 3892")
+        self.assertTrue(time.time()<timeout)
+        self.assertEquals("123", v)
+
+        txn=self.dbenvMaster.txn_begin()
+        self.dbMaster.delete("ABC", txn=txn)
+        txn.commit()
+        timeout=time.time()+10
+        while (time.time()<timeout) and (v is not None) :
+            txn=self.dbenvClient.txn_begin()
+            v=self.dbClient.get("ABC", txn=txn)
+            txn.commit()
+            if v is None :
+                time.sleep(0.02)
+        self.assertTrue(time.time()<timeout)
+        self.assertEquals(None, v)
+
+class DBBaseReplication(DBReplicationManager):
+    def setUp(self) :
+        DBReplicationManager.setUp(self)
+        wr = weakref.ref(self)
+        def confirmed_master(a,b,c) :
+            if (b == db.DB_EVENT_REP_MASTER) or (b == db.DB_EVENT_REP_ELECTED) :
+                self = wr()
+                self.confirmed_master = True
+
+        def client_startupdone(a,b,c) :
+            if b == db.DB_EVENT_REP_STARTUPDONE :
+                self = wr()
+                self.client_startupdone = True
+
+        self.dbenvMaster.set_event_notify(confirmed_master)
+        self.dbenvClient.set_event_notify(client_startupdone)
+
+        import Queue
+        self.m2c = Queue.Queue()
+        self.c2m = Queue.Queue()
+
+        # There are only two nodes, so we don't need to
+        # do any routing decision
+        def m2c(dbenv, control, rec, lsnp, envid, flags) :
+            self = wr()
+            self.m2c.put((control, rec))
+
+        def c2m(dbenv, control, rec, lsnp, envid, flags) :
+            self = wr()
+            self.c2m.put((control, rec))
+
+        self.dbenvMaster.rep_set_transport(13,m2c)
+        self.dbenvMaster.rep_set_priority(10)
+        self.dbenvClient.rep_set_transport(3,c2m)
+        self.dbenvClient.rep_set_priority(0)
+
+        self.assertEquals(self.dbenvMaster.rep_get_priority(),10)
+        self.assertEquals(self.dbenvClient.rep_get_priority(),0)
+
+        #self.dbenvMaster.set_verbose(db.DB_VERB_REPLICATION, True)
+        #self.dbenvMaster.set_verbose(db.DB_VERB_FILEOPS_ALL, True)
+        #self.dbenvClient.set_verbose(db.DB_VERB_REPLICATION, True)
+        #self.dbenvClient.set_verbose(db.DB_VERB_FILEOPS_ALL, True)
+
+        def thread_master() :
+            self = wr()
+            return self.thread_do(self.dbenvMaster, self.c2m, 3,
+                    self.master_doing_election, True)
+
+        def thread_client() :
+            self = wr()
+            return self.thread_do(self.dbenvClient, self.m2c, 13,
+                    self.client_doing_election, False)
+
+        from threading import Thread
+        t_m=Thread(target=thread_master)
+        t_c=Thread(target=thread_client)
+        import sys
+        if sys.version_info[0] < 3 :
+            t_m.setDaemon(True)
+            t_c.setDaemon(True)
+        else :
+            t_m.daemon = True
+            t_c.daemon = True
+
+        self.t_m = t_m
+        self.t_c = t_c
+
+        self.dbMaster = self.dbClient = None
+
+        self.master_doing_election=[False]
+        self.client_doing_election=[False]
+
+
+    def tearDown(self):
+        if self.dbClient :
+            self.dbClient.close()
+        if self.dbMaster :
+            self.dbMaster.close()
+        self.m2c.put(None)
+        self.c2m.put(None)
+        self.t_m.join()
+        self.t_c.join()
+        self.dbenvClient.close()
+        self.dbenvMaster.close()
+        test_support.rmtree(self.homeDirClient)
+        test_support.rmtree(self.homeDirMaster)
+
+    def basic_rep_threading(self) :
+        self.dbenvMaster.rep_start(flags=db.DB_REP_MASTER)
+        self.dbenvClient.rep_start(flags=db.DB_REP_CLIENT)
+
+        def thread_do(env, q, envid, election_status, must_be_master) :
+            while True :
+                v=q.get()
+                if v is None : return
+                env.rep_process_message(v[0], v[1], envid)
+
+        self.thread_do = thread_do
+
+        self.t_m.start()
+        self.t_c.start()
+
+    def test01_basic_replication(self) :
+        self.basic_rep_threading()
+
+        # The timeout is necessary in BDB 4.5, since DB_EVENT_REP_STARTUPDONE
+        # is not generated if the master has no new transactions.
+        # This is solved in BDB 4.6 (#15542).
+        import time
+        timeout = time.time()+60
+        while (time.time()<timeout) and not (self.confirmed_master and
+                self.client_startupdone) :
+            time.sleep(0.02)
+        self.assertTrue(time.time()<timeout)
+
+        self.dbMaster=db.DB(self.dbenvMaster)
+        txn=self.dbenvMaster.txn_begin()
+        self.dbMaster.open("test", db.DB_HASH, db.DB_CREATE, 0666, txn=txn)
+        txn.commit()
+
+        import time,os.path
+        timeout=time.time()+10
+        while (time.time()<timeout) and \
+          not (os.path.exists(os.path.join(self.homeDirClient,"test"))) :
+            time.sleep(0.01)
+
+        self.dbClient=db.DB(self.dbenvClient)
+        while True :
+            txn=self.dbenvClient.txn_begin()
+            try :
+                self.dbClient.open("test", db.DB_HASH, flags=db.DB_RDONLY,
+                        mode=0666, txn=txn)
+            except db.DBRepHandleDeadError :
+                txn.abort()
+                self.dbClient.close()
+                self.dbClient=db.DB(self.dbenvClient)
+                continue
+
+            txn.commit()
+            break
+
+        txn=self.dbenvMaster.txn_begin()
+        self.dbMaster.put("ABC", "123", txn=txn)
+        txn.commit()
+        import time
+        timeout=time.time()+10
+        v=None
+        while (time.time()<timeout) and (v is None) :
+            txn=self.dbenvClient.txn_begin()
+            v=self.dbClient.get("ABC", txn=txn)
+            txn.commit()
+            if v is None :
+                time.sleep(0.02)
+        self.assertTrue(time.time()<timeout)
+        self.assertEquals("123", v)
+
+        txn=self.dbenvMaster.txn_begin()
+        self.dbMaster.delete("ABC", txn=txn)
+        txn.commit()
+        timeout=time.time()+10
+        while (time.time()<timeout) and (v is not None) :
+            txn=self.dbenvClient.txn_begin()
+            v=self.dbClient.get("ABC", txn=txn)
+            txn.commit()
+            if v is None :
+                time.sleep(0.02)
+        self.assertTrue(time.time()<timeout)
+        self.assertEquals(None, v)
+
+    if db.version() >= (4,7) :
+        def test02_test_request(self) :
+            self.basic_rep_threading()
+            (minimum, maximum) = self.dbenvClient.rep_get_request()
+            self.dbenvClient.rep_set_request(minimum-1, maximum+1)
+            self.assertEqual(self.dbenvClient.rep_get_request(),
+                    (minimum-1, maximum+1))
+
+    if db.version() >= (4,6) :
+        def test03_master_election(self) :
+            # Get ready to hold an election
+            #self.dbenvMaster.rep_start(flags=db.DB_REP_MASTER)
+            self.dbenvMaster.rep_start(flags=db.DB_REP_CLIENT)
+            self.dbenvClient.rep_start(flags=db.DB_REP_CLIENT)
+
+            def thread_do(env, q, envid, election_status, must_be_master) :
+                while True :
+                    v=q.get()
+                    if v is None : return
+                    r = env.rep_process_message(v[0],v[1],envid)
+                    if must_be_master and self.confirmed_master :
+                        self.dbenvMaster.rep_start(flags = db.DB_REP_MASTER)
+                        must_be_master = False
+
+                    if r[0] == db.DB_REP_HOLDELECTION :
+                        def elect() :
+                            while True :
+                                try :
+                                    env.rep_elect(2, 1)
+                                    election_status[0] = False
+                                    break
+                                except db.DBRepUnavailError :
+                                    pass
+
+                        if not election_status[0] and not self.confirmed_master :
+                            from threading import Thread
+                            election_status[0] = True
+                            t=Thread(target=elect)
+                            import sys
+                            if sys.version_info[0] < 3 :
+                                t.setDaemon(True)
+                            else :
+                                t.daemon = True
+                            t.start()
+
+            self.thread_do = thread_do
+
+            self.t_m.start()
+            self.t_c.start()
+
+            self.dbenvMaster.rep_set_timeout(db.DB_REP_ELECTION_TIMEOUT, 50000)
+            self.dbenvClient.rep_set_timeout(db.DB_REP_ELECTION_TIMEOUT, 50000)
+            self.client_doing_election[0] = True
+            while True :
+                try :
+                    self.dbenvClient.rep_elect(2, 1)
+                    self.client_doing_election[0] = False
+                    break
+                except db.DBRepUnavailError :
+                    pass
+
+            self.assertTrue(self.confirmed_master)
+
+#----------------------------------------------------------------------
+
+def test_suite():
+    suite = unittest.TestSuite()
+    if db.version() >= (4, 6) :
+        dbenv = db.DBEnv()
+        try :
+            dbenv.repmgr_get_ack_policy()
+            ReplicationManager_available=True
+        except :
+            ReplicationManager_available=False
+        dbenv.close()
+        del dbenv
+        if ReplicationManager_available :
+            suite.addTest(unittest.makeSuite(DBReplicationManager))
+
+        if have_threads :
+            suite.addTest(unittest.makeSuite(DBBaseReplication))
+
+    return suite
+
+
+if __name__ == '__main__':
+    unittest.main(defaultTest='test_suite')
diff --git a/Lib/bsddb/test/test_sequence.py b/Lib/bsddb/test/test_sequence.py
index 979f858..b61ead4 100644
--- a/Lib/bsddb/test/test_sequence.py
+++ b/Lib/bsddb/test/test_sequence.py
@@ -1,29 +1,19 @@
 import unittest
 import os
-import sys
-import tempfile
-import glob
 
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db
-except ImportError:
-    from bsddb import db
-
-from test_all import verbose
+from test_all import db, test_support, get_new_environment_path, get_new_database_path
 
 
 class DBSequenceTest(unittest.TestCase):
+    import sys
+    if sys.version_info[:3] < (2, 4, 0):
+        def assertTrue(self, expr, msg=None):
+            self.failUnless(expr,msg=msg)
+
     def setUp(self):
         self.int_32_max = 0x100000000
-        self.homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        try:
-            os.mkdir(self.homeDir)
-        except os.error:
-            pass
-        tempfile.tempdir = self.homeDir
-        self.filename = os.path.split(tempfile.mktemp())[1]
-        tempfile.tempdir = None
+        self.homeDir = get_new_environment_path()
+        self.filename = "test"
 
         self.dbenv = db.DBEnv()
         self.dbenv.open(self.homeDir, db.DB_CREATE | db.DB_INIT_MPOOL, 0666)
@@ -41,9 +31,7 @@ class DBSequenceTest(unittest.TestCase):
             self.dbenv.close()
             del self.dbenv
 
-        files = glob.glob(os.path.join(self.homeDir, '*'))
-        for file in files:
-            os.remove(file)
+        test_support.rmtree(self.homeDir)
 
     def test_get(self):
         self.seq = db.DBSequence(self.d, flags=0)
@@ -101,6 +89,48 @@ class DBSequenceTest(unittest.TestCase):
                       'flags', 'cache_size', 'last_value', 'wait'):
             self.assertTrue(param in stat, "parameter %s isn't in stat info" % param)
 
+    if db.version() >= (4,7) :
+        # This code checks a crash solved in Berkeley DB 4.7
+        def test_stat_crash(self) :
+            d=db.DB()
+            d.open(None,dbtype=db.DB_HASH,flags=db.DB_CREATE)  # In RAM
+            seq = db.DBSequence(d, flags=0)
+
+            self.assertRaises(db.DBNotFoundError, seq.open,
+                    key='id', txn=None, flags=0)
+
+            self.assertRaises(db.DBInvalidArgError, seq.stat)
+
+            d.close()
+
+    def test_64bits(self) :
+        # We don't use both extremes because they are problematic
+        value_plus=(1L<<63)-2
+        self.assertEquals(9223372036854775806L,value_plus)
+        value_minus=(-1L<<63)+1  # Two complement
+        self.assertEquals(-9223372036854775807L,value_minus)
+        self.seq = db.DBSequence(self.d, flags=0)
+        self.assertEquals(None, self.seq.init_value(value_plus-1))
+        self.assertEquals(None, self.seq.open(key='id', txn=None,
+            flags=db.DB_CREATE))
+        self.assertEquals(value_plus-1, self.seq.get(1))
+        self.assertEquals(value_plus, self.seq.get(1))
+
+        self.seq.remove(txn=None, flags=0)
+
+        self.seq = db.DBSequence(self.d, flags=0)
+        self.assertEquals(None, self.seq.init_value(value_minus))
+        self.assertEquals(None, self.seq.open(key='id', txn=None,
+            flags=db.DB_CREATE))
+        self.assertEquals(value_minus, self.seq.get(1))
+        self.assertEquals(value_minus+1, self.seq.get(1))
+
+    def test_multiple_close(self):
+        self.seq = db.DBSequence(self.d)
+        self.seq.close()  # You can close a Sequence multiple times
+        self.seq.close()
+        self.seq.close()
+
 def test_suite():
     suite = unittest.TestSuite()
     if db.version() >= (4,3):
diff --git a/Lib/bsddb/test/test_thread.py b/Lib/bsddb/test/test_thread.py
index 31964f0..28a2555 100644
--- a/Lib/bsddb/test/test_thread.py
+++ b/Lib/bsddb/test/test_thread.py
@@ -5,40 +5,27 @@ import os
 import sys
 import time
 import errno
-import shutil
-import tempfile
-from pprint import pprint
 from random import random
 
-try:
-    True, False
-except NameError:
-    True = 1
-    False = 0
-
 DASH = '-'
 
 try:
-    from threading import Thread, currentThread
-    have_threads = True
-except ImportError:
-    have_threads = False
-
-try:
     WindowsError
 except NameError:
     class WindowsError(Exception):
         pass
 
 import unittest
-from test_all import verbose
+from test_all import db, dbutils, test_support, verbose, have_threads, \
+        get_new_environment_path, get_new_database_path
 
-try:
-    # For Pythons w/distutils pybsddb
-    from bsddb3 import db, dbutils
-except ImportError:
-    # For Python 2.3
-    from bsddb import db, dbutils
+if have_threads :
+    from threading import Thread
+    import sys
+    if sys.version_info[0] < 3 :
+        from threading import currentThread
+    else :
+        from threading import current_thread as currentThread
 
 
 #----------------------------------------------------------------------
@@ -49,19 +36,19 @@ class BaseThreadedTestCase(unittest.TestCase):
     dbsetflags   = 0
     envflags     = 0
 
+    import sys
+    if sys.version_info[:3] < (2, 4, 0):
+        def assertTrue(self, expr, msg=None):
+            self.failUnless(expr,msg=msg)
+
     def setUp(self):
         if verbose:
             dbutils._deadlock_VerboseFile = sys.stdout
 
-        homeDir = os.path.join(os.path.dirname(sys.argv[0]), 'db_home')
-        self.homeDir = homeDir
-        try:
-            os.mkdir(homeDir)
-        except OSError, e:
-            if e.errno <> errno.EEXIST: raise
+        self.homeDir = get_new_environment_path()
         self.env = db.DBEnv()
         self.setEnvOpts()
-        self.env.open(homeDir, self.envflags | db.DB_CREATE)
+        self.env.open(self.homeDir, self.envflags | db.DB_CREATE)
 
         self.filename = self.__class__.__name__ + '.db'
         self.d = db.DB(self.env)
@@ -72,7 +59,7 @@ class BaseThreadedTestCase(unittest.TestCase):
     def tearDown(self):
         self.d.close()
         self.env.close()
-        shutil.rmtree(self.homeDir)
+        test_support.rmtree(self.homeDir)
 
     def setEnvOpts(self):
         pass
@@ -97,63 +84,90 @@ class ConcurrentDataStoreBase(BaseThreadedTestCase):
             print "Running %s.test01_1WriterMultiReaders..." % \
                   self.__class__.__name__
 
-        threads = []
-        for x in range(self.writers):
-            wt = Thread(target = self.writerThread,
-                        args = (self.d, self.records, x),
-                        name = 'writer %d' % x,
-                        )#verbose = verbose)
-            threads.append(wt)
-
-        for x in range(self.readers):
+        keys=range(self.records)
+        import random
+        random.shuffle(keys)
+        records_per_writer=self.records//self.writers
+        readers_per_writer=self.readers//self.writers
+        self.assertEqual(self.records,self.writers*records_per_writer)
+        self.assertEqual(self.readers,self.writers*readers_per_writer)
+        self.assertTrue((records_per_writer%readers_per_writer)==0)
+        readers = []
+
+        for x in xrange(self.readers):
             rt = Thread(target = self.readerThread,
                         args = (self.d, x),
                         name = 'reader %d' % x,
                         )#verbose = verbose)
-            threads.append(rt)
-
-        for t in threads:
+            import sys
+            if sys.version_info[0] < 3 :
+                rt.setDaemon(True)
+            else :
+                rt.daemon = True
+            readers.append(rt)
+
+        writers=[]
+        for x in xrange(self.writers):
+            a=keys[records_per_writer*x:records_per_writer*(x+1)]
+            a.sort()  # Generate conflicts
+            b=readers[readers_per_writer*x:readers_per_writer*(x+1)]
+            wt = Thread(target = self.writerThread,
+                        args = (self.d, a, b),
+                        name = 'writer %d' % x,
+                        )#verbose = verbose)
+            writers.append(wt)
+
+        for t in writers:
+            import sys
+            if sys.version_info[0] < 3 :
+                t.setDaemon(True)
+            else :
+                t.daemon = True
             t.start()
-        for t in threads:
+
+        for t in writers:
             t.join()
+        for t in readers:
+            t.join()
+
+    def writerThread(self, d, keys, readers):
+        import sys
+        if sys.version_info[0] < 3 :
+            name = currentThread().getName()
+        else :
+            name = currentThread().name
 
-    def writerThread(self, d, howMany, writerNum):
-        #time.sleep(0.01 * writerNum + 0.01)
-        name = currentThread().getName()
-        start = howMany * writerNum
-        stop = howMany * (writerNum + 1) - 1
         if verbose:
             print "%s: creating records %d - %d" % (name, start, stop)
 
-        for x in range(start, stop):
+        count=len(keys)//len(readers)
+        count2=count
+        for x in keys :
             key = '%04d' % x
             dbutils.DeadlockWrap(d.put, key, self.makeData(key),
                                  max_retries=12)
             if verbose and x % 100 == 0:
                 print "%s: records %d - %d finished" % (name, start, x)
 
+            count2-=1
+            if not count2 :
+                readers.pop().start()
+                count2=count
+
         if verbose:
             print "%s: finished creating records" % name
 
-##         # Each write-cursor will be exclusive, the only one that can update the DB...
-##         if verbose: print "%s: deleting a few records" % name
-##         c = d.cursor(flags = db.DB_WRITECURSOR)
-##         for x in range(10):
-##             key = int(random() * howMany) + start
-##             key = '%04d' % key
-##             if d.has_key(key):
-##                 c.set(key)
-##                 c.delete()
-
-##         c.close()
         if verbose:
             print "%s: thread finished" % name
 
     def readerThread(self, d, readerNum):
-        time.sleep(0.01 * readerNum)
-        name = currentThread().getName()
+        import sys
+        if sys.version_info[0] < 3 :
+            name = currentThread().getName()
+        else :
+            name = currentThread().name
 
-        for loop in range(5):
+        for i in xrange(5) :
             c = d.cursor()
             count = 0
             rec = c.first()
@@ -165,7 +179,6 @@ class ConcurrentDataStoreBase(BaseThreadedTestCase):
             if verbose:
                 print "%s: found %d records" % (name, count)
             c.close()
-            time.sleep(0.05)
 
         if verbose:
             print "%s: thread finished" % name
@@ -190,8 +203,8 @@ class HashConcurrentDataStore(ConcurrentDataStoreBase):
 class SimpleThreadedBase(BaseThreadedTestCase):
     dbopenflags = db.DB_THREAD
     envflags    = db.DB_THREAD | db.DB_INIT_MPOOL | db.DB_INIT_LOCK
-    readers = 5
-    writers = 3
+    readers = 10
+    writers = 2
     records = 1000
 
     def setEnvOpts(self):
@@ -202,34 +215,65 @@ class SimpleThreadedBase(BaseThreadedTestCase):
             print '\n', '-=' * 30
             print "Running %s.test02_SimpleLocks..." % self.__class__.__name__
 
-        threads = []
-        for x in range(self.writers):
-            wt = Thread(target = self.writerThread,
-                        args = (self.d, self.records, x),
-                        name = 'writer %d' % x,
-                        )#verbose = verbose)
-            threads.append(wt)
-        for x in range(self.readers):
+
+        keys=range(self.records)
+        import random
+        random.shuffle(keys)
+        records_per_writer=self.records//self.writers
+        readers_per_writer=self.readers//self.writers
+        self.assertEqual(self.records,self.writers*records_per_writer)
+        self.assertEqual(self.readers,self.writers*readers_per_writer)
+        self.assertTrue((records_per_writer%readers_per_writer)==0)
+
+        readers = []
+        for x in xrange(self.readers):
             rt = Thread(target = self.readerThread,
                         args = (self.d, x),
                         name = 'reader %d' % x,
                         )#verbose = verbose)
-            threads.append(rt)
-
-        for t in threads:
+            import sys
+            if sys.version_info[0] < 3 :
+                rt.setDaemon(True)
+            else :
+                rt.daemon = True
+            readers.append(rt)
+
+        writers = []
+        for x in xrange(self.writers):
+            a=keys[records_per_writer*x:records_per_writer*(x+1)]
+            a.sort()  # Generate conflicts
+            b=readers[readers_per_writer*x:readers_per_writer*(x+1)]
+            wt = Thread(target = self.writerThread,
+                        args = (self.d, a, b),
+                        name = 'writer %d' % x,
+                        )#verbose = verbose)
+            writers.append(wt)
+
+        for t in writers:
+            import sys
+            if sys.version_info[0] < 3 :
+                t.setDaemon(True)
+            else :
+                t.daemon = True
             t.start()
-        for t in threads:
+
+        for t in writers:
+            t.join()
+        for t in readers:
             t.join()
 
-    def writerThread(self, d, howMany, writerNum):
-        name = currentThread().getName()
-        start = howMany * writerNum
-        stop = howMany * (writerNum + 1) - 1
+    def writerThread(self, d, keys, readers):
+        import sys
+        if sys.version_info[0] < 3 :
+            name = currentThread().getName()
+        else :
+            name = currentThread().name
         if verbose:
             print "%s: creating records %d - %d" % (name, start, stop)
 
-        # create a bunch of records
-        for x in xrange(start, stop):
+        count=len(keys)//len(readers)
+        count2=count
+        for x in keys :
             key = '%04d' % x
             dbutils.DeadlockWrap(d.put, key, self.makeData(key),
                                  max_retries=12)
@@ -237,52 +281,32 @@ class SimpleThreadedBase(BaseThreadedTestCase):
             if verbose and x % 100 == 0:
                 print "%s: records %d - %d finished" % (name, start, x)
 
-            # do a bit or reading too
-            if random() <= 0.05:
-                for y in xrange(start, x):
-                    key = '%04d' % x
-                    data = dbutils.DeadlockWrap(d.get, key, max_retries=12)
-                    self.assertEqual(data, self.makeData(key))
-
-        # flush them
-        try:
-            dbutils.DeadlockWrap(d.sync, max_retries=12)
-        except db.DBIncompleteError, val:
-            if verbose:
-                print "could not complete sync()..."
-
-        # read them back, deleting a few
-        for x in xrange(start, stop):
-            key = '%04d' % x
-            data = dbutils.DeadlockWrap(d.get, key, max_retries=12)
-            if verbose and x % 100 == 0:
-                print "%s: fetched record (%s, %s)" % (name, key, data)
-            self.assertEqual(data, self.makeData(key))
-            if random() <= 0.10:
-                dbutils.DeadlockWrap(d.delete, key, max_retries=12)
-                if verbose:
-                    print "%s: deleted record %s" % (name, key)
+            count2-=1
+            if not count2 :
+                readers.pop().start()
+                count2=count
 
         if verbose:
             print "%s: thread finished" % name
 
     def readerThread(self, d, readerNum):
-        time.sleep(0.01 * readerNum)
-        name = currentThread().getName()
-
-        for loop in range(5):
-            c = d.cursor()
-            count = 0
-            rec = dbutils.DeadlockWrap(c.first, max_retries=10)
-            while rec:
-                count += 1
-                key, data = rec
-                self.assertEqual(self.makeData(key), data)
-                rec = dbutils.DeadlockWrap(c.next, max_retries=10)
-            if verbose:
-                print "%s: found %d records" % (name, count)
-            c.close()
-            time.sleep(0.05)
+        import sys
+        if sys.version_info[0] < 3 :
+            name = currentThread().getName()
+        else :
+            name = currentThread().name
+
+        c = d.cursor()
+        count = 0
+        rec = dbutils.DeadlockWrap(c.first, max_retries=10)
+        while rec:
+            count += 1
+            key, data = rec
+            self.assertEqual(self.makeData(key), data)
+            rec = dbutils.DeadlockWrap(c.next, max_retries=10)
+        if verbose:
+            print "%s: found %d records" % (name, count)
+        c.close()
 
         if verbose:
             print "%s: thread finished" % name
@@ -322,120 +346,118 @@ class ThreadedTransactionsBase(BaseThreadedTestCase):
             print "Running %s.test03_ThreadedTransactions..." % \
                   self.__class__.__name__
 
-        threads = []
-        for x in range(self.writers):
-            wt = Thread(target = self.writerThread,
-                        args = (self.d, self.records, x),
-                        name = 'writer %d' % x,
-                        )#verbose = verbose)
-            threads.append(wt)
-
-        for x in range(self.readers):
+        keys=range(self.records)
+        import random
+        random.shuffle(keys)
+        records_per_writer=self.records//self.writers
+        readers_per_writer=self.readers//self.writers
+        self.assertEqual(self.records,self.writers*records_per_writer)
+        self.assertEqual(self.readers,self.writers*readers_per_writer)
+        self.assertTrue((records_per_writer%readers_per_writer)==0)
+
+        readers=[]
+        for x in xrange(self.readers):
             rt = Thread(target = self.readerThread,
                         args = (self.d, x),
                         name = 'reader %d' % x,
                         )#verbose = verbose)
-            threads.append(rt)
+            import sys
+            if sys.version_info[0] < 3 :
+                rt.setDaemon(True)
+            else :
+                rt.daemon = True
+            readers.append(rt)
+
+        writers = []
+        for x in xrange(self.writers):
+            a=keys[records_per_writer*x:records_per_writer*(x+1)]
+            b=readers[readers_per_writer*x:readers_per_writer*(x+1)]
+            wt = Thread(target = self.writerThread,
+                        args = (self.d, a, b),
+                        name = 'writer %d' % x,
+                        )#verbose = verbose)
+            writers.append(wt)
 
         dt = Thread(target = self.deadlockThread)
+        import sys
+        if sys.version_info[0] < 3 :
+            dt.setDaemon(True)
+        else :
+            dt.daemon = True
         dt.start()
 
-        for t in threads:
+        for t in writers:
+            import sys
+            if sys.version_info[0] < 3 :
+                t.setDaemon(True)
+            else :
+                t.daemon = True
             t.start()
-        for t in threads:
+
+        for t in writers:
+            t.join()
+        for t in readers:
             t.join()
 
         self.doLockDetect = False
         dt.join()
 
-    def doWrite(self, d, name, start, stop):
-        finished = False
-        while not finished:
+    def writerThread(self, d, keys, readers):
+        import sys
+        if sys.version_info[0] < 3 :
+            name = currentThread().getName()
+        else :
+            name = currentThread().name
+
+        count=len(keys)//len(readers)
+        while len(keys):
             try:
                 txn = self.env.txn_begin(None, self.txnFlag)
-                for x in range(start, stop):
+                keys2=keys[:count]
+                for x in keys2 :
                     key = '%04d' % x
                     d.put(key, self.makeData(key), txn)
                     if verbose and x % 100 == 0:
                         print "%s: records %d - %d finished" % (name, start, x)
                 txn.commit()
-                finished = True
+                keys=keys[count:]
+                readers.pop().start()
             except (db.DBLockDeadlockError, db.DBLockNotGrantedError), val:
                 if verbose:
-                    print "%s: Aborting transaction (%s)" % (name, val[1])
+                    print "%s: Aborting transaction (%s)" % (name, val.args[1])
                 txn.abort()
-                time.sleep(0.05)
 
-    def writerThread(self, d, howMany, writerNum):
-        name = currentThread().getName()
-        start = howMany * writerNum
-        stop = howMany * (writerNum + 1) - 1
         if verbose:
-            print "%s: creating records %d - %d" % (name, start, stop)
-
-        step = 100
-        for x in range(start, stop, step):
-            self.doWrite(d, name, x, min(stop, x+step))
+            print "%s: thread finished" % name
 
-        if verbose:
-            print "%s: finished creating records" % name
-        if verbose:
-            print "%s: deleting a few records" % name
+    def readerThread(self, d, readerNum):
+        import sys
+        if sys.version_info[0] < 3 :
+            name = currentThread().getName()
+        else :
+            name = currentThread().name
 
         finished = False
         while not finished:
             try:
-                recs = []
                 txn = self.env.txn_begin(None, self.txnFlag)
-                for x in range(10):
-                    key = int(random() * howMany) + start
-                    key = '%04d' % key
-                    data = d.get(key, None, txn, db.DB_RMW)
-                    if data is not None:
-                        d.delete(key, txn)
-                        recs.append(key)
+                c = d.cursor(txn)
+                count = 0
+                rec = c.first()
+                while rec:
+                    count += 1
+                    key, data = rec
+                    self.assertEqual(self.makeData(key), data)
+                    rec = c.next()
+                if verbose: print "%s: found %d records" % (name, count)
+                c.close()
                 txn.commit()
                 finished = True
-                if verbose:
-                    print "%s: deleted records %s" % (name, recs)
             except (db.DBLockDeadlockError, db.DBLockNotGrantedError), val:
                 if verbose:
-                    print "%s: Aborting transaction (%s)" % (name, val[1])
+                    print "%s: Aborting transaction (%s)" % (name, val.args[1])
+                c.close()
                 txn.abort()
-                time.sleep(0.05)
-
-        if verbose:
-            print "%s: thread finished" % name
-
-    def readerThread(self, d, readerNum):
-        time.sleep(0.01 * readerNum + 0.05)
-        name = currentThread().getName()
-
-        for loop in range(5):
-            finished = False
-            while not finished:
-                try:
-                    txn = self.env.txn_begin(None, self.txnFlag)
-                    c = d.cursor(txn)
-                    count = 0
-                    rec = c.first()
-                    while rec:
-                        count += 1
-                        key, data = rec
-                        self.assertEqual(self.makeData(key), data)
-                        rec = c.next()
-                    if verbose: print "%s: found %d records" % (name, count)
-                    c.close()
-                    txn.commit()
-                    finished = True
-                except (db.DBLockDeadlockError, db.DBLockNotGrantedError), val:
-                    if verbose:
-                        print "%s: Aborting transaction (%s)" % (name, val[1])
-                    c.close()
-                    txn.abort()
-                    time.sleep(0.05)
-
-            time.sleep(0.05)
 
         if verbose:
             print "%s: thread finished" % name
@@ -443,7 +465,7 @@ class ThreadedTransactionsBase(BaseThreadedTestCase):
     def deadlockThread(self):
         self.doLockDetect = True
         while self.doLockDetect:
-            time.sleep(0.5)
+            time.sleep(0.05)
             try:
                 aborted = self.env.lock_detect(
                     db.DB_LOCK_RANDOM, db.DB_LOCK_CONFLICT)
@@ -456,28 +478,28 @@ class ThreadedTransactionsBase(BaseThreadedTestCase):
 
 class BTreeThreadedTransactions(ThreadedTransactionsBase):
     dbtype = db.DB_BTREE
-    writers = 3
-    readers = 5
-    records = 2000
+    writers = 2
+    readers = 10
+    records = 1000
 
 class HashThreadedTransactions(ThreadedTransactionsBase):
     dbtype = db.DB_HASH
-    writers = 1
-    readers = 5
-    records = 2000
+    writers = 2
+    readers = 10
+    records = 1000
 
 class BTreeThreadedNoWaitTransactions(ThreadedTransactionsBase):
     dbtype = db.DB_BTREE
-    writers = 3
-    readers = 5
-    records = 2000
+    writers = 2
+    readers = 10
+    records = 1000
     txnFlag = db.DB_TXN_NOWAIT
 
 class HashThreadedNoWaitTransactions(ThreadedTransactionsBase):
     dbtype = db.DB_HASH
-    writers = 1
-    readers = 5
-    records = 2000
+    writers = 2
+    readers = 10
+    records = 1000
     txnFlag = db.DB_TXN_NOWAIT
 
 
diff --git a/Modules/_bsddb.c b/Modules/_bsddb.c
index d48c88e..e5e2909 100644
--- a/Modules/_bsddb.c
+++ b/Modules/_bsddb.c
@@ -36,19 +36,22 @@
 /*
  * Handwritten code to wrap version 3.x of the Berkeley DB library,
  * written to replace a SWIG-generated file.  It has since been updated
- * to compile with BerkeleyDB versions 3.2 through 4.2.
+ * to compile with Berkeley DB versions 3.2 through 4.2.
  *
  * This module was started by Andrew Kuchling to remove the dependency
- * on SWIG in a package by Gregory P. Smith <greg@electricrain.com> who
- * based his work on a similar package by Robin Dunn <robin@alldunn.com>
- * which wrapped Berkeley DB 2.7.x.
+ * on SWIG in a package by Gregory P. Smith who based his work on a
+ * similar package by Robin Dunn <robin@alldunn.com> which wrapped
+ * Berkeley DB 2.7.x.
  *
  * Development of this module then returned full circle back to Robin Dunn
  * who worked on behalf of Digital Creations to complete the wrapping of
  * the DB 3.x API and to build a solid unit test suite.  Robin has
  * since gone onto other projects (wxPython).
  *
- * Gregory P. Smith <greg@electricrain.com> is once again the maintainer.
+ * Gregory P. Smith <greg@krypto.org> was once again the maintainer.
+ *
+ * Since January 2008, new maintainer is Jesus Cea <jcea@jcea.es>.
+ * Jesus Cea licenses this code to PSF under a Contributor Agreement.
  *
  * Use the pybsddb-users@lists.sf.net mailing list for all questions.
  * Things can change faster than the header of this file is updated.  This
@@ -87,23 +90,39 @@
 
 #include <stddef.h>   /* for offsetof() */
 #include <Python.h>
-#include <db.h>
+
+#define COMPILING_BSDDB_C
+#include "bsddb.h"
+#undef COMPILING_BSDDB_C
+
+static char *rcs_id = "$Id: _bsddb.c 81031 2010-05-09 15:15:40Z antoine.pitrou $";
 
 /* --------------------------------------------------------------------- */
 /* Various macro definitions */
 
-/* 40 = 4.0, 33 = 3.3; this will break if the second number is > 9 */
-#define DBVER (DB_VERSION_MAJOR * 10 + DB_VERSION_MINOR)
-#if DB_VERSION_MINOR > 9
-#error "eek! DBVER can't handle minor versions > 9"
+#if (PY_VERSION_HEX < 0x02050000)
+typedef int Py_ssize_t;
 #endif
 
-#define PY_BSDDB_VERSION "4.4.5.3"
-static char *rcs_id = "$Id: _bsddb.c 63404 2008-05-17 06:46:39Z gregory.p.smith $";
-
+#if (PY_VERSION_HEX < 0x02060000)  /* really: before python trunk r63675 */
+/* This code now uses PyBytes* API function names instead of PyString*.
+ * These #defines map to their equivalent on earlier python versions.    */
+#define PyBytes_FromStringAndSize PyString_FromStringAndSize
+#define PyBytes_FromString PyString_FromString
+#define PyBytes_AsStringAndSize PyString_AsStringAndSize
+#define PyBytes_Check PyString_Check
+#define PyBytes_GET_SIZE PyString_GET_SIZE
+#define PyBytes_AS_STRING PyString_AS_STRING
+#endif
 
-#if (PY_VERSION_HEX < 0x02050000)
-typedef int Py_ssize_t;
+#if (PY_VERSION_HEX >= 0x03000000)
+#define NUMBER_Check    PyLong_Check
+#define NUMBER_AsLong   PyLong_AsLong
+#define NUMBER_FromLong PyLong_FromLong
+#else
+#define NUMBER_Check    PyInt_Check
+#define NUMBER_AsLong   PyInt_AsLong
+#define NUMBER_FromLong PyInt_FromLong
 #endif
 
 #ifdef WITH_THREAD
@@ -120,9 +139,9 @@ typedef int Py_ssize_t;
 /* and these are for calling C --> Python */
 #if defined(MYDB_USE_GILSTATE)
 #define MYDB_BEGIN_BLOCK_THREADS \
-		PyGILState_STATE __savestate = PyGILState_Ensure();
+                PyGILState_STATE __savestate = PyGILState_Ensure();
 #define MYDB_END_BLOCK_THREADS \
-		PyGILState_Release(__savestate);
+                PyGILState_Release(__savestate);
 #else /* MYDB_USE_GILSTATE */
 /* Pre GILState API - do it the long old way */
 static PyInterpreterState* _db_interpreterState = NULL;
@@ -169,10 +188,8 @@ static PyObject* DBVerifyBadError;      /* DB_VERIFY_BAD */
 static PyObject* DBNoServerError;       /* DB_NOSERVER */
 static PyObject* DBNoServerHomeError;   /* DB_NOSERVER_HOME */
 static PyObject* DBNoServerIDError;     /* DB_NOSERVER_ID */
-#if (DBVER >= 33)
 static PyObject* DBPageNotFoundError;   /* DB_PAGE_NOTFOUND */
 static PyObject* DBSecondaryBadError;   /* DB_SECONDARY_BAD */
-#endif
 
 #if !INCOMPLETE_IS_WARNING
 static PyObject* DBIncompleteError;     /* DB_INCOMPLETE */
@@ -188,131 +205,129 @@ static PyObject* DBFileExistsError;     /* EEXIST */
 static PyObject* DBNoSuchFileError;     /* ENOENT */
 static PyObject* DBPermissionsError;    /* EPERM  */
 
+#if (DBVER >= 42)
+static PyObject* DBRepHandleDeadError;  /* DB_REP_HANDLE_DEAD */
+#endif
+
+static PyObject* DBRepUnavailError;     /* DB_REP_UNAVAIL */
+
 #if (DBVER < 43)
-#define	DB_BUFFER_SMALL		ENOMEM
+#define DB_BUFFER_SMALL         ENOMEM
 #endif
 
 
 /* --------------------------------------------------------------------- */
 /* Structure definitions */
 
-#if PYTHON_API_VERSION >= 1010       /* python >= 2.1 support weak references */
-#define HAVE_WEAKREF
-#else
-#undef HAVE_WEAKREF
+#if PYTHON_API_VERSION < 1010
+#error "Python 2.1 or later required"
 #endif
 
-/* if Python >= 2.1 better support warnings */
-#if PYTHON_API_VERSION >= 1010
-#define HAVE_WARNINGS
-#else
-#undef HAVE_WARNINGS
-#endif
-
-#if PYTHON_API_VERSION <= 1007
-    /* 1.5 compatibility */
-#define PyObject_New PyObject_NEW
-#define PyObject_Del PyMem_DEL
-#endif
-
-struct behaviourFlags {
-    /* What is the default behaviour when DB->get or DBCursor->get returns a
-       DB_NOTFOUND || DB_KEYEMPTY error?  Return None or raise an exception? */
-    unsigned int getReturnsNone : 1;
-    /* What is the default behaviour for DBCursor.set* methods when DBCursor->get
-     * returns a DB_NOTFOUND || DB_KEYEMPTY  error?  Return None or raise? */
-    unsigned int cursorSetReturnsNone : 1;
-};
 
+/* Defaults for moduleFlags in DBEnvObject and DBObject. */
 #define DEFAULT_GET_RETURNS_NONE                1
 #define DEFAULT_CURSOR_SET_RETURNS_NONE         1   /* 0 in pybsddb < 4.2, python < 2.4 */
 
-typedef struct {
-    PyObject_HEAD
-    DB_ENV*     db_env;
-    u_int32_t   flags;             /* saved flags from open() */
-    int         closed;
-    struct behaviourFlags moduleFlags;
-#ifdef HAVE_WEAKREF
-    PyObject        *in_weakreflist; /* List of weak references */
-#endif
-} DBEnvObject;
 
-
-typedef struct {
-    PyObject_HEAD
-    DB*             db;
-    DBEnvObject*    myenvobj;  /* PyObject containing the DB_ENV */
-    u_int32_t       flags;     /* saved flags from open() */
-    u_int32_t       setflags;  /* saved flags from set_flags() */
-    int             haveStat;
-    struct behaviourFlags moduleFlags;
-#if (DBVER >= 33)
-    PyObject*       associateCallback;
-    PyObject*       btCompareCallback;
-    int             primaryDBType;
-#endif
-#ifdef HAVE_WEAKREF
-    PyObject        *in_weakreflist; /* List of weak references */
+/* See comment in Python 2.6 "object.h" */
+#ifndef staticforward
+#define staticforward static
 #endif
-} DBObject;
-
-
-typedef struct {
-    PyObject_HEAD
-    DBC*            dbc;
-    DBObject*       mydb;
-#ifdef HAVE_WEAKREF
-    PyObject        *in_weakreflist; /* List of weak references */
+#ifndef statichere
+#define statichere static
 #endif
-} DBCursorObject;
-
 
-typedef struct {
-    PyObject_HEAD
-    DB_TXN*         txn;
-    PyObject        *env;
-#ifdef HAVE_WEAKREF
-    PyObject        *in_weakreflist; /* List of weak references */
+staticforward PyTypeObject DB_Type, DBCursor_Type, DBEnv_Type, DBTxn_Type,
+              DBLock_Type;
+#if (DBVER >= 43)
+staticforward PyTypeObject DBSequence_Type;
 #endif
-} DBTxnObject;
-
 
-typedef struct {
-    PyObject_HEAD
-    DB_LOCK         lock;
-#ifdef HAVE_WEAKREF
-    PyObject        *in_weakreflist; /* List of weak references */
+#ifndef Py_TYPE
+/* for compatibility with Python 2.5 and earlier */
+#define Py_TYPE(ob)              (((PyObject*)(ob))->ob_type)
 #endif
-} DBLockObject;
 
+#define DBObject_Check(v)           (Py_TYPE(v) == &DB_Type)
+#define DBCursorObject_Check(v)     (Py_TYPE(v) == &DBCursor_Type)
+#define DBEnvObject_Check(v)        (Py_TYPE(v) == &DBEnv_Type)
+#define DBTxnObject_Check(v)        (Py_TYPE(v) == &DBTxn_Type)
+#define DBLockObject_Check(v)       (Py_TYPE(v) == &DBLock_Type)
 #if (DBVER >= 43)
-typedef struct {
-    PyObject_HEAD
-    DB_SEQUENCE*     sequence;
-    DBObject*        mydb;
-#ifdef HAVE_WEAKREF
-    PyObject        *in_weakreflist; /* List of weak references */
-#endif
-} DBSequenceObject;
-staticforward PyTypeObject DBSequence_Type;
+#define DBSequenceObject_Check(v)   (Py_TYPE(v) == &DBSequence_Type)
 #endif
 
-staticforward PyTypeObject DB_Type, DBCursor_Type, DBEnv_Type, DBTxn_Type, DBLock_Type;
-
-#define DBObject_Check(v)           ((v)->ob_type == &DB_Type)
-#define DBCursorObject_Check(v)     ((v)->ob_type == &DBCursor_Type)
-#define DBEnvObject_Check(v)        ((v)->ob_type == &DBEnv_Type)
-#define DBTxnObject_Check(v)        ((v)->ob_type == &DBTxn_Type)
-#define DBLockObject_Check(v)       ((v)->ob_type == &DBLock_Type)
-#if (DBVER >= 43)
-#define DBSequenceObject_Check(v)   ((v)->ob_type == &DBSequence_Type)
+#if (DBVER < 46)
+  #define _DBC_close(dbc)           dbc->c_close(dbc)
+  #define _DBC_count(dbc,a,b)       dbc->c_count(dbc,a,b)
+  #define _DBC_del(dbc,a)           dbc->c_del(dbc,a)
+  #define _DBC_dup(dbc,a,b)         dbc->c_dup(dbc,a,b)
+  #define _DBC_get(dbc,a,b,c)       dbc->c_get(dbc,a,b,c)
+  #define _DBC_pget(dbc,a,b,c,d)    dbc->c_pget(dbc,a,b,c,d)
+  #define _DBC_put(dbc,a,b,c)       dbc->c_put(dbc,a,b,c)
+#else
+  #define _DBC_close(dbc)           dbc->close(dbc)
+  #define _DBC_count(dbc,a,b)       dbc->count(dbc,a,b)
+  #define _DBC_del(dbc,a)           dbc->del(dbc,a)
+  #define _DBC_dup(dbc,a,b)         dbc->dup(dbc,a,b)
+  #define _DBC_get(dbc,a,b,c)       dbc->get(dbc,a,b,c)
+  #define _DBC_pget(dbc,a,b,c,d)    dbc->pget(dbc,a,b,c,d)
+  #define _DBC_put(dbc,a,b,c)       dbc->put(dbc,a,b,c)
 #endif
 
 
 /* --------------------------------------------------------------------- */
 /* Utility macros and functions */
 
+#define INSERT_IN_DOUBLE_LINKED_LIST(backlink,object)                   \
+    {                                                                   \
+        object->sibling_next=backlink;                                  \
+        object->sibling_prev_p=&(backlink);                             \
+        backlink=object;                                                \
+        if (object->sibling_next) {                                     \
+          object->sibling_next->sibling_prev_p=&(object->sibling_next); \
+        }                                                               \
+    }
+
+#define EXTRACT_FROM_DOUBLE_LINKED_LIST(object)                          \
+    {                                                                    \
+        if (object->sibling_next) {                                      \
+            object->sibling_next->sibling_prev_p=object->sibling_prev_p; \
+        }                                                                \
+        *(object->sibling_prev_p)=object->sibling_next;                  \
+    }
+
+#define EXTRACT_FROM_DOUBLE_LINKED_LIST_MAYBE_NULL(object)               \
+    {                                                                    \
+        if (object->sibling_next) {                                      \
+            object->sibling_next->sibling_prev_p=object->sibling_prev_p; \
+        }                                                                \
+        if (object->sibling_prev_p) {                                    \
+            *(object->sibling_prev_p)=object->sibling_next;              \
+        }                                                                \
+    }
+
+#define INSERT_IN_DOUBLE_LINKED_LIST_TXN(backlink,object)  \
+    {                                                      \
+        object->sibling_next_txn=backlink;                 \
+        object->sibling_prev_p_txn=&(backlink);            \
+        backlink=object;                                   \
+        if (object->sibling_next_txn) {                    \
+            object->sibling_next_txn->sibling_prev_p_txn=  \
+                &(object->sibling_next_txn);               \
+        }                                                  \
+    }
+
+#define EXTRACT_FROM_DOUBLE_LINKED_LIST_TXN(object)             \
+    {                                                           \
+        if (object->sibling_next_txn) {                         \
+            object->sibling_next_txn->sibling_prev_p_txn=       \
+                object->sibling_prev_p_txn;                     \
+        }                                                       \
+        *(object->sibling_prev_p_txn)=object->sibling_next_txn; \
+    }
+
+
 #define RETURN_IF_ERR()          \
     if (makeDBError(err)) {      \
         return NULL;             \
@@ -324,8 +339,10 @@ staticforward PyTypeObject DB_Type, DBCursor_Type, DBEnv_Type, DBTxn_Type, DBLoc
     if ((nonNull) == NULL) {          \
         PyObject *errTuple = NULL;    \
         errTuple = Py_BuildValue("(is)", 0, #name " object has been closed"); \
-        PyErr_SetObject((pyErrObj), errTuple);  \
-	Py_DECREF(errTuple);          \
+        if (errTuple) { \
+            PyErr_SetObject((pyErrObj), errTuple);  \
+            Py_DECREF(errTuple);          \
+        } \
         return NULL;                  \
     }
 
@@ -358,17 +375,14 @@ static int makeDBError(int err);
 /* Return the access method type of the DBObject */
 static int _DB_get_type(DBObject* self)
 {
-#if (DBVER >= 33)
     DBTYPE type;
     int err;
+
     err = self->db->get_type(self->db, &type);
     if (makeDBError(err)) {
         return -1;
     }
     return type;
-#else
-    return self->db->get_type(self->db);
-#endif
 }
 
 
@@ -382,7 +396,11 @@ static int make_dbt(PyObject* obj, DBT* dbt)
     }
     else if (!PyArg_Parse(obj, "s#", &dbt->data, &dbt->size)) {
         PyErr_SetString(PyExc_TypeError,
+#if (PY_VERSION_HEX < 0x03000000)
                         "Data values must be of type string or None.");
+#else
+                        "Data values must be of type bytes or None.");
+#endif
         return 0;
     }
     return 1;
@@ -413,7 +431,7 @@ make_key_dbt(DBObject* self, PyObject* keyobj, DBT* key, int* pflags)
         /* no need to do anything, the structure has already been zeroed */
     }
 
-    else if (PyString_Check(keyobj)) {
+    else if (PyBytes_Check(keyobj)) {
         /* verify access method type */
         type = _DB_get_type(self);
         if (type == -1)
@@ -421,7 +439,11 @@ make_key_dbt(DBObject* self, PyObject* keyobj, DBT* key, int* pflags)
         if (type == DB_RECNO || type == DB_QUEUE) {
             PyErr_SetString(
                 PyExc_TypeError,
+#if (PY_VERSION_HEX < 0x03000000)
                 "String keys not allowed for Recno and Queue DB's");
+#else
+                "Bytes keys not allowed for Recno and Queue DB's");
+#endif
             return 0;
         }
 
@@ -432,18 +454,18 @@ make_key_dbt(DBObject* self, PyObject* keyobj, DBT* key, int* pflags)
          * the code check for DB_THREAD and forceably set DBT_MALLOC
          * when we otherwise would leave flags 0 to indicate that.
          */
-        key->data = malloc(PyString_GET_SIZE(keyobj));
+        key->data = malloc(PyBytes_GET_SIZE(keyobj));
         if (key->data == NULL) {
             PyErr_SetString(PyExc_MemoryError, "Key memory allocation failed");
             return 0;
         }
-        memcpy(key->data, PyString_AS_STRING(keyobj),
-               PyString_GET_SIZE(keyobj));
+        memcpy(key->data, PyBytes_AS_STRING(keyobj),
+               PyBytes_GET_SIZE(keyobj));
         key->flags = DB_DBT_REALLOC;
-        key->size = PyString_GET_SIZE(keyobj);
+        key->size = PyBytes_GET_SIZE(keyobj);
     }
 
-    else if (PyInt_Check(keyobj)) {
+    else if (NUMBER_Check(keyobj)) {
         /* verify access method type */
         type = _DB_get_type(self);
         if (type == -1)
@@ -462,7 +484,7 @@ make_key_dbt(DBObject* self, PyObject* keyobj, DBT* key, int* pflags)
 
         /* Make a key out of the requested recno, use allocated space so DB
          * will be able to realloc room for the real key if needed. */
-        recno = PyInt_AS_LONG(keyobj);
+        recno = NUMBER_AsLong(keyobj);
         key->data = malloc(sizeof(db_recno_t));
         if (key->data == NULL) {
             PyErr_SetString(PyExc_MemoryError, "Key memory allocation failed");
@@ -474,8 +496,12 @@ make_key_dbt(DBObject* self, PyObject* keyobj, DBT* key, int* pflags)
     }
     else {
         PyErr_Format(PyExc_TypeError,
+#if (PY_VERSION_HEX < 0x03000000)
                      "String or Integer object expected for key, %s found",
-                     keyobj->ob_type->tp_name);
+#else
+                     "Bytes or Integer object expected for key, %s found",
+#endif
+                     Py_TYPE(keyobj)->tp_name);
         return 0;
     }
 
@@ -511,7 +537,7 @@ unsigned int our_strlcpy(char* dest, const char* src, unsigned int n)
 
     srclen = strlen(src);
     if (n <= 0)
-	return srclen;
+        return srclen;
     copylen = (srclen > n-1) ? n-1 : srclen;
     /* populate dest[0] thru dest[copylen-1] */
     memcpy(dest, src, copylen);
@@ -528,13 +554,109 @@ static char _db_errmsg[1024];
 static void _db_errorCallback(const char* prefix, char* msg)
 #else
 static void _db_errorCallback(const DB_ENV *db_env,
-	const char* prefix, const char* msg)
+        const char* prefix, const char* msg)
 #endif
 {
     our_strlcpy(_db_errmsg, msg, sizeof(_db_errmsg));
 }
 
 
+/*
+** We need these functions because some results
+** are undefined if pointer is NULL. Some other
+** give None instead of "".
+**
+** This functions are static and will be
+** -I hope- inlined.
+*/
+static const char *DummyString = "This string is a simple placeholder";
+static PyObject *Build_PyString(const char *p,int s)
+{
+  if (!p) {
+    p=DummyString;
+    assert(s==0);
+  }
+  return PyBytes_FromStringAndSize(p,s);
+}
+
+static PyObject *BuildValue_S(const void *p,int s)
+{
+  if (!p) {
+    p=DummyString;
+    assert(s==0);
+  }
+  return PyBytes_FromStringAndSize(p, s);
+}
+
+static PyObject *BuildValue_SS(const void *p1,int s1,const void *p2,int s2)
+{
+PyObject *a, *b, *r;
+
+  if (!p1) {
+    p1=DummyString;
+    assert(s1==0);
+  }
+  if (!p2) {
+    p2=DummyString;
+    assert(s2==0);
+  }
+
+  if (!(a = PyBytes_FromStringAndSize(p1, s1))) {
+      return NULL;
+  }
+  if (!(b = PyBytes_FromStringAndSize(p2, s2))) {
+      Py_DECREF(a);
+      return NULL;
+  }
+
+#if (PY_VERSION_HEX >= 0x02040000)
+  r = PyTuple_Pack(2, a, b) ;
+#else
+  r = Py_BuildValue("OO", a, b);
+#endif
+  Py_DECREF(a);
+  Py_DECREF(b);
+  return r;
+}
+
+static PyObject *BuildValue_IS(int i,const void *p,int s)
+{
+  PyObject *a, *r;
+
+  if (!p) {
+    p=DummyString;
+    assert(s==0);
+  }
+
+  if (!(a = PyBytes_FromStringAndSize(p, s))) {
+      return NULL;
+  }
+
+  r = Py_BuildValue("iO", i, a);
+  Py_DECREF(a);
+  return r;
+}
+
+static PyObject *BuildValue_LS(long l,const void *p,int s)
+{
+  PyObject *a, *r;
+
+  if (!p) {
+    p=DummyString;
+    assert(s==0);
+  }
+
+  if (!(a = PyBytes_FromStringAndSize(p, s))) {
+      return NULL;
+  }
+
+  r = Py_BuildValue("lO", l, a);
+  Py_DECREF(a);
+  return r;
+}
+
+
+
 /* make a nice exception object to raise for errors. */
 static int makeDBError(int err)
 {
@@ -554,17 +676,12 @@ static int makeDBError(int err)
             /* Ensure that bytes_left never goes negative */
             if (_db_errmsg[0] && bytes_left < (sizeof(errTxt) - 4)) {
                 bytes_left = sizeof(errTxt) - bytes_left - 4 - 1;
-		assert(bytes_left >= 0);
+                assert(bytes_left >= 0);
                 strcat(errTxt, " -- ");
                 strncat(errTxt, _db_errmsg, bytes_left);
             }
             _db_errmsg[0] = 0;
-#ifdef HAVE_WARNINGS
             exceptionRaised = PyErr_Warn(PyExc_RuntimeWarning, errTxt);
-#else
-            fprintf(stderr, errTxt);
-            fprintf(stderr, "\n");
-#endif
 
 #else  /* do an exception instead */
         errObj = DBIncompleteError;
@@ -583,15 +700,13 @@ static int makeDBError(int err)
         case DB_NOSERVER:           errObj = DBNoServerError;       break;
         case DB_NOSERVER_HOME:      errObj = DBNoServerHomeError;   break;
         case DB_NOSERVER_ID:        errObj = DBNoServerIDError;     break;
-#if (DBVER >= 33)
         case DB_PAGE_NOTFOUND:      errObj = DBPageNotFoundError;   break;
         case DB_SECONDARY_BAD:      errObj = DBSecondaryBadError;   break;
-#endif
         case DB_BUFFER_SMALL:       errObj = DBNoMemoryError;       break;
 
 #if (DBVER >= 43)
-	/* ENOMEM and DB_BUFFER_SMALL were one and the same until 4.3 */
-	case ENOMEM:  errObj = PyExc_MemoryError;   break;
+        /* ENOMEM and DB_BUFFER_SMALL were one and the same until 4.3 */
+        case ENOMEM:  errObj = PyExc_MemoryError;   break;
 #endif
         case EINVAL:  errObj = DBInvalidArgError;   break;
         case EACCES:  errObj = DBAccessError;       break;
@@ -602,6 +717,12 @@ static int makeDBError(int err)
         case ENOENT:  errObj = DBNoSuchFileError;   break;
         case EPERM :  errObj = DBPermissionsError;  break;
 
+#if (DBVER >= 42)
+        case DB_REP_HANDLE_DEAD : errObj = DBRepHandleDeadError; break;
+#endif
+
+        case DB_REP_UNAVAIL : errObj = DBRepUnavailError; break;
+
         default:      errObj = DBError;             break;
     }
 
@@ -616,9 +737,13 @@ static int makeDBError(int err)
         }
         _db_errmsg[0] = 0;
 
-	errTuple = Py_BuildValue("(is)", err, errTxt);
+        errTuple = Py_BuildValue("(is)", err, errTxt);
+        if (errTuple == NULL) {
+            Py_DECREF(errObj);
+            return !0;
+        }
         PyErr_SetObject(errObj, errTuple);
-	Py_DECREF(errTuple);
+        Py_DECREF(errTuple);
     }
 
     return ((errObj != NULL) || exceptionRaised);
@@ -630,7 +755,7 @@ static int makeDBError(int err)
 static void makeTypeError(char* expected, PyObject* found)
 {
     PyErr_Format(PyExc_TypeError, "Expected %s argument, %s found.",
-                 expected, found->ob_type->tp_name);
+                 expected, Py_TYPE(found)->tp_name);
 }
 
 
@@ -686,7 +811,7 @@ static int _DB_put(DBObject* self, DB_TXN *txn, DBT *key, DBT *data, int flags)
 
 /* Get a key/data pair from a cursor */
 static PyObject* _DBCursor_get(DBCursorObject* self, int extra_flags,
-			       PyObject *args, PyObject *kwargs, char *format)
+                               PyObject *args, PyObject *kwargs, char *format)
 {
     int err;
     PyObject* retval = NULL;
@@ -697,7 +822,7 @@ static PyObject* _DBCursor_get(DBCursorObject* self, int extra_flags,
     static char* kwnames[] = { "flags", "dlen", "doff", NULL };
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, format, kwnames,
-				     &flags, &dlen, &doff)) 
+                                     &flags, &dlen, &doff))
       return NULL;
 
     CHECK_CURSOR_NOT_CLOSED(self);
@@ -705,20 +830,15 @@ static PyObject* _DBCursor_get(DBCursorObject* self, int extra_flags,
     flags |= extra_flags;
     CLEAR_DBT(key);
     CLEAR_DBT(data);
-    if (CHECK_DBFLAG(self->mydb, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
-        data.flags = DB_DBT_MALLOC;
-        key.flags = DB_DBT_MALLOC;
-    }
     if (!add_partial_dbt(&data, dlen, doff))
         return NULL;
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, flags);
+    err = _DBC_get(self->dbc, &key, &data, flags);
     MYDB_END_ALLOW_THREADS;
 
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->mydb->moduleFlags.getReturnsNone) {
+            && self->mydb->moduleFlags.getReturnsNone) {
         Py_INCREF(Py_None);
         retval = Py_None;
     }
@@ -735,21 +855,15 @@ static PyObject* _DBCursor_get(DBCursorObject* self, int extra_flags,
 
         case DB_RECNO:
         case DB_QUEUE:
-            retval = Py_BuildValue("is#", *((db_recno_t*)key.data),
-                                   data.data, data.size);
+            retval = BuildValue_IS(*((db_recno_t*)key.data), data.data, data.size);
             break;
         case DB_HASH:
         case DB_BTREE:
         default:
-            retval = Py_BuildValue("s#s#", key.data, key.size,
-                                   data.data, data.size);
+            retval = BuildValue_SS(key.data, key.size, data.data, data.size);
             break;
         }
     }
-    if (!err) {
-        FREE_DBT(key);
-        FREE_DBT(data);
-    }
     return retval;
 }
 
@@ -757,12 +871,30 @@ static PyObject* _DBCursor_get(DBCursorObject* self, int extra_flags,
 /* add an integer to a dictionary using the given name as a key */
 static void _addIntToDict(PyObject* dict, char *name, int value)
 {
-    PyObject* v = PyInt_FromLong((long) value);
+    PyObject* v = NUMBER_FromLong((long) value);
     if (!v || PyDict_SetItemString(dict, name, v))
         PyErr_Clear();
 
     Py_XDECREF(v);
 }
+
+/* The same, when the value is a time_t */
+static void _addTimeTToDict(PyObject* dict, char *name, time_t value)
+{
+    PyObject* v;
+        /* if the value fits in regular int, use that. */
+#ifdef PY_LONG_LONG
+        if (sizeof(time_t) > sizeof(long))
+                v = PyLong_FromLongLong((PY_LONG_LONG) value);
+        else
+#endif
+                v = NUMBER_FromLong((long) value);
+    if (!v || PyDict_SetItemString(dict, name, v))
+        PyErr_Clear();
+
+    Py_XDECREF(v);
+}
+
 #if (DBVER >= 43)
 /* add an db_seq_t to a dictionary using the given name as a key */
 static void _addDb_seq_tToDict(PyObject* dict, char *name, db_seq_t value)
@@ -775,7 +907,14 @@ static void _addDb_seq_tToDict(PyObject* dict, char *name, db_seq_t value)
 }
 #endif
 
+static void _addDB_lsnToDict(PyObject* dict, char *name, DB_LSN value)
+{
+    PyObject *v = Py_BuildValue("(ll)",value.file,value.offset);
+    if (!v || PyDict_SetItemString(dict, name, v))
+        PyErr_Clear();
 
+    Py_XDECREF(v);
+}
 
 /* --------------------------------------------------------------------- */
 /* Allocators and deallocators */
@@ -795,21 +934,31 @@ newDBObject(DBEnvObject* arg, int flags)
     self->flags = 0;
     self->setflags = 0;
     self->myenvobj = NULL;
-#if (DBVER >= 33)
+    self->db = NULL;
+    self->children_cursors = NULL;
+#if (DBVER >=43)
+    self->children_sequences = NULL;
+#endif
     self->associateCallback = NULL;
     self->btCompareCallback = NULL;
     self->primaryDBType = 0;
-#endif
-#ifdef HAVE_WEAKREF
+    Py_INCREF(Py_None);
+    self->private_obj = Py_None;
     self->in_weakreflist = NULL;
-#endif
 
     /* keep a reference to our python DBEnv object */
     if (arg) {
         Py_INCREF(arg);
         self->myenvobj = arg;
         db_env = arg->db_env;
+        INSERT_IN_DOUBLE_LINKED_LIST(self->myenvobj->children_dbs,self);
+    } else {
+      self->sibling_prev_p=NULL;
+      self->sibling_next=NULL;
     }
+    self->txn=NULL;
+    self->sibling_prev_p_txn=NULL;
+    self->sibling_next_txn=NULL;
 
     if (self->myenvobj)
         self->moduleFlags = self->myenvobj->moduleFlags;
@@ -821,9 +970,7 @@ newDBObject(DBEnvObject* arg, int flags)
     err = db_create(&self->db, db_env, flags);
     if (self->db != NULL) {
         self->db->set_errcall(self->db, _db_errorCallback);
-#if (DBVER >= 33)
         self->db->app_private = (void*)self;
-#endif
     }
     MYDB_END_ALLOW_THREADS;
     /* TODO add a weakref(self) to the self->myenvobj->open_child_weakrefs
@@ -841,36 +988,32 @@ newDBObject(DBEnvObject* arg, int flags)
 }
 
 
+/* Forward declaration */
+static PyObject *DB_close_internal(DBObject* self, int flags, int do_not_close);
+
 static void
 DB_dealloc(DBObject* self)
 {
+  PyObject *dummy;
+
     if (self->db != NULL) {
-        /* avoid closing a DB when its DBEnv has been closed out from under
-         * it */
-        if (!self->myenvobj ||
-            (self->myenvobj && self->myenvobj->db_env))
-        {
-            MYDB_BEGIN_ALLOW_THREADS;
-            self->db->close(self->db, 0);
-            MYDB_END_ALLOW_THREADS;
-#ifdef HAVE_WARNINGS
-        } else {
-            PyErr_Warn(PyExc_RuntimeWarning,
-                "DB could not be closed in destructor: DBEnv already closed");
-#endif
-        }
-        self->db = NULL;
+        dummy=DB_close_internal(self, 0, 0);
+        /*
+        ** Raising exceptions while doing
+        ** garbage collection is a fatal error.
+        */
+        if (dummy)
+            Py_DECREF(dummy);
+        else
+            PyErr_Clear();
     }
-#ifdef HAVE_WEAKREF
     if (self->in_weakreflist != NULL) {
         PyObject_ClearWeakRefs((PyObject *) self);
     }
-#endif
     if (self->myenvobj) {
         Py_DECREF(self->myenvobj);
         self->myenvobj = NULL;
     }
-#if (DBVER >= 33)
     if (self->associateCallback != NULL) {
         Py_DECREF(self->associateCallback);
         self->associateCallback = NULL;
@@ -879,13 +1022,12 @@ DB_dealloc(DBObject* self)
         Py_DECREF(self->btCompareCallback);
         self->btCompareCallback = NULL;
     }
-#endif
+    Py_DECREF(self->private_obj);
     PyObject_Del(self);
 }
 
-
 static DBCursorObject*
-newDBCursorObject(DBC* dbc, DBObject* db)
+newDBCursorObject(DBC* dbc, DBTxnObject *txn, DBObject* db)
 {
     DBCursorObject* self = PyObject_New(DBCursorObject, &DBCursor_Type);
     if (self == NULL)
@@ -893,44 +1035,44 @@ newDBCursorObject(DBC* dbc, DBObject* db)
 
     self->dbc = dbc;
     self->mydb = db;
-#ifdef HAVE_WEAKREF
+
+    INSERT_IN_DOUBLE_LINKED_LIST(self->mydb->children_cursors,self);
+    if (txn && ((PyObject *)txn!=Py_None)) {
+            INSERT_IN_DOUBLE_LINKED_LIST_TXN(txn->children_cursors,self);
+            self->txn=txn;
+    } else {
+            self->txn=NULL;
+    }
+
     self->in_weakreflist = NULL;
-#endif
     Py_INCREF(self->mydb);
     return self;
 }
 
 
+/* Forward declaration */
+static PyObject *DBC_close_internal(DBCursorObject* self);
+
 static void
 DBCursor_dealloc(DBCursorObject* self)
 {
-    int err;
+    PyObject *dummy;
 
-#ifdef HAVE_WEAKREF
+    if (self->dbc != NULL) {
+        dummy=DBC_close_internal(self);
+        /*
+        ** Raising exceptions while doing
+        ** garbage collection is a fatal error.
+        */
+        if (dummy)
+            Py_DECREF(dummy);
+        else
+            PyErr_Clear();
+    }
     if (self->in_weakreflist != NULL) {
         PyObject_ClearWeakRefs((PyObject *) self);
     }
-#endif
-
-    if (self->dbc != NULL) {
-	/* If the underlying database has been closed, we don't
-	   need to do anything. If the environment has been closed
-	   we need to leak, as BerkeleyDB will crash trying to access
-	   the environment. There was an exception when the 
-	   user closed the environment even though there still was
-	   a database open. */
-	if (self->mydb->db && self->mydb->myenvobj &&
-	    !self->mydb->myenvobj->closed)
-        /* test for: open db + no environment or non-closed environment */
-	if (self->mydb->db && (!self->mydb->myenvobj || (self->mydb->myenvobj &&
-	    !self->mydb->myenvobj->closed))) {
-            MYDB_BEGIN_ALLOW_THREADS;
-            err = self->dbc->c_close(self->dbc);
-            MYDB_END_ALLOW_THREADS;
-        }
-        self->dbc = NULL;
-    }
-    Py_XDECREF( self->mydb );
+    Py_DECREF(self->mydb);
     PyObject_Del(self);
 }
 
@@ -943,13 +1085,19 @@ newDBEnvObject(int flags)
     if (self == NULL)
         return NULL;
 
+    self->db_env = NULL;
     self->closed = 1;
     self->flags = flags;
     self->moduleFlags.getReturnsNone = DEFAULT_GET_RETURNS_NONE;
     self->moduleFlags.cursorSetReturnsNone = DEFAULT_CURSOR_SET_RETURNS_NONE;
-#ifdef HAVE_WEAKREF
+    self->children_dbs = NULL;
+    self->children_txns = NULL;
+    Py_INCREF(Py_None);
+    self->private_obj = Py_None;
+    Py_INCREF(Py_None);
+    self->rep_transport = Py_None;
     self->in_weakreflist = NULL;
-#endif
+    self->event_notifyCallback = NULL;
 
     MYDB_BEGIN_ALLOW_THREADS;
     err = db_env_create(&self->db_env, flags);
@@ -960,82 +1108,132 @@ newDBEnvObject(int flags)
     }
     else {
         self->db_env->set_errcall(self->db_env, _db_errorCallback);
+        self->db_env->app_private = self;
     }
     return self;
 }
 
+/* Forward declaration */
+static PyObject *DBEnv_close_internal(DBEnvObject* self, int flags);
 
 static void
 DBEnv_dealloc(DBEnvObject* self)
 {
-#ifdef HAVE_WEAKREF
-    if (self->in_weakreflist != NULL) {
-        PyObject_ClearWeakRefs((PyObject *) self);
+  PyObject *dummy;
+
+    if (self->db_env) {
+        dummy=DBEnv_close_internal(self, 0);
+        /*
+        ** Raising exceptions while doing
+        ** garbage collection is a fatal error.
+        */
+        if (dummy)
+            Py_DECREF(dummy);
+        else
+            PyErr_Clear();
     }
-#endif
 
-    if (self->db_env && !self->closed) {
-        MYDB_BEGIN_ALLOW_THREADS;
-        self->db_env->close(self->db_env, 0);
-        MYDB_END_ALLOW_THREADS;
+    Py_XDECREF(self->event_notifyCallback);
+    self->event_notifyCallback = NULL;
+
+    if (self->in_weakreflist != NULL) {
+        PyObject_ClearWeakRefs((PyObject *) self);
     }
+    Py_DECREF(self->private_obj);
+    Py_DECREF(self->rep_transport);
     PyObject_Del(self);
 }
 
 
 static DBTxnObject*
-newDBTxnObject(DBEnvObject* myenv, DB_TXN *parent, int flags)
+newDBTxnObject(DBEnvObject* myenv, DBTxnObject *parent, DB_TXN *txn, int flags)
 {
     int err;
+    DB_TXN *parent_txn = NULL;
+
     DBTxnObject* self = PyObject_New(DBTxnObject, &DBTxn_Type);
     if (self == NULL)
         return NULL;
-    Py_INCREF(myenv);
-    self->env = (PyObject*)myenv;
-#ifdef HAVE_WEAKREF
+
     self->in_weakreflist = NULL;
-#endif
+    self->children_txns = NULL;
+    self->children_dbs = NULL;
+    self->children_cursors = NULL;
+    self->children_sequences = NULL;
+    self->flag_prepare = 0;
+    self->parent_txn = NULL;
+    self->env = NULL;
 
-    MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
-    err = myenv->db_env->txn_begin(myenv->db_env, parent, &(self->txn), flags);
-#else
-    err = txn_begin(myenv->db_env, parent, &(self->txn), flags);
-#endif
-    MYDB_END_ALLOW_THREADS;
-    if (makeDBError(err)) {
-        Py_DECREF(self);
-        self = NULL;
+    if (parent && ((PyObject *)parent!=Py_None)) {
+        parent_txn = parent->txn;
     }
+
+    if (txn) {
+        self->txn = txn;
+    } else {
+        MYDB_BEGIN_ALLOW_THREADS;
+        err = myenv->db_env->txn_begin(myenv->db_env, parent_txn, &(self->txn), flags);
+        MYDB_END_ALLOW_THREADS;
+
+        if (makeDBError(err)) {
+            Py_DECREF(self);
+            return NULL;
+        }
+    }
+
+    /* Can't use 'parent' because could be 'parent==Py_None' */
+    if (parent_txn) {
+        self->parent_txn = parent;
+        Py_INCREF(parent);
+        self->env = NULL;
+        INSERT_IN_DOUBLE_LINKED_LIST(parent->children_txns, self);
+    } else {
+        self->parent_txn = NULL;
+        Py_INCREF(myenv);
+        self->env = myenv;
+        INSERT_IN_DOUBLE_LINKED_LIST(myenv->children_txns, self);
+    }
+
     return self;
 }
 
+/* Forward declaration */
+static PyObject *
+DBTxn_abort_discard_internal(DBTxnObject* self, int discard);
 
 static void
 DBTxn_dealloc(DBTxnObject* self)
 {
-#ifdef HAVE_WEAKREF
+  PyObject *dummy;
+
+    if (self->txn) {
+        int flag_prepare = self->flag_prepare;
+
+        dummy=DBTxn_abort_discard_internal(self,0);
+        /*
+        ** Raising exceptions while doing
+        ** garbage collection is a fatal error.
+        */
+        if (dummy)
+            Py_DECREF(dummy);
+        else
+            PyErr_Clear();
+
+        if (!flag_prepare) {
+            PyErr_Warn(PyExc_RuntimeWarning,
+              "DBTxn aborted in destructor.  No prior commit() or abort().");
+        }
+    }
+
     if (self->in_weakreflist != NULL) {
         PyObject_ClearWeakRefs((PyObject *) self);
     }
-#endif
 
-#ifdef HAVE_WARNINGS
-    if (self->txn) {
-        /* it hasn't been finalized, abort it! */
-        MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
-        self->txn->abort(self->txn);
-#else
-        txn_abort(self->txn);
-#endif
-        MYDB_END_ALLOW_THREADS;
-        PyErr_Warn(PyExc_RuntimeWarning,
-            "DBTxn aborted in destructor.  No prior commit() or abort().");
+    if (self->env) {
+        Py_DECREF(self->env);
+    } else {
+        Py_DECREF(self->parent_txn);
     }
-#endif
-
-    Py_DECREF(self->env);
     PyObject_Del(self);
 }
 
@@ -1048,17 +1246,11 @@ newDBLockObject(DBEnvObject* myenv, u_int32_t locker, DBT* obj,
     DBLockObject* self = PyObject_New(DBLockObject, &DBLock_Type);
     if (self == NULL)
         return NULL;
-#ifdef HAVE_WEAKREF
     self->in_weakreflist = NULL;
-#endif
 
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = myenv->db_env->lock_get(myenv->db_env, locker, flags, obj, lock_mode,
                                   &self->lock);
-#else
-    err = lock_get(myenv->db_env, locker, flags, obj, lock_mode, &self->lock);
-#endif
     MYDB_END_ALLOW_THREADS;
     if (makeDBError(err)) {
         Py_DECREF(self);
@@ -1072,11 +1264,9 @@ newDBLockObject(DBEnvObject* myenv, u_int32_t locker, DBT* obj,
 static void
 DBLock_dealloc(DBLockObject* self)
 {
-#ifdef HAVE_WEAKREF
     if (self->in_weakreflist != NULL) {
         PyObject_ClearWeakRefs((PyObject *) self);
     }
-#endif
     /* TODO: is this lock held? should we release it? */
 
     PyObject_Del(self);
@@ -1093,10 +1283,11 @@ newDBSequenceObject(DBObject* mydb,  int flags)
         return NULL;
     Py_INCREF(mydb);
     self->mydb = mydb;
-#ifdef HAVE_WEAKREF
-    self->in_weakreflist = NULL;
-#endif
 
+    INSERT_IN_DOUBLE_LINKED_LIST(self->mydb->children_sequences,self);
+    self->txn = NULL;
+
+    self->in_weakreflist = NULL;
 
     MYDB_BEGIN_ALLOW_THREADS;
     err = db_sequence_create(&self->sequence, self->mydb->db, flags);
@@ -1109,15 +1300,30 @@ newDBSequenceObject(DBObject* mydb,  int flags)
     return self;
 }
 
+/* Forward declaration */
+static PyObject
+*DBSequence_close_internal(DBSequenceObject* self, int flags, int do_not_close);
 
 static void
 DBSequence_dealloc(DBSequenceObject* self)
 {
-#ifdef HAVE_WEAKREF
+    PyObject *dummy;
+
+    if (self->sequence != NULL) {
+        dummy=DBSequence_close_internal(self,0,0);
+        /*
+        ** Raising exceptions while doing
+        ** garbage collection is a fatal error.
+        */
+        if (dummy)
+            Py_DECREF(dummy);
+        else
+            PyErr_Clear();
+    }
+
     if (self->in_weakreflist != NULL) {
         PyObject_ClearWeakRefs((PyObject *) self);
     }
-#endif
 
     Py_DECREF(self->mydb);
     PyObject_Del(self);
@@ -1128,15 +1334,17 @@ DBSequence_dealloc(DBSequenceObject* self)
 /* DB methods */
 
 static PyObject*
-DB_append(DBObject* self, PyObject* args)
+DB_append(DBObject* self, PyObject* args, PyObject* kwargs)
 {
     PyObject* txnobj = NULL;
     PyObject* dataobj;
     db_recno_t recno;
     DBT key, data;
     DB_TXN *txn = NULL;
+    static char* kwnames[] = { "data", "txn", NULL };
 
-    if (!PyArg_UnpackTuple(args, "append", 1, 2, &dataobj, &txnobj))
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs, "O|O:append", kwnames,
+                                     &dataobj, &txnobj))
         return NULL;
 
     CHECK_DB_NOT_CLOSED(self);
@@ -1155,12 +1363,10 @@ DB_append(DBObject* self, PyObject* args)
     if (-1 == _DB_put(self, txn, &key, &data, DB_APPEND))
         return NULL;
 
-    return PyInt_FromLong(recno);
+    return NUMBER_FromLong(recno);
 }
 
 
-#if (DBVER >= 33)
-
 static int
 _db_associateCallback(DB* db, const DBT* priKey, const DBT* priData,
                       DBT* secKey)
@@ -1177,11 +1383,9 @@ _db_associateCallback(DB* db, const DBT* priKey, const DBT* priData,
         MYDB_BEGIN_BLOCK_THREADS;
 
         if (type == DB_RECNO || type == DB_QUEUE)
-            args = Py_BuildValue("(ls#)", *((db_recno_t*)priKey->data),
-                                 priData->data, priData->size);
+            args = BuildValue_LS(*((db_recno_t*)priKey->data), priData->data, priData->size);
         else
-            args = Py_BuildValue("(s#s#)", priKey->data, priKey->size,
-                                 priData->data, priData->size);
+            args = BuildValue_SS(priKey->data, priKey->size, priData->data, priData->size);
         if (args != NULL) {
                 result = PyEval_CallObject(callback, args);
         }
@@ -1191,33 +1395,27 @@ _db_associateCallback(DB* db, const DBT* priKey, const DBT* priData,
         else if (result == Py_None) {
             retval = DB_DONOTINDEX;
         }
-        else if (PyInt_Check(result)) {
-            retval = PyInt_AsLong(result);
+        else if (NUMBER_Check(result)) {
+            retval = NUMBER_AsLong(result);
         }
-        else if (PyString_Check(result)) {
+        else if (PyBytes_Check(result)) {
             char* data;
             Py_ssize_t size;
 
             CLEAR_DBT(*secKey);
-#if PYTHON_API_VERSION <= 1007
-            /* 1.5 compatibility */
-            size = PyString_Size(result);
-            data = PyString_AsString(result);
-#else
-            PyString_AsStringAndSize(result, &data, &size);
-#endif
+            PyBytes_AsStringAndSize(result, &data, &size);
             secKey->flags = DB_DBT_APPMALLOC;   /* DB will free */
             secKey->data = malloc(size);        /* TODO, check this */
-	    if (secKey->data) {
-		memcpy(secKey->data, data, size);
-		secKey->size = size;
-		retval = 0;
-	    }
-	    else {
-		PyErr_SetString(PyExc_MemoryError,
+            if (secKey->data) {
+                memcpy(secKey->data, data, size);
+                secKey->size = size;
+                retval = 0;
+            }
+            else {
+                PyErr_SetString(PyExc_MemoryError,
                                 "malloc failed in _db_associateCallback");
-		PyErr_Print();
-	    }
+                PyErr_Print();
+            }
         }
         else {
             PyErr_SetString(
@@ -1301,7 +1499,7 @@ DB_associate(DBObject* self, PyObject* args, PyObject* kwargs)
     MYDB_BEGIN_ALLOW_THREADS;
 #if (DBVER >= 41)
     err = self->db->associate(self->db,
-	                      txn,
+                              txn,
                               secondaryDB->db,
                               _db_associateCallback,
                               flags);
@@ -1324,27 +1522,62 @@ DB_associate(DBObject* self, PyObject* args, PyObject* kwargs)
 }
 
 
+static PyObject*
+DB_close_internal(DBObject* self, int flags, int do_not_close)
+{
+    PyObject *dummy;
+    int err = 0;
+
+    if (self->db != NULL) {
+        /* Can be NULL if db is not in an environment */
+        EXTRACT_FROM_DOUBLE_LINKED_LIST_MAYBE_NULL(self);
+
+        if (self->txn) {
+            EXTRACT_FROM_DOUBLE_LINKED_LIST_TXN(self);
+            self->txn=NULL;
+        }
+
+        while(self->children_cursors) {
+          dummy=DBC_close_internal(self->children_cursors);
+          Py_XDECREF(dummy);
+        }
+
+#if (DBVER >= 43)
+        while(self->children_sequences) {
+            dummy=DBSequence_close_internal(self->children_sequences,0,0);
+            Py_XDECREF(dummy);
+        }
 #endif
 
+        /*
+        ** "do_not_close" is used to dispose all related objects in the
+        ** tree, without actually releasing the "root" object.
+        ** This is done, for example, because function calls like
+        ** "DB.verify()" implicitly close the underlying handle. So
+        ** the handle doesn't need to be closed, but related objects
+        ** must be cleaned up.
+        */
+        if (!do_not_close) {
+            MYDB_BEGIN_ALLOW_THREADS;
+            err = self->db->close(self->db, flags);
+            MYDB_END_ALLOW_THREADS;
+            self->db = NULL;
+        }
+        RETURN_IF_ERR();
+    }
+    RETURN_NONE();
+}
 
 static PyObject*
 DB_close(DBObject* self, PyObject* args)
 {
-    int err, flags=0;
+    int flags=0;
     if (!PyArg_ParseTuple(args,"|i:close", &flags))
         return NULL;
-    if (self->db != NULL) {
-        if (self->myenvobj)
-            CHECK_ENV_NOT_CLOSED(self->myenvobj);
-        err = self->db->close(self->db, flags);
-        self->db = NULL;
-        RETURN_IF_ERR();
-    }
-    RETURN_NONE();
+    return DB_close_internal(self, flags, 0);
 }
 
 
-#if (DBVER >= 32)
 static PyObject*
 _DB_consume(DBObject* self, PyObject* args, PyObject* kwargs, int consume_flag)
 {
@@ -1374,7 +1607,7 @@ _DB_consume(DBObject* self, PyObject* args, PyObject* kwargs, int consume_flag)
     CLEAR_DBT(key);
     CLEAR_DBT(data);
     if (CHECK_DBFLAG(self, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
+        /* Tell Berkeley DB to malloc the return value (thread safe) */
         data.flags = DB_DBT_MALLOC;
         key.flags = DB_DBT_MALLOC;
     }
@@ -1384,14 +1617,13 @@ _DB_consume(DBObject* self, PyObject* args, PyObject* kwargs, int consume_flag)
     MYDB_END_ALLOW_THREADS;
 
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->moduleFlags.getReturnsNone) {
+            && self->moduleFlags.getReturnsNone) {
         err = 0;
         Py_INCREF(Py_None);
         retval = Py_None;
     }
     else if (!err) {
-        retval = Py_BuildValue("s#s#", key.data, key.size, data.data,
-                               data.size);
+        retval = BuildValue_SS(key.data, key.size, data.data, data.size);
         FREE_DBT(key);
         FREE_DBT(data);
     }
@@ -1412,8 +1644,6 @@ DB_consume_wait(DBObject* self, PyObject* args, PyObject* kwargs,
 {
     return _DB_consume(self, args, kwargs, DB_CONSUME_WAIT);
 }
-#endif
-
 
 
 static PyObject*
@@ -1436,7 +1666,7 @@ DB_cursor(DBObject* self, PyObject* args, PyObject* kwargs)
     err = self->db->cursor(self->db, txn, &dbc, flags);
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
-    return (PyObject*) newDBCursorObject(dbc, self);
+    return (PyObject*) newDBCursorObject(dbc, (DBTxnObject *)txnobj, self);
 }
 
 
@@ -1472,19 +1702,17 @@ DB_delete(DBObject* self, PyObject* args, PyObject* kwargs)
 
 
 static PyObject*
-DB_fd(DBObject* self, PyObject* args)
+DB_fd(DBObject* self)
 {
     int err, the_fd;
 
-    if (!PyArg_ParseTuple(args,":fd"))
-        return NULL;
     CHECK_DB_NOT_CLOSED(self);
 
     MYDB_BEGIN_ALLOW_THREADS;
     err = self->db->fd(self->db, &the_fd);
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
-    return PyInt_FromLong(the_fd);
+    return NUMBER_FromLong(the_fd);
 }
 
 
@@ -1518,7 +1746,7 @@ DB_get(DBObject* self, PyObject* args, PyObject* kwargs)
 
     CLEAR_DBT(data);
     if (CHECK_DBFLAG(self, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
+        /* Tell Berkeley DB to malloc the return value (thread safe) */
         data.flags = DB_DBT_MALLOC;
     }
     if (!add_partial_dbt(&data, dlen, doff)) {
@@ -1536,17 +1764,16 @@ DB_get(DBObject* self, PyObject* args, PyObject* kwargs)
         retval = dfltobj;
     }
     else if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	     && self->moduleFlags.getReturnsNone) {
+             && self->moduleFlags.getReturnsNone) {
         err = 0;
         Py_INCREF(Py_None);
         retval = Py_None;
     }
     else if (!err) {
         if (flags & DB_SET_RECNO) /* return both key and data */
-            retval = Py_BuildValue("s#s#", key.data, key.size, data.data,
-                                   data.size);
+            retval = BuildValue_SS(key.data, key.size, data.data, data.size);
         else /* return just the data */
-            retval = PyString_FromStringAndSize((char*)data.data, data.size);
+            retval = Build_PyString(data.data, data.size);
         FREE_DBT(data);
     }
     FREE_DBT(key);
@@ -1555,7 +1782,6 @@ DB_get(DBObject* self, PyObject* args, PyObject* kwargs)
     return retval;
 }
 
-#if (DBVER >= 33)
 static PyObject*
 DB_pget(DBObject* self, PyObject* args, PyObject* kwargs)
 {
@@ -1586,7 +1812,7 @@ DB_pget(DBObject* self, PyObject* args, PyObject* kwargs)
 
     CLEAR_DBT(data);
     if (CHECK_DBFLAG(self, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
+        /* Tell Berkeley DB to malloc the return value (thread safe) */
         data.flags = DB_DBT_MALLOC;
     }
     if (!add_partial_dbt(&data, dlen, doff)) {
@@ -1596,7 +1822,7 @@ DB_pget(DBObject* self, PyObject* args, PyObject* kwargs)
 
     CLEAR_DBT(pkey);
     pkey.flags = DB_DBT_MALLOC;
-    
+
     MYDB_BEGIN_ALLOW_THREADS;
     err = self->db->pget(self->db, txn, &key, &pkey, &data, flags);
     MYDB_END_ALLOW_THREADS;
@@ -1607,7 +1833,7 @@ DB_pget(DBObject* self, PyObject* args, PyObject* kwargs)
         retval = dfltobj;
     }
     else if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	     && self->moduleFlags.getReturnsNone) {
+             && self->moduleFlags.getReturnsNone) {
         err = 0;
         Py_INCREF(Py_None);
         retval = Py_None;
@@ -1615,22 +1841,22 @@ DB_pget(DBObject* self, PyObject* args, PyObject* kwargs)
     else if (!err) {
         PyObject *pkeyObj;
         PyObject *dataObj;
-        dataObj = PyString_FromStringAndSize(data.data, data.size);
+        dataObj = Build_PyString(data.data, data.size);
 
         if (self->primaryDBType == DB_RECNO ||
             self->primaryDBType == DB_QUEUE)
-            pkeyObj = PyInt_FromLong(*(int *)pkey.data);
+            pkeyObj = NUMBER_FromLong(*(int *)pkey.data);
         else
-            pkeyObj = PyString_FromStringAndSize(pkey.data, pkey.size);
+            pkeyObj = Build_PyString(pkey.data, pkey.size);
 
         if (flags & DB_SET_RECNO) /* return key , pkey and data */
         {
             PyObject *keyObj;
             int type = _DB_get_type(self);
             if (type == DB_RECNO || type == DB_QUEUE)
-                keyObj = PyInt_FromLong(*(int *)key.data);
+                keyObj = NUMBER_FromLong(*(int *)key.data);
             else
-                keyObj = PyString_FromStringAndSize(key.data, key.size);
+                keyObj = Build_PyString(key.data, key.size);
 #if (PY_VERSION_HEX >= 0x02040000)
             retval = PyTuple_Pack(3, keyObj, pkeyObj, dataObj);
 #else
@@ -1648,7 +1874,7 @@ DB_pget(DBObject* self, PyObject* args, PyObject* kwargs)
         }
         Py_DECREF(dataObj);
         Py_DECREF(pkeyObj);
-	FREE_DBT(pkey);
+        FREE_DBT(pkey);
         FREE_DBT(data);
     }
     FREE_DBT(key);
@@ -1656,7 +1882,6 @@ DB_pget(DBObject* self, PyObject* args, PyObject* kwargs)
     RETURN_IF_ERR();
     return retval;
 }
-#endif
 
 
 /* Return size of entry */
@@ -1691,7 +1916,7 @@ DB_get_size(DBObject* self, PyObject* args, PyObject* kwargs)
     err = self->db->get(self->db, txn, &key, &data, flags);
     MYDB_END_ALLOW_THREADS;
     if (err == DB_BUFFER_SMALL) {
-        retval = PyInt_FromLong((long)data.size);
+        retval = NUMBER_FromLong((long)data.size);
         err = 0;
     }
 
@@ -1715,7 +1940,6 @@ DB_get_both(DBObject* self, PyObject* args, PyObject* kwargs)
     DB_TXN *txn = NULL;
     static char* kwnames[] = { "key", "data", "txn", "flags", NULL };
 
-
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "OO|Oi:get_both", kwnames,
                                      &keyobj, &dataobj, &txnobj, &flags))
         return NULL;
@@ -1734,7 +1958,7 @@ DB_get_both(DBObject* self, PyObject* args, PyObject* kwargs)
     orig_data = data.data;
 
     if (CHECK_DBFLAG(self, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
+        /* Tell Berkeley DB to malloc the return value (thread safe) */
         /* XXX(nnorwitz): At least 4.4.20 and 4.5.20 require this flag. */
         data.flags = DB_DBT_MALLOC;
     }
@@ -1744,14 +1968,14 @@ DB_get_both(DBObject* self, PyObject* args, PyObject* kwargs)
     MYDB_END_ALLOW_THREADS;
 
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->moduleFlags.getReturnsNone) {
+            && self->moduleFlags.getReturnsNone) {
         err = 0;
         Py_INCREF(Py_None);
         retval = Py_None;
     }
     else if (!err) {
         /* XXX(nnorwitz): can we do: retval = dataobj; Py_INCREF(retval); */
-        retval = PyString_FromStringAndSize((char*)data.data, data.size);
+        retval = Build_PyString(data.data, data.size);
 
         /* Even though the flags require DB_DBT_MALLOC, data is not always
            allocated.  4.4: allocated, 4.5: *not* allocated. :-( */
@@ -1766,44 +1990,32 @@ DB_get_both(DBObject* self, PyObject* args, PyObject* kwargs)
 
 
 static PyObject*
-DB_get_byteswapped(DBObject* self, PyObject* args)
+DB_get_byteswapped(DBObject* self)
 {
-#if (DBVER >= 33)
     int err = 0;
-#endif
     int retval = -1;
 
-    if (!PyArg_ParseTuple(args,":get_byteswapped"))
-        return NULL;
     CHECK_DB_NOT_CLOSED(self);
 
-#if (DBVER >= 33)
     MYDB_BEGIN_ALLOW_THREADS;
     err = self->db->get_byteswapped(self->db, &retval);
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
-#else
-    MYDB_BEGIN_ALLOW_THREADS;
-    retval = self->db->get_byteswapped(self->db);
-    MYDB_END_ALLOW_THREADS;
-#endif
-    return PyInt_FromLong(retval);
+    return NUMBER_FromLong(retval);
 }
 
 
 static PyObject*
-DB_get_type(DBObject* self, PyObject* args)
+DB_get_type(DBObject* self)
 {
     int type;
 
-    if (!PyArg_ParseTuple(args,":get_type"))
-        return NULL;
     CHECK_DB_NOT_CLOSED(self);
 
     type = _DB_get_type(self);
     if (type == -1)
         return NULL;
-    return PyInt_FromLong(type);
+    return NUMBER_FromLong(type);
 }
 
 
@@ -1830,8 +2042,8 @@ DB_join(DBObject* self, PyObject* args)
     length = PyObject_Length(cursorsObj);
     cursors = malloc((length+1) * sizeof(DBC*));
     if (!cursors) {
-	PyErr_NoMemory();
-	return NULL;
+        PyErr_NoMemory();
+        return NULL;
     }
 
     cursors[length] = NULL;
@@ -1862,7 +2074,7 @@ DB_join(DBObject* self, PyObject* args)
        but does not hold python references to them or prevent
        them from being closed prematurely.  This can cause
        python to crash when things are done in the wrong order. */
-    return (PyObject*) newDBCursorObject(dbc, self);
+    return (PyObject*) newDBCursorObject(dbc, NULL, self);
 }
 
 
@@ -1922,28 +2134,28 @@ DB_open(DBObject* self, PyObject* args, PyObject* kwargs)
 
 #if (DBVER >= 41)
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "z|ziiiO:open", kwnames,
-				     &filename, &dbname, &type, &flags, &mode,
+                                     &filename, &dbname, &type, &flags, &mode,
                                      &txnobj))
 #else
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "z|ziii:open", kwnames,
-				     &filename, &dbname, &type, &flags,
+                                     &filename, &dbname, &type, &flags,
                                      &mode))
 #endif
     {
-	PyErr_Clear();
-	type = DB_UNKNOWN; flags = 0; mode = 0660;
-	filename = NULL; dbname = NULL;
+        PyErr_Clear();
+        type = DB_UNKNOWN; flags = 0; mode = 0660;
+        filename = NULL; dbname = NULL;
 #if (DBVER >= 41)
-	if (!PyArg_ParseTupleAndKeywords(args, kwargs,"z|iiiO:open",
+        if (!PyArg_ParseTupleAndKeywords(args, kwargs,"z|iiiO:open",
                                          kwnames_basic,
-					 &filename, &type, &flags, &mode,
+                                         &filename, &type, &flags, &mode,
                                          &txnobj))
-	    return NULL;
+            return NULL;
 #else
-	if (!PyArg_ParseTupleAndKeywords(args, kwargs,"z|iii:open",
+        if (!PyArg_ParseTupleAndKeywords(args, kwargs,"z|iii:open",
                                          kwnames_basic,
-					 &filename, &type, &flags, &mode))
-	    return NULL;
+                                         &filename, &type, &flags, &mode))
+            return NULL;
 #endif
     }
 
@@ -1954,24 +2166,22 @@ DB_open(DBObject* self, PyObject* args, PyObject* kwargs)
     if (NULL == self->db) {
         PyObject *t = Py_BuildValue("(is)", 0,
                                 "Cannot call open() twice for DB object");
-        PyErr_SetObject(DBError, t);
-        Py_DECREF(t);
+        if (t) {
+            PyErr_SetObject(DBError, t);
+            Py_DECREF(t);
+        }
         return NULL;
     }
 
-#if 0 && (DBVER >= 41)
-    if ((!txn) && (txnobj != Py_None) && self->myenvobj
-        && (self->myenvobj->flags & DB_INIT_TXN))
-    {
-	/* If no 'txn' parameter was supplied (no DbTxn object and None was not
-	 * explicitly passed) but we are in a transaction ready environment:
-	 *   add DB_AUTO_COMMIT to allow for older pybsddb apps using transactions
-	 *   to work on BerkeleyDB 4.1 without needing to modify their
-	 *   DBEnv or DB open calls. 
-	 * TODO make this behaviour of the library configurable.
-	 */
-	flags |= DB_AUTO_COMMIT;
+#if (DBVER >= 41)
+    if (txn) {  /* Can't use 'txnobj' because could be 'txnobj==Py_None' */
+        INSERT_IN_DOUBLE_LINKED_LIST_TXN(((DBTxnObject *)txnobj)->children_dbs,self);
+        self->txn=(DBTxnObject *)txnobj;
+    } else {
+        self->txn=NULL;
     }
+#else
+    self->txn=NULL;
 #endif
 
     MYDB_BEGIN_ALLOW_THREADS;
@@ -1982,12 +2192,19 @@ DB_open(DBObject* self, PyObject* args, PyObject* kwargs)
 #endif
     MYDB_END_ALLOW_THREADS;
     if (makeDBError(err)) {
-        self->db->close(self->db, 0);
-        self->db = NULL;
+        PyObject *dummy;
+
+        dummy=DB_close_internal(self, 0, 0);
+        Py_XDECREF(dummy);
         return NULL;
     }
 
+#if (DBVER >= 42)
+    self->db->get_flags(self->db, &self->setflags);
+#endif
+
     self->flags = flags;
+
     RETURN_NONE();
 }
 
@@ -2026,7 +2243,7 @@ DB_put(DBObject* self, PyObject* args, PyObject* kwargs)
     }
 
     if (flags & DB_APPEND)
-        retval = PyInt_FromLong(*((db_recno_t*)key.data));
+        retval = NUMBER_FromLong(*((db_recno_t*)key.data));
     else {
         retval = Py_None;
         Py_INCREF(retval);
@@ -2050,7 +2267,12 @@ DB_remove(DBObject* self, PyObject* args, PyObject* kwargs)
         return NULL;
     CHECK_DB_NOT_CLOSED(self);
 
+    EXTRACT_FROM_DOUBLE_LINKED_LIST_MAYBE_NULL(self);
+
+    MYDB_BEGIN_ALLOW_THREADS;
     err = self->db->remove(self->db, filename, database, flags);
+    MYDB_END_ALLOW_THREADS;
+
     self->db = NULL;
     RETURN_IF_ERR();
     RETURN_NONE();
@@ -2080,6 +2302,25 @@ DB_rename(DBObject* self, PyObject* args)
 
 
 static PyObject*
+DB_get_private(DBObject* self)
+{
+    /* We can give out the private field even if db is closed */
+    Py_INCREF(self->private_obj);
+    return self->private_obj;
+}
+
+static PyObject*
+DB_set_private(DBObject* self, PyObject* private_obj)
+{
+    /* We can set the private field even if db is closed */
+    Py_DECREF(self->private_obj);
+    Py_INCREF(private_obj);
+    self->private_obj = private_obj;
+    RETURN_NONE();
+}
+
+
+static PyObject*
 DB_set_bt_minkey(DBObject* self, PyObject* args)
 {
     int err, minkey;
@@ -2095,32 +2336,31 @@ DB_set_bt_minkey(DBObject* self, PyObject* args)
     RETURN_NONE();
 }
 
-#if (DBVER >= 33)
-static int 
+static int
 _default_cmp(const DBT *leftKey,
-	     const DBT *rightKey)
+             const DBT *rightKey)
 {
   int res;
   int lsize = leftKey->size, rsize = rightKey->size;
 
-  res = memcmp(leftKey->data, rightKey->data, 
-	       lsize < rsize ? lsize : rsize);
-  
+  res = memcmp(leftKey->data, rightKey->data,
+               lsize < rsize ? lsize : rsize);
+
   if (res == 0) {
       if (lsize < rsize) {
-	  res = -1;
+          res = -1;
       }
       else if (lsize > rsize) {
-	  res = 1;
+          res = 1;
       }
   }
   return res;
 }
 
 static int
-_db_compareCallback(DB* db, 
-		    const DBT *leftKey,
-		    const DBT *rightKey)
+_db_compareCallback(DB* db,
+                    const DBT *leftKey,
+                    const DBT *rightKey)
 {
     int res = 0;
     PyObject *args;
@@ -2128,65 +2368,58 @@ _db_compareCallback(DB* db,
     DBObject *self = (DBObject *)db->app_private;
 
     if (self == NULL || self->btCompareCallback == NULL) {
-	MYDB_BEGIN_BLOCK_THREADS;
-	PyErr_SetString(PyExc_TypeError,
-			(self == 0
-			 ? "DB_bt_compare db is NULL."
-			 : "DB_bt_compare callback is NULL."));
-	/* we're in a callback within the DB code, we can't raise */
-	PyErr_Print();
-	res = _default_cmp(leftKey, rightKey);
-	MYDB_END_BLOCK_THREADS;
+        MYDB_BEGIN_BLOCK_THREADS;
+        PyErr_SetString(PyExc_TypeError,
+                        (self == 0
+                         ? "DB_bt_compare db is NULL."
+                         : "DB_bt_compare callback is NULL."));
+        /* we're in a callback within the DB code, we can't raise */
+        PyErr_Print();
+        res = _default_cmp(leftKey, rightKey);
+        MYDB_END_BLOCK_THREADS;
     } else {
-	MYDB_BEGIN_BLOCK_THREADS;
-
-	args = Py_BuildValue("s#s#", leftKey->data, leftKey->size,
-			     rightKey->data, rightKey->size);
-	if (args != NULL) {
-		/* XXX(twouters) I highly doubt this INCREF is correct */
-		Py_INCREF(self);
-		result = PyEval_CallObject(self->btCompareCallback, args);
-	}
-	if (args == NULL || result == NULL) {
-	    /* we're in a callback within the DB code, we can't raise */
-	    PyErr_Print();
-	    res = _default_cmp(leftKey, rightKey);
-	} else if (PyInt_Check(result)) {
-	    res = PyInt_AsLong(result);
-	} else {
-	    PyErr_SetString(PyExc_TypeError,
-			    "DB_bt_compare callback MUST return an int.");
-	    /* we're in a callback within the DB code, we can't raise */
-	    PyErr_Print();
-	    res = _default_cmp(leftKey, rightKey);
-	}
-    
-	Py_XDECREF(args);
-	Py_XDECREF(result);
-
-	MYDB_END_BLOCK_THREADS;
+        MYDB_BEGIN_BLOCK_THREADS;
+
+        args = BuildValue_SS(leftKey->data, leftKey->size, rightKey->data, rightKey->size);
+        if (args != NULL) {
+                result = PyEval_CallObject(self->btCompareCallback, args);
+        }
+        if (args == NULL || result == NULL) {
+            /* we're in a callback within the DB code, we can't raise */
+            PyErr_Print();
+            res = _default_cmp(leftKey, rightKey);
+        } else if (NUMBER_Check(result)) {
+            res = NUMBER_AsLong(result);
+        } else {
+            PyErr_SetString(PyExc_TypeError,
+                            "DB_bt_compare callback MUST return an int.");
+            /* we're in a callback within the DB code, we can't raise */
+            PyErr_Print();
+            res = _default_cmp(leftKey, rightKey);
+        }
+
+        Py_XDECREF(args);
+        Py_XDECREF(result);
+
+        MYDB_END_BLOCK_THREADS;
     }
     return res;
 }
 
 static PyObject*
-DB_set_bt_compare(DBObject* self, PyObject* args)
+DB_set_bt_compare(DBObject* self, PyObject* comparator)
 {
     int err;
-    PyObject *comparator;
     PyObject *tuple, *result;
 
-    if (!PyArg_ParseTuple(args, "O:set_bt_compare", &comparator))
-	return NULL;
-
     CHECK_DB_NOT_CLOSED(self);
 
     if (!PyCallable_Check(comparator)) {
-	makeTypeError("Callable", comparator);
-	return NULL;
+        makeTypeError("Callable", comparator);
+        return NULL;
     }
 
-    /* 
+    /*
      * Perform a test call of the comparator function with two empty
      * string objects here.  verify that it returns an int (0).
      * err if not.
@@ -2196,14 +2429,16 @@ DB_set_bt_compare(DBObject* self, PyObject* args)
     Py_DECREF(tuple);
     if (result == NULL)
         return NULL;
-    if (!PyInt_Check(result)) {
-	PyErr_SetString(PyExc_TypeError,
-		        "callback MUST return an int");
-	return NULL;
-    } else if (PyInt_AsLong(result) != 0) {
-	PyErr_SetString(PyExc_TypeError,
-		        "callback failed to return 0 on two empty strings");
-	return NULL;
+    if (!NUMBER_Check(result)) {
+        Py_DECREF(result);
+        PyErr_SetString(PyExc_TypeError,
+                        "callback MUST return an int");
+        return NULL;
+    } else if (NUMBER_AsLong(result) != 0) {
+        Py_DECREF(result);
+        PyErr_SetString(PyExc_TypeError,
+                        "callback failed to return 0 on two empty strings");
+        return NULL;
     }
     Py_DECREF(result);
 
@@ -2211,8 +2446,8 @@ DB_set_bt_compare(DBObject* self, PyObject* args)
      * simplify the code. This would have no real use, as one cannot
      * change the function once the db is opened anyway */
     if (self->btCompareCallback != NULL) {
-	PyErr_SetString(PyExc_RuntimeError, "set_bt_compare() cannot be called more than once");
-	return NULL;
+        PyErr_SetString(PyExc_RuntimeError, "set_bt_compare() cannot be called more than once");
+        return NULL;
     }
 
     Py_INCREF(comparator);
@@ -2227,15 +2462,14 @@ DB_set_bt_compare(DBObject* self, PyObject* args)
     err = self->db->set_bt_compare(self->db, _db_compareCallback);
 
     if (err) {
-	/* restore the old state in case of error */
-	Py_DECREF(comparator);
-	self->btCompareCallback = NULL;
+        /* restore the old state in case of error */
+        Py_DECREF(comparator);
+        self->btCompareCallback = NULL;
     }
 
     RETURN_IF_ERR();
     RETURN_NONE();
 }
-#endif /* DBVER >= 33 */
 
 
 static PyObject*
@@ -2421,7 +2655,6 @@ DB_set_re_source(DBObject* self, PyObject* args)
 }
 
 
-#if (DBVER >= 32)
 static PyObject*
 DB_set_q_extentsize(DBObject* self, PyObject* args)
 {
@@ -2438,7 +2671,6 @@ DB_set_q_extentsize(DBObject* self, PyObject* args)
     RETURN_IF_ERR();
     RETURN_NONE();
 }
-#endif
 
 static PyObject*
 DB_stat(DBObject* self, PyObject* args, PyObject* kwargs)
@@ -2469,10 +2701,8 @@ DB_stat(DBObject* self, PyObject* args, PyObject* kwargs)
     MYDB_BEGIN_ALLOW_THREADS;
 #if (DBVER >= 43)
     err = self->db->stat(self->db, txn, &sp, flags);
-#elif (DBVER >= 33)
-    err = self->db->stat(self->db, &sp, flags);
 #else
-    err = self->db->stat(self->db, &sp, NULL, flags);
+    err = self->db->stat(self->db, &sp, flags);
 #endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
@@ -2496,6 +2726,9 @@ DB_stat(DBObject* self, PyObject* args, PyObject* kwargs)
         MAKE_HASH_ENTRY(version);
         MAKE_HASH_ENTRY(nkeys);
         MAKE_HASH_ENTRY(ndata);
+#if (DBVER >= 46)
+        MAKE_HASH_ENTRY(pagecnt);
+#endif
         MAKE_HASH_ENTRY(pagesize);
 #if (DBVER < 41)
         MAKE_HASH_ENTRY(nelem);
@@ -2518,6 +2751,9 @@ DB_stat(DBObject* self, PyObject* args, PyObject* kwargs)
         MAKE_BT_ENTRY(version);
         MAKE_BT_ENTRY(nkeys);
         MAKE_BT_ENTRY(ndata);
+#if (DBVER >= 46)
+        MAKE_BT_ENTRY(pagecnt);
+#endif
         MAKE_BT_ENTRY(pagesize);
         MAKE_BT_ENTRY(minkey);
         MAKE_BT_ENTRY(re_len);
@@ -2527,6 +2763,9 @@ DB_stat(DBObject* self, PyObject* args, PyObject* kwargs)
         MAKE_BT_ENTRY(leaf_pg);
         MAKE_BT_ENTRY(dup_pg);
         MAKE_BT_ENTRY(over_pg);
+#if (DBVER >= 43)
+        MAKE_BT_ENTRY(empty_pg);
+#endif
         MAKE_BT_ENTRY(free);
         MAKE_BT_ENTRY(int_pgfree);
         MAKE_BT_ENTRY(leaf_pgfree);
@@ -2540,6 +2779,9 @@ DB_stat(DBObject* self, PyObject* args, PyObject* kwargs)
         MAKE_QUEUE_ENTRY(nkeys);
         MAKE_QUEUE_ENTRY(ndata);
         MAKE_QUEUE_ENTRY(pagesize);
+#if (DBVER >= 41)
+        MAKE_QUEUE_ENTRY(extentsize);
+#endif
         MAKE_QUEUE_ENTRY(pages);
         MAKE_QUEUE_ENTRY(re_len);
         MAKE_QUEUE_ENTRY(re_pad);
@@ -2583,7 +2825,6 @@ DB_sync(DBObject* self, PyObject* args)
 }
 
 
-#if (DBVER >= 33)
 static PyObject*
 DB_truncate(DBObject* self, PyObject* args, PyObject* kwargs)
 {
@@ -2604,9 +2845,8 @@ DB_truncate(DBObject* self, PyObject* args, PyObject* kwargs)
     err = self->db->truncate(self->db, txn, &count, flags);
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
-    return PyInt_FromLong(count);
+    return NUMBER_FromLong(count);
 }
-#endif
 
 
 static PyObject*
@@ -2645,25 +2885,27 @@ DB_verify(DBObject* self, PyObject* args, PyObject* kwargs)
     CHECK_DB_NOT_CLOSED(self);
     if (outFileName)
         outFile = fopen(outFileName, "w");
-	/* XXX(nnorwitz): it should probably be an exception if outFile
-	   can't be opened. */
+        /* XXX(nnorwitz): it should probably be an exception if outFile
+           can't be opened. */
+
+    {  /* DB.verify acts as a DB handle destructor (like close) */
+        PyObject *error;
+
+        error=DB_close_internal(self, 0, 1);
+        if (error ) {
+          return error;
+        }
+     }
 
     MYDB_BEGIN_ALLOW_THREADS;
     err = self->db->verify(self->db, fileName, dbName, outFile, flags);
     MYDB_END_ALLOW_THREADS;
+
+    self->db = NULL;  /* Implicit close; related objects already released */
+
     if (outFile)
         fclose(outFile);
 
-    /* DB.verify acts as a DB handle destructor (like close); this was
-     * documented in BerkeleyDB 4.2 but had the undocumented effect
-     * of not being safe in prior versions while still requiring an explicit
-     * DB.close call afterwards.  Lets call close for the user to emulate
-     * the safe 4.2 behaviour. */
-#if (DBVER <= 41)
-    self->db->close(self->db, 0);
-#endif
-    self->db = NULL;
-
     RETURN_IF_ERR();
     RETURN_NONE();
 }
@@ -2685,7 +2927,7 @@ DB_set_get_returns_none(DBObject* self, PyObject* args)
         ++oldValue;
     self->moduleFlags.getReturnsNone = (flags >= 1);
     self->moduleFlags.cursorSetReturnsNone = (flags >= 2);
-    return PyInt_FromLong(oldValue);
+    return NUMBER_FromLong(oldValue);
 }
 
 #if (DBVER >= 41)
@@ -2698,8 +2940,8 @@ DB_set_encrypt(DBObject* self, PyObject* args, PyObject* kwargs)
     static char* kwnames[] = { "passwd", "flags", NULL };
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "s|i:set_encrypt", kwnames,
-		&passwd, &flags)) {
-	return NULL;
+                &passwd, &flags)) {
+        return NULL;
     }
 
     MYDB_BEGIN_ALLOW_THREADS;
@@ -2725,8 +2967,10 @@ Py_ssize_t DB_length(PyObject* _self)
 
     if (self->db == NULL) {
         PyObject *t = Py_BuildValue("(is)", 0, "DB object has been closed");
-        PyErr_SetObject(DBError, t);
-        Py_DECREF(t);
+        if (t) {
+            PyErr_SetObject(DBError, t);
+            Py_DECREF(t);
+        }
         return -1;
     }
 
@@ -2739,17 +2983,15 @@ Py_ssize_t DB_length(PyObject* _self)
 redo_stat_for_length:
 #if (DBVER >= 43)
     err = self->db->stat(self->db, /*txnid*/ NULL, &sp, flags);
-#elif (DBVER >= 33)
-    err = self->db->stat(self->db, &sp, flags);
 #else
-    err = self->db->stat(self->db, &sp, NULL, flags);
+    err = self->db->stat(self->db, &sp, flags);
 #endif
 
     /* All the stat structures have matching fields upto the ndata field,
        so we can use any of them for the type cast */
     size = ((DB_BTREE_STAT*)sp)->bt_ndata;
 
-    /* A size of 0 could mean that BerkeleyDB no longer had the stat values cached.
+    /* A size of 0 could mean that Berkeley DB no longer had the stat values cached.
      * redo a full stat to make sure.
      *   Fixes SF python bug 1493322, pybsddb bug 1184012
      */
@@ -2785,7 +3027,7 @@ PyObject* DB_subscript(DBObject* self, PyObject* keyobj)
 
     CLEAR_DBT(data);
     if (CHECK_DBFLAG(self, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
+        /* Tell Berkeley DB to malloc the return value (thread safe) */
         data.flags = DB_DBT_MALLOC;
     }
     MYDB_BEGIN_ALLOW_THREADS;
@@ -2799,7 +3041,7 @@ PyObject* DB_subscript(DBObject* self, PyObject* keyobj)
         retval = NULL;
     }
     else {
-        retval = PyString_FromStringAndSize((char*)data.data, data.size);
+        retval = Build_PyString(data.data, data.size);
         FREE_DBT(data);
     }
 
@@ -2817,8 +3059,10 @@ DB_ass_sub(DBObject* self, PyObject* keyobj, PyObject* dataobj)
 
     if (self->db == NULL) {
         PyObject *t = Py_BuildValue("(is)", 0, "DB object has been closed");
-        PyErr_SetObject(DBError, t);
-        Py_DECREF(t);
+        if (t) {
+            PyErr_SetObject(DBError, t);
+            Py_DECREF(t);
+        }
         return -1;
     }
 
@@ -2853,16 +3097,19 @@ DB_ass_sub(DBObject* self, PyObject* keyobj, PyObject* dataobj)
 
 
 static PyObject*
-DB_has_key(DBObject* self, PyObject* args)
+DB_has_key(DBObject* self, PyObject* args, PyObject* kwargs)
 {
     int err;
     PyObject* keyobj;
     DBT key, data;
     PyObject* txnobj = NULL;
     DB_TXN *txn = NULL;
+    static char* kwnames[] = {"key","txn", NULL};
 
-    if (!PyArg_ParseTuple(args,"O|O:has_key", &keyobj, &txnobj))
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs, "O|O:has_key", kwnames,
+                &keyobj, &txnobj))
         return NULL;
+
     CHECK_DB_NOT_CLOSED(self);
     if (!make_key_dbt(self, keyobj, &key, NULL))
         return NULL;
@@ -2884,9 +3131,9 @@ DB_has_key(DBObject* self, PyObject* args)
     FREE_DBT(key);
 
     if (err == DB_BUFFER_SMALL || err == 0) {
-        return PyInt_FromLong(1);
+        return NUMBER_FromLong(1);
     } else if (err == DB_NOTFOUND || err == DB_KEYEMPTY) {
-        return PyInt_FromLong(0);
+        return NUMBER_FromLong(0);
     }
 
     makeDBError(err);
@@ -2929,14 +3176,9 @@ _DB_make_list(DBObject* self, DB_TXN* txn, int type)
         return NULL;
     }
 
-    if (CHECK_DBFLAG(self, DB_THREAD)) {
-        key.flags = DB_DBT_REALLOC;
-        data.flags = DB_DBT_REALLOC;
-    }
-
     while (1) { /* use the cursor to traverse the DB, collecting items */
         MYDB_BEGIN_ALLOW_THREADS;
-        err = cursor->c_get(cursor, &key, &data, DB_NEXT);
+        err = _DBC_get(cursor, &key, &data, DB_NEXT);
         MYDB_END_ALLOW_THREADS;
 
         if (err) {
@@ -2950,17 +3192,17 @@ _DB_make_list(DBObject* self, DB_TXN* txn, int type)
             case DB_BTREE:
             case DB_HASH:
             default:
-                item = PyString_FromStringAndSize((char*)key.data, key.size);
+                item = Build_PyString(key.data, key.size);
                 break;
             case DB_RECNO:
             case DB_QUEUE:
-                item = PyInt_FromLong(*((db_recno_t*)key.data));
+                item = NUMBER_FromLong(*((db_recno_t*)key.data));
                 break;
             }
             break;
 
         case _VALUES_LIST:
-            item = PyString_FromStringAndSize((char*)data.data, data.size);
+            item = Build_PyString(data.data, data.size);
             break;
 
         case _ITEMS_LIST:
@@ -2968,13 +3210,11 @@ _DB_make_list(DBObject* self, DB_TXN* txn, int type)
             case DB_BTREE:
             case DB_HASH:
             default:
-                item = Py_BuildValue("s#s#", key.data, key.size, data.data,
-                                     data.size);
+                item = BuildValue_SS(key.data, key.size, data.data, data.size);
                 break;
             case DB_RECNO:
             case DB_QUEUE:
-                item = Py_BuildValue("is#", *((db_recno_t*)key.data),
-                                     data.data, data.size);
+                item = BuildValue_IS(*((db_recno_t*)key.data), data.data, data.size);
                 break;
             }
             break;
@@ -2988,7 +3228,12 @@ _DB_make_list(DBObject* self, DB_TXN* txn, int type)
             list = NULL;
             goto done;
         }
-        PyList_Append(list, item);
+        if (PyList_Append(list, item)) {
+            Py_DECREF(list);
+            Py_DECREF(item);
+            list = NULL;
+            goto done;
+        }
         Py_DECREF(item);
     }
 
@@ -2999,10 +3244,8 @@ _DB_make_list(DBObject* self, DB_TXN* txn, int type)
     }
 
  done:
-    FREE_DBT(key);
-    FREE_DBT(data);
     MYDB_BEGIN_ALLOW_THREADS;
-    cursor->c_close(cursor);
+    _DBC_close(cursor);
     MYDB_END_ALLOW_THREADS;
     return list;
 }
@@ -3054,23 +3297,32 @@ DB_values(DBObject* self, PyObject* args)
 
 
 static PyObject*
-DBC_close(DBCursorObject* self, PyObject* args)
+DBC_close_internal(DBCursorObject* self)
 {
     int err = 0;
 
-    if (!PyArg_ParseTuple(args, ":close"))
-        return NULL;
-
     if (self->dbc != NULL) {
+        EXTRACT_FROM_DOUBLE_LINKED_LIST(self);
+        if (self->txn) {
+            EXTRACT_FROM_DOUBLE_LINKED_LIST_TXN(self);
+            self->txn=NULL;
+        }
+
         MYDB_BEGIN_ALLOW_THREADS;
-        err = self->dbc->c_close(self->dbc);
-        self->dbc = NULL;
+        err = _DBC_close(self->dbc);
         MYDB_END_ALLOW_THREADS;
+        self->dbc = NULL;
     }
     RETURN_IF_ERR();
     RETURN_NONE();
 }
 
+static PyObject*
+DBC_close(DBCursorObject* self)
+{
+    return DBC_close_internal(self);
+}
+
 
 static PyObject*
 DBC_count(DBCursorObject* self, PyObject* args)
@@ -3085,11 +3337,11 @@ DBC_count(DBCursorObject* self, PyObject* args)
     CHECK_CURSOR_NOT_CLOSED(self);
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_count(self->dbc, &count, flags);
+    err = _DBC_count(self->dbc, &count, flags);
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
 
-    return PyInt_FromLong(count);
+    return NUMBER_FromLong(count);
 }
 
 
@@ -3111,7 +3363,7 @@ DBC_delete(DBCursorObject* self, PyObject* args)
     CHECK_CURSOR_NOT_CLOSED(self);
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_del(self->dbc, flags);
+    err = _DBC_del(self->dbc, flags);
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
 
@@ -3132,11 +3384,11 @@ DBC_dup(DBCursorObject* self, PyObject* args)
     CHECK_CURSOR_NOT_CLOSED(self);
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_dup(self->dbc, &dbc, flags);
+    err = _DBC_dup(self->dbc, &dbc, flags);
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
 
-    return (PyObject*) newDBCursorObject(dbc, self->mydb);
+    return (PyObject*) newDBCursorObject(dbc, self->txn, self->mydb);
 }
 
 static PyObject*
@@ -3162,12 +3414,12 @@ DBC_get(DBCursorObject* self, PyObject* args, PyObject *kwargs)
     CLEAR_DBT(key);
     CLEAR_DBT(data);
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "i|ii:get", &kwnames[2],
-				     &flags, &dlen, &doff))
+                                     &flags, &dlen, &doff))
     {
         PyErr_Clear();
         if (!PyArg_ParseTupleAndKeywords(args, kwargs, "Oi|ii:get",
-                                         &kwnames[1], 
-					 &keyobj, &flags, &dlen, &doff))
+                                         &kwnames[1],
+                                         &keyobj, &flags, &dlen, &doff))
         {
             PyErr_Clear();
             if (!PyArg_ParseTupleAndKeywords(args, kwargs, "OOi|ii:get",
@@ -3175,8 +3427,8 @@ DBC_get(DBCursorObject* self, PyObject* args, PyObject *kwargs)
                                              &flags, &dlen, &doff))
             {
                 return NULL;
-	    }
-	}
+            }
+        }
     }
 
     CHECK_CURSOR_NOT_CLOSED(self);
@@ -3186,23 +3438,16 @@ DBC_get(DBCursorObject* self, PyObject* args, PyObject *kwargs)
     if ( (dataobj && !make_dbt(dataobj, &data)) ||
          (!add_partial_dbt(&data, dlen, doff)) )
     {
-        FREE_DBT(key);
+        FREE_DBT(key); /* 'make_key_dbt' could do a 'malloc' */
         return NULL;
     }
 
-    if (CHECK_DBFLAG(self->mydb, DB_THREAD)) {
-        data.flags = DB_DBT_MALLOC;
-        if (!(key.flags & DB_DBT_REALLOC)) {
-            key.flags |= DB_DBT_MALLOC;
-        }
-    }
-
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, flags);
+    err = _DBC_get(self->dbc, &key, &data, flags);
     MYDB_END_ALLOW_THREADS;
 
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->mydb->moduleFlags.getReturnsNone) {
+            && self->mydb->moduleFlags.getReturnsNone) {
         Py_INCREF(Py_None);
         retval = Py_None;
     }
@@ -3217,22 +3462,18 @@ DBC_get(DBCursorObject* self, PyObject* args, PyObject *kwargs)
         case DB_BTREE:
         case DB_HASH:
         default:
-            retval = Py_BuildValue("s#s#", key.data, key.size,
-                                   data.data, data.size);
+            retval = BuildValue_SS(key.data, key.size, data.data, data.size);
             break;
         case DB_RECNO:
         case DB_QUEUE:
-            retval = Py_BuildValue("is#", *((db_recno_t*)key.data),
-                                   data.data, data.size);
+            retval = BuildValue_IS(*((db_recno_t*)key.data), data.data, data.size);
             break;
         }
-        FREE_DBT(data);
     }
-    FREE_DBT(key);
+    FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
     return retval;
 }
 
-#if (DBVER >= 33)
 static PyObject*
 DBC_pget(DBCursorObject* self, PyObject* args, PyObject *kwargs)
 {
@@ -3249,12 +3490,12 @@ DBC_pget(DBCursorObject* self, PyObject* args, PyObject *kwargs)
     CLEAR_DBT(key);
     CLEAR_DBT(data);
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "i|ii:pget", &kwnames[2],
-				     &flags, &dlen, &doff))
+                                     &flags, &dlen, &doff))
     {
         PyErr_Clear();
         if (!PyArg_ParseTupleAndKeywords(args, kwargs, "Oi|ii:pget",
-                                         kwnames_keyOnly, 
-					 &keyobj, &flags, &dlen, &doff))
+                                         kwnames_keyOnly,
+                                         &keyobj, &flags, &dlen, &doff))
         {
             PyErr_Clear();
             if (!PyArg_ParseTupleAndKeywords(args, kwargs, "OOi|ii:pget",
@@ -3262,8 +3503,8 @@ DBC_pget(DBCursorObject* self, PyObject* args, PyObject *kwargs)
                                              &flags, &dlen, &doff))
             {
                 return NULL;
-	    }
-	}
+            }
+        }
     }
 
     CHECK_CURSOR_NOT_CLOSED(self);
@@ -3272,26 +3513,19 @@ DBC_pget(DBCursorObject* self, PyObject* args, PyObject *kwargs)
         return NULL;
     if ( (dataobj && !make_dbt(dataobj, &data)) ||
          (!add_partial_dbt(&data, dlen, doff)) ) {
-        FREE_DBT(key);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
         return NULL;
     }
 
-    if (CHECK_DBFLAG(self->mydb, DB_THREAD)) {
-        data.flags = DB_DBT_MALLOC;
-        if (!(key.flags & DB_DBT_REALLOC)) {
-            key.flags |= DB_DBT_MALLOC;
-        }
-    }
-
     CLEAR_DBT(pkey);
     pkey.flags = DB_DBT_MALLOC;
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_pget(self->dbc, &key, &pkey, &data, flags);
+    err = _DBC_pget(self->dbc, &key, &pkey, &data, flags);
     MYDB_END_ALLOW_THREADS;
 
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->mydb->moduleFlags.getReturnsNone) {
+            && self->mydb->moduleFlags.getReturnsNone) {
         Py_INCREF(Py_None);
         retval = Py_None;
     }
@@ -3301,29 +3535,29 @@ DBC_pget(DBCursorObject* self, PyObject* args, PyObject *kwargs)
     else {
         PyObject *pkeyObj;
         PyObject *dataObj;
-        dataObj = PyString_FromStringAndSize(data.data, data.size);
+        dataObj = Build_PyString(data.data, data.size);
 
         if (self->mydb->primaryDBType == DB_RECNO ||
             self->mydb->primaryDBType == DB_QUEUE)
-            pkeyObj = PyInt_FromLong(*(int *)pkey.data);
+            pkeyObj = NUMBER_FromLong(*(int *)pkey.data);
         else
-            pkeyObj = PyString_FromStringAndSize(pkey.data, pkey.size);
+            pkeyObj = Build_PyString(pkey.data, pkey.size);
 
         if (key.data && key.size) /* return key, pkey and data */
         {
             PyObject *keyObj;
             int type = _DB_get_type(self->mydb);
             if (type == DB_RECNO || type == DB_QUEUE)
-                keyObj = PyInt_FromLong(*(int *)key.data);
+                keyObj = NUMBER_FromLong(*(int *)key.data);
             else
-                keyObj = PyString_FromStringAndSize(key.data, key.size);
+                keyObj = Build_PyString(key.data, key.size);
 #if (PY_VERSION_HEX >= 0x02040000)
             retval = PyTuple_Pack(3, keyObj, pkeyObj, dataObj);
 #else
             retval = Py_BuildValue("OOO", keyObj, pkeyObj, dataObj);
 #endif
             Py_DECREF(keyObj);
-            FREE_DBT(key);
+            FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
         }
         else /* return just the pkey and data */
         {
@@ -3336,48 +3570,36 @@ DBC_pget(DBCursorObject* self, PyObject* args, PyObject *kwargs)
         Py_DECREF(dataObj);
         Py_DECREF(pkeyObj);
         FREE_DBT(pkey);
-        FREE_DBT(data);
     }
     /* the only time REALLOC should be set is if we used an integer
      * key that make_key_dbt malloc'd for us.  always free these. */
-    if (key.flags & DB_DBT_REALLOC) {
+    if (key.flags & DB_DBT_REALLOC) {  /* 'make_key_dbt' could do a 'malloc' */
         FREE_DBT(key);
     }
     return retval;
 }
-#endif
 
 
 static PyObject*
-DBC_get_recno(DBCursorObject* self, PyObject* args)
+DBC_get_recno(DBCursorObject* self)
 {
     int err;
     db_recno_t recno;
     DBT key;
     DBT data;
 
-    if (!PyArg_ParseTuple(args, ":get_recno"))
-        return NULL;
-
     CHECK_CURSOR_NOT_CLOSED(self);
 
     CLEAR_DBT(key);
     CLEAR_DBT(data);
-    if (CHECK_DBFLAG(self->mydb, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
-        data.flags = DB_DBT_MALLOC;
-        key.flags = DB_DBT_MALLOC;
-    }
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, DB_GET_RECNO);
+    err = _DBC_get(self->dbc, &key, &data, DB_GET_RECNO);
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
 
     recno = *((db_recno_t*)data.data);
-    FREE_DBT(key);
-    FREE_DBT(data);
-    return PyInt_FromLong(recno);
+    return NUMBER_FromLong(recno);
 }
 
 
@@ -3414,7 +3636,7 @@ DBC_put(DBCursorObject* self, PyObject* args, PyObject* kwargs)
     int doff = -1;
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "OO|iii:put", kwnames,
-				     &keyobj, &dataobj, &flags, &dlen, &doff))
+                                     &keyobj, &dataobj, &flags, &dlen, &doff))
         return NULL;
 
     CHECK_CURSOR_NOT_CLOSED(self);
@@ -3424,14 +3646,14 @@ DBC_put(DBCursorObject* self, PyObject* args, PyObject* kwargs)
     if (!make_dbt(dataobj, &data) ||
         !add_partial_dbt(&data, dlen, doff) )
     {
-        FREE_DBT(key);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
         return NULL;
     }
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_put(self->dbc, &key, &data, flags);
+    err = _DBC_put(self->dbc, &key, &data, flags);
     MYDB_END_ALLOW_THREADS;
-    FREE_DBT(key);
+    FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
     RETURN_IF_ERR();
     self->mydb->haveStat = 0;
     RETURN_NONE();
@@ -3449,7 +3671,7 @@ DBC_set(DBCursorObject* self, PyObject* args, PyObject *kwargs)
     int doff = -1;
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "O|iii:set", kwnames,
-				     &keyobj, &flags, &dlen, &doff))
+                                     &keyobj, &flags, &dlen, &doff))
         return NULL;
 
     CHECK_CURSOR_NOT_CLOSED(self);
@@ -3458,20 +3680,16 @@ DBC_set(DBCursorObject* self, PyObject* args, PyObject *kwargs)
         return NULL;
 
     CLEAR_DBT(data);
-    if (CHECK_DBFLAG(self->mydb, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
-        data.flags = DB_DBT_MALLOC;
-    }
     if (!add_partial_dbt(&data, dlen, doff)) {
-        FREE_DBT(key);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
         return NULL;
     }
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, flags|DB_SET);
+    err = _DBC_get(self->dbc, &key, &data, flags|DB_SET);
     MYDB_END_ALLOW_THREADS;
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->mydb->moduleFlags.cursorSetReturnsNone) {
+            && self->mydb->moduleFlags.cursorSetReturnsNone) {
         Py_INCREF(Py_None);
         retval = Py_None;
     }
@@ -3486,22 +3704,19 @@ DBC_set(DBCursorObject* self, PyObject* args, PyObject *kwargs)
         case DB_BTREE:
         case DB_HASH:
         default:
-            retval = Py_BuildValue("s#s#", key.data, key.size,
-                                   data.data, data.size);
+            retval = BuildValue_SS(key.data, key.size, data.data, data.size);
             break;
         case DB_RECNO:
         case DB_QUEUE:
-            retval = Py_BuildValue("is#", *((db_recno_t*)key.data),
-                                   data.data, data.size);
+            retval = BuildValue_IS(*((db_recno_t*)key.data), data.data, data.size);
             break;
         }
-        FREE_DBT(data);
-        FREE_DBT(key);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
     }
     /* the only time REALLOC should be set is if we used an integer
      * key that make_key_dbt malloc'd for us.  always free these. */
     if (key.flags & DB_DBT_REALLOC) {
-        FREE_DBT(key);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
     }
 
     return retval;
@@ -3519,7 +3734,7 @@ DBC_set_range(DBCursorObject* self, PyObject* args, PyObject* kwargs)
     int doff = -1;
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "O|iii:set_range", kwnames,
-				     &keyobj, &flags, &dlen, &doff))
+                                     &keyobj, &flags, &dlen, &doff))
         return NULL;
 
     CHECK_CURSOR_NOT_CLOSED(self);
@@ -3529,22 +3744,14 @@ DBC_set_range(DBCursorObject* self, PyObject* args, PyObject* kwargs)
 
     CLEAR_DBT(data);
     if (!add_partial_dbt(&data, dlen, doff)) {
-        FREE_DBT(key);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
         return NULL;
     }
-    if (CHECK_DBFLAG(self->mydb, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
-        data.flags |= DB_DBT_MALLOC;
-        /* only BTREE databases will return anything in the key */
-        if (!(key.flags & DB_DBT_REALLOC) && _DB_get_type(self->mydb) == DB_BTREE) {
-            key.flags |= DB_DBT_MALLOC;
-        }
-    }
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, flags|DB_SET_RANGE);
+    err = _DBC_get(self->dbc, &key, &data, flags|DB_SET_RANGE);
     MYDB_END_ALLOW_THREADS;
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->mydb->moduleFlags.cursorSetReturnsNone) {
+            && self->mydb->moduleFlags.cursorSetReturnsNone) {
         Py_INCREF(Py_None);
         retval = Py_None;
     }
@@ -3559,22 +3766,19 @@ DBC_set_range(DBCursorObject* self, PyObject* args, PyObject* kwargs)
         case DB_BTREE:
         case DB_HASH:
         default:
-            retval = Py_BuildValue("s#s#", key.data, key.size,
-                                   data.data, data.size);
+            retval = BuildValue_SS(key.data, key.size, data.data, data.size);
             break;
         case DB_RECNO:
         case DB_QUEUE:
-            retval = Py_BuildValue("is#", *((db_recno_t*)key.data),
-                                   data.data, data.size);
+            retval = BuildValue_IS(*((db_recno_t*)key.data), data.data, data.size);
             break;
         }
-        FREE_DBT(key);
-        FREE_DBT(data);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
     }
     /* the only time REALLOC should be set is if we used an integer
      * key that make_key_dbt malloc'd for us.  always free these. */
     if (key.flags & DB_DBT_REALLOC) {
-        FREE_DBT(key);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
     }
 
     return retval;
@@ -3592,12 +3796,12 @@ _DBC_get_set_both(DBCursorObject* self, PyObject* keyobj, PyObject* dataobj,
     if (!make_key_dbt(self->mydb, keyobj, &key, NULL))
         return NULL;
     if (!make_dbt(dataobj, &data)) {
-        FREE_DBT(key);
+        FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
         return NULL;
     }
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, flags|DB_GET_BOTH);
+    err = _DBC_get(self->dbc, &key, &data, flags|DB_GET_BOTH);
     MYDB_END_ALLOW_THREADS;
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY) && returnsNone) {
         Py_INCREF(Py_None);
@@ -3614,18 +3818,16 @@ _DBC_get_set_both(DBCursorObject* self, PyObject* keyobj, PyObject* dataobj,
         case DB_BTREE:
         case DB_HASH:
         default:
-            retval = Py_BuildValue("s#s#", key.data, key.size,
-                                   data.data, data.size);
+            retval = BuildValue_SS(key.data, key.size, data.data, data.size);
             break;
         case DB_RECNO:
         case DB_QUEUE:
-            retval = Py_BuildValue("is#", *((db_recno_t*)key.data),
-                                   data.data, data.size);
+            retval = BuildValue_IS(*((db_recno_t*)key.data), data.data, data.size);
             break;
         }
     }
 
-    FREE_DBT(key);
+    FREE_DBT(key);  /* 'make_key_dbt' could do a 'malloc' */
     return retval;
 }
 
@@ -3647,14 +3849,12 @@ DBC_get_both(DBCursorObject* self, PyObject* args)
 
 /* Return size of entry */
 static PyObject*
-DBC_get_current_size(DBCursorObject* self, PyObject* args)
+DBC_get_current_size(DBCursorObject* self)
 {
     int err, flags=DB_CURRENT;
     PyObject* retval = NULL;
     DBT key, data;
 
-    if (!PyArg_ParseTuple(args, ":get_current_size"))
-        return NULL;
     CHECK_CURSOR_NOT_CLOSED(self);
     CLEAR_DBT(key);
     CLEAR_DBT(data);
@@ -3664,16 +3864,14 @@ DBC_get_current_size(DBCursorObject* self, PyObject* args)
     data.flags = DB_DBT_USERMEM;
     data.ulen = 0;
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, flags);
+    err = _DBC_get(self->dbc, &key, &data, flags);
     MYDB_END_ALLOW_THREADS;
     if (err == DB_BUFFER_SMALL || !err) {
         /* DB_BUFFER_SMALL means positive size, !err means zero length value */
-        retval = PyInt_FromLong((long)data.size);
+        retval = NUMBER_FromLong((long)data.size);
         err = 0;
     }
 
-    FREE_DBT(key);
-    FREE_DBT(data);
     RETURN_IF_ERR();
     return retval;
 }
@@ -3707,7 +3905,7 @@ DBC_set_recno(DBCursorObject* self, PyObject* args, PyObject *kwargs)
     static char* kwnames[] = { "recno","flags", "dlen", "doff", NULL };
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "i|iii:set_recno", kwnames,
-				     &irecno, &flags, &dlen, &doff))
+                                     &irecno, &flags, &dlen, &doff))
       return NULL;
 
     CHECK_CURSOR_NOT_CLOSED(self);
@@ -3727,20 +3925,16 @@ DBC_set_recno(DBCursorObject* self, PyObject* args, PyObject *kwargs)
     key.flags = DB_DBT_REALLOC;
 
     CLEAR_DBT(data);
-    if (CHECK_DBFLAG(self->mydb, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
-        data.flags = DB_DBT_MALLOC;
-    }
     if (!add_partial_dbt(&data, dlen, doff)) {
         FREE_DBT(key);
         return NULL;
     }
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, flags|DB_SET_RECNO);
+    err = _DBC_get(self->dbc, &key, &data, flags|DB_SET_RECNO);
     MYDB_END_ALLOW_THREADS;
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->mydb->moduleFlags.cursorSetReturnsNone) {
+            && self->mydb->moduleFlags.cursorSetReturnsNone) {
         Py_INCREF(Py_None);
         retval = Py_None;
     }
@@ -3748,9 +3942,7 @@ DBC_set_recno(DBCursorObject* self, PyObject* args, PyObject *kwargs)
         retval = NULL;
     }
     else {  /* Can only be used for BTrees, so no need to return int key */
-        retval = Py_BuildValue("s#s#", key.data, key.size,
-                               data.data, data.size);
-        FREE_DBT(data);
+        retval = BuildValue_SS(key.data, key.size, data.data, data.size);
     }
     FREE_DBT(key);
 
@@ -3800,16 +3992,12 @@ DBC_join_item(DBCursorObject* self, PyObject* args)
 
     CLEAR_DBT(key);
     CLEAR_DBT(data);
-    if (CHECK_DBFLAG(self->mydb, DB_THREAD)) {
-        /* Tell BerkeleyDB to malloc the return value (thread safe) */
-        key.flags = DB_DBT_MALLOC;
-    }
 
     MYDB_BEGIN_ALLOW_THREADS;
-    err = self->dbc->c_get(self->dbc, &key, &data, flags | DB_JOIN_ITEM);
+    err = _DBC_get(self->dbc, &key, &data, flags | DB_JOIN_ITEM);
     MYDB_END_ALLOW_THREADS;
     if ((err == DB_NOTFOUND || err == DB_KEYEMPTY)
-	    && self->mydb->moduleFlags.getReturnsNone) {
+            && self->mydb->moduleFlags.getReturnsNone) {
         Py_INCREF(Py_None);
         retval = Py_None;
     }
@@ -3817,8 +4005,7 @@ DBC_join_item(DBCursorObject* self, PyObject* args)
         retval = NULL;
     }
     else {
-        retval = Py_BuildValue("s#", key.data, key.size);
-        FREE_DBT(key);
+        retval = BuildValue_S(key.data, key.size);
     }
 
     return retval;
@@ -3831,25 +4018,45 @@ DBC_join_item(DBCursorObject* self, PyObject* args)
 
 
 static PyObject*
-DBEnv_close(DBEnvObject* self, PyObject* args)
+DBEnv_close_internal(DBEnvObject* self, int flags)
 {
-    int err, flags = 0;
+    PyObject *dummy;
+    int err;
 
-    if (!PyArg_ParseTuple(args, "|i:close", &flags))
-        return NULL;
     if (!self->closed) {      /* Don't close more than once */
+        while(self->children_txns) {
+          dummy=DBTxn_abort_discard_internal(self->children_txns,0);
+          Py_XDECREF(dummy);
+        }
+        while(self->children_dbs) {
+          dummy=DB_close_internal(self->children_dbs, 0, 0);
+          Py_XDECREF(dummy);
+        }
+    }
+
+    self->closed = 1;
+    if (self->db_env) {
         MYDB_BEGIN_ALLOW_THREADS;
         err = self->db_env->close(self->db_env, flags);
         MYDB_END_ALLOW_THREADS;
         /* after calling DBEnv->close, regardless of error, this DBEnv
-         * may not be accessed again (BerkeleyDB docs). */
-        self->closed = 1;
+         * may not be accessed again (Berkeley DB docs). */
         self->db_env = NULL;
         RETURN_IF_ERR();
     }
     RETURN_NONE();
 }
 
+static PyObject*
+DBEnv_close(DBEnvObject* self, PyObject* args)
+{
+    int flags = 0;
+
+    if (!PyArg_ParseTuple(args, "|i:close", &flags))
+        return NULL;
+    return DBEnv_close_internal(self, flags);
+}
+
 
 static PyObject*
 DBEnv_open(DBEnvObject* self, PyObject* args)
@@ -3902,8 +4109,8 @@ DBEnv_dbremove(DBEnvObject* self, PyObject* args, PyObject* kwargs)
                                      NULL };
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "s|zOi:dbremove", kwnames,
-		&file, &database, &txnobj, &flags)) {
-	return NULL;
+                &file, &database, &txnobj, &flags)) {
+        return NULL;
     }
     if (!checkTxnObj(txnobj, &txn)) {
         return NULL;
@@ -3930,8 +4137,8 @@ DBEnv_dbrename(DBEnvObject* self, PyObject* args, PyObject* kwargs)
                                      "flags", NULL };
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "szs|Oi:dbrename", kwnames,
-		&file, &database, &newname, &txnobj, &flags)) {
-	return NULL;
+                &file, &database, &newname, &txnobj, &flags)) {
+        return NULL;
     }
     if (!checkTxnObj(txnobj, &txn)) {
         return NULL;
@@ -3954,8 +4161,8 @@ DBEnv_set_encrypt(DBEnvObject* self, PyObject* args, PyObject* kwargs)
     static char* kwnames[] = { "passwd", "flags", NULL };
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "s|i:set_encrypt", kwnames,
-		&passwd, &flags)) {
-	return NULL;
+                &passwd, &flags)) {
+        return NULL;
     }
 
     MYDB_BEGIN_ALLOW_THREADS;
@@ -3967,7 +4174,6 @@ DBEnv_set_encrypt(DBEnvObject* self, PyObject* args, PyObject* kwargs)
 }
 #endif /* DBVER >= 41 */
 
-#if (DBVER >= 40)
 static PyObject*
 DBEnv_set_timeout(DBEnvObject* self, PyObject* args, PyObject* kwargs)
 {
@@ -3977,8 +4183,8 @@ DBEnv_set_timeout(DBEnvObject* self, PyObject* args, PyObject* kwargs)
     static char* kwnames[] = { "timeout", "flags", NULL };
 
     if (!PyArg_ParseTupleAndKeywords(args, kwargs, "ii:set_timeout", kwnames,
-		&timeout, &flags)) {
-	return NULL;
+                &timeout, &flags)) {
+        return NULL;
     }
 
     MYDB_BEGIN_ALLOW_THREADS;
@@ -3988,7 +4194,6 @@ DBEnv_set_timeout(DBEnvObject* self, PyObject* args, PyObject* kwargs)
     RETURN_IF_ERR();
     RETURN_NONE();
 }
-#endif /* DBVER >= 40 */
 
 static PyObject*
 DBEnv_set_shm_key(DBEnvObject* self, PyObject* args)
@@ -4023,7 +4228,6 @@ DBEnv_set_cachesize(DBEnvObject* self, PyObject* args)
 }
 
 
-#if (DBVER >= 32)
 static PyObject*
 DBEnv_set_flags(DBEnvObject* self, PyObject* args)
 {
@@ -4040,7 +4244,26 @@ DBEnv_set_flags(DBEnvObject* self, PyObject* args)
     RETURN_IF_ERR();
     RETURN_NONE();
 }
-#endif
+
+
+#if (DBVER >= 47)
+static PyObject*
+DBEnv_log_set_config(DBEnvObject* self, PyObject* args)
+{
+    int err, flags, onoff;
+
+    if (!PyArg_ParseTuple(args, "ii:log_set_config",
+                          &flags, &onoff))
+        return NULL;
+    CHECK_ENV_NOT_CLOSED(self);
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->log_set_config(self->db_env, flags, onoff);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+#endif /* DBVER >= 47 */
 
 
 static PyObject*
@@ -4111,8 +4334,24 @@ DBEnv_set_lg_max(DBEnvObject* self, PyObject* args)
     RETURN_NONE();
 }
 
+#if (DBVER >= 42)
+static PyObject*
+DBEnv_get_lg_max(DBEnvObject* self)
+{
+    int err;
+    u_int32_t lg_max;
+
+    CHECK_ENV_NOT_CLOSED(self);
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->get_lg_max(self->db_env, &lg_max);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return NUMBER_FromLong(lg_max);
+}
+#endif
+
 
-#if (DBVER >= 33)
 static PyObject*
 DBEnv_set_lg_regionmax(DBEnvObject* self, PyObject* args)
 {
@@ -4128,7 +4367,6 @@ DBEnv_set_lg_regionmax(DBEnvObject* self, PyObject* args)
     RETURN_IF_ERR();
     RETURN_NONE();
 }
-#endif
 
 
 static PyObject*
@@ -4167,7 +4405,6 @@ DBEnv_set_lk_max(DBEnvObject* self, PyObject* args)
 #endif
 
 
-#if (DBVER >= 32)
 
 static PyObject*
 DBEnv_set_lk_max_locks(DBEnvObject* self, PyObject* args)
@@ -4219,8 +4456,6 @@ DBEnv_set_lk_max_objects(DBEnvObject* self, PyObject* args)
     RETURN_NONE();
 }
 
-#endif
-
 
 static PyObject*
 DBEnv_set_mp_mmapsize(DBEnvObject* self, PyObject* args)
@@ -4258,6 +4493,79 @@ DBEnv_set_tmp_dir(DBEnvObject* self, PyObject* args)
 
 
 static PyObject*
+DBEnv_txn_recover(DBEnvObject* self)
+{
+    int flags = DB_FIRST;
+    int err, i;
+    PyObject *list, *tuple, *gid;
+    DBTxnObject *txn;
+#define PREPLIST_LEN 16
+    DB_PREPLIST preplist[PREPLIST_LEN];
+    long retp;
+
+    CHECK_ENV_NOT_CLOSED(self);
+
+    list=PyList_New(0);
+    if (!list)
+        return NULL;
+    while (!0) {
+        MYDB_BEGIN_ALLOW_THREADS
+        err=self->db_env->txn_recover(self->db_env,
+                        preplist, PREPLIST_LEN, &retp, flags);
+#undef PREPLIST_LEN
+        MYDB_END_ALLOW_THREADS
+        if (err) {
+            Py_DECREF(list);
+            RETURN_IF_ERR();
+        }
+        if (!retp) break;
+        flags=DB_NEXT;  /* Prepare for next loop pass */
+        for (i=0; i<retp; i++) {
+            gid=PyBytes_FromStringAndSize((char *)(preplist[i].gid),
+                                DB_XIDDATASIZE);
+            if (!gid) {
+                Py_DECREF(list);
+                return NULL;
+            }
+            txn=newDBTxnObject(self, NULL, preplist[i].txn, flags);
+            if (!txn) {
+                Py_DECREF(list);
+                Py_DECREF(gid);
+                return NULL;
+            }
+            txn->flag_prepare=1;  /* Recover state */
+            tuple=PyTuple_New(2);
+            if (!tuple) {
+                Py_DECREF(list);
+                Py_DECREF(gid);
+                Py_DECREF(txn);
+                return NULL;
+            }
+            if (PyTuple_SetItem(tuple, 0, gid)) {
+                Py_DECREF(list);
+                Py_DECREF(gid);
+                Py_DECREF(txn);
+                Py_DECREF(tuple);
+                return NULL;
+            }
+            if (PyTuple_SetItem(tuple, 1, (PyObject *)txn)) {
+                Py_DECREF(list);
+                Py_DECREF(txn);
+                Py_DECREF(tuple); /* This delete the "gid" also */
+                return NULL;
+            }
+            if (PyList_Append(list, tuple)) {
+                Py_DECREF(list);
+                Py_DECREF(tuple);/* This delete the "gid" and the "txn" also */
+                return NULL;
+            }
+            Py_DECREF(tuple);
+        }
+    }
+    return list;
+}
+
+static PyObject*
 DBEnv_txn_begin(DBEnvObject* self, PyObject* args, PyObject* kwargs)
 {
     int flags = 0;
@@ -4273,7 +4581,7 @@ DBEnv_txn_begin(DBEnvObject* self, PyObject* args, PyObject* kwargs)
         return NULL;
     CHECK_ENV_NOT_CLOSED(self);
 
-    return (PyObject*)newDBTxnObject(self, txn, flags);
+    return (PyObject*)newDBTxnObject(self, (DBTxnObject *)txnobj, NULL, flags);
 }
 
 
@@ -4287,11 +4595,7 @@ DBEnv_txn_checkpoint(DBEnvObject* self, PyObject* args)
     CHECK_ENV_NOT_CLOSED(self);
 
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = self->db_env->txn_checkpoint(self->db_env, kbyte, min, flags);
-#else
-    err = txn_checkpoint(self->db_env, kbyte, min, flags);
-#endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
     RETURN_NONE();
@@ -4341,14 +4645,10 @@ DBEnv_lock_detect(DBEnvObject* self, PyObject* args)
     CHECK_ENV_NOT_CLOSED(self);
 
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = self->db_env->lock_detect(self->db_env, flags, atype, &aborted);
-#else
-    err = lock_detect(self->db_env, flags, atype, &aborted);
-#endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
-    return PyInt_FromLong(aborted);
+    return NUMBER_FromLong(aborted);
 }
 
 
@@ -4372,27 +4672,36 @@ DBEnv_lock_get(DBEnvObject* self, PyObject* args)
 
 
 static PyObject*
-DBEnv_lock_id(DBEnvObject* self, PyObject* args)
+DBEnv_lock_id(DBEnvObject* self)
 {
     int err;
     u_int32_t theID;
 
-    if (!PyArg_ParseTuple(args, ":lock_id"))
-        return NULL;
-
     CHECK_ENV_NOT_CLOSED(self);
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = self->db_env->lock_id(self->db_env, &theID);
-#else
-    err = lock_id(self->db_env, &theID);
-#endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
 
-    return PyInt_FromLong((long)theID);
+    return NUMBER_FromLong((long)theID);
 }
 
+static PyObject*
+DBEnv_lock_id_free(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    u_int32_t theID;
+
+    if (!PyArg_ParseTuple(args, "I:lock_id_free", &theID))
+        return NULL;
+
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->lock_id_free(self->db_env, theID);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
 
 static PyObject*
 DBEnv_lock_put(DBEnvObject* self, PyObject* args)
@@ -4405,11 +4714,7 @@ DBEnv_lock_put(DBEnvObject* self, PyObject* args)
 
     CHECK_ENV_NOT_CLOSED(self);
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = self->db_env->lock_put(self->db_env, &dblockobj->lock);
-#else
-    err = lock_put(self->db_env, &dblockobj->lock);
-#endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
     RETURN_NONE();
@@ -4437,7 +4742,6 @@ DBEnv_lsn_reset(DBEnvObject* self, PyObject* args, PyObject* kwargs)
 }
 #endif /* DBVER >= 4.4 */
 
-#if (DBVER >= 40)
 static PyObject*
 DBEnv_log_stat(DBEnvObject* self, PyObject* args)
 {
@@ -4473,7 +4777,7 @@ DBEnv_log_stat(DBEnvObject* self, PyObject* args)
     MAKE_ENTRY(lg_size);
     MAKE_ENTRY(record);
 #endif
-#if (DBVER <= 40)
+#if (DBVER < 41)
     MAKE_ENTRY(lg_max);
 #endif
     MAKE_ENTRY(w_mbytes);
@@ -4500,7 +4804,6 @@ DBEnv_log_stat(DBEnvObject* self, PyObject* args)
     free(statp);
     return d;
 } /* DBEnv_log_stat */
-#endif /* DBVER >= 4.0 for log_stat method */
 
 
 static PyObject*
@@ -4516,15 +4819,7 @@ DBEnv_lock_stat(DBEnvObject* self, PyObject* args)
     CHECK_ENV_NOT_CLOSED(self);
 
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = self->db_env->lock_stat(self->db_env, &sp, flags);
-#else
-#if (DBVER >= 33)
-    err = lock_stat(self->db_env, &sp);
-#else
-    err = lock_stat(self->db_env, &sp, NULL);
-#endif
-#endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
 
@@ -4540,22 +4835,26 @@ DBEnv_lock_stat(DBEnvObject* self, PyObject* args)
 #if (DBVER < 41)
     MAKE_ENTRY(lastid);
 #endif
+#if (DBVER >=41)
+    MAKE_ENTRY(id);
+    MAKE_ENTRY(cur_maxid);
+#endif
     MAKE_ENTRY(nmodes);
-#if (DBVER >= 32)
     MAKE_ENTRY(maxlocks);
     MAKE_ENTRY(maxlockers);
     MAKE_ENTRY(maxobjects);
     MAKE_ENTRY(nlocks);
     MAKE_ENTRY(maxnlocks);
-#endif
     MAKE_ENTRY(nlockers);
     MAKE_ENTRY(maxnlockers);
-#if (DBVER >= 32)
     MAKE_ENTRY(nobjects);
     MAKE_ENTRY(maxnobjects);
-#endif
     MAKE_ENTRY(nrequests);
     MAKE_ENTRY(nreleases);
+#if (DBVER >= 44)
+    MAKE_ENTRY(nupgrade);
+    MAKE_ENTRY(ndowngrade);
+#endif
 #if (DBVER < 44)
     MAKE_ENTRY(nnowaits);       /* these were renamed in 4.4 */
     MAKE_ENTRY(nconflicts);
@@ -4564,6 +4863,26 @@ DBEnv_lock_stat(DBEnvObject* self, PyObject* args)
     MAKE_ENTRY(lock_wait);
 #endif
     MAKE_ENTRY(ndeadlocks);
+#if (DBVER >= 41)
+    MAKE_ENTRY(locktimeout);
+    MAKE_ENTRY(txntimeout);
+#endif
+    MAKE_ENTRY(nlocktimeouts);
+    MAKE_ENTRY(ntxntimeouts);
+#if (DBVER >= 46)
+    MAKE_ENTRY(objs_wait);
+    MAKE_ENTRY(objs_nowait);
+    MAKE_ENTRY(lockers_wait);
+    MAKE_ENTRY(lockers_nowait);
+#if (DBVER >= 47)
+    MAKE_ENTRY(lock_wait);
+    MAKE_ENTRY(lock_nowait);
+#else
+    MAKE_ENTRY(locks_wait);
+    MAKE_ENTRY(locks_nowait);
+#endif
+    MAKE_ENTRY(hash_len);
+#endif
     MAKE_ENTRY(regsize);
     MAKE_ENTRY(region_wait);
     MAKE_ENTRY(region_nowait);
@@ -4573,6 +4892,20 @@ DBEnv_lock_stat(DBEnvObject* self, PyObject* args)
     return d;
 }
 
+static PyObject*
+DBEnv_log_flush(DBEnvObject* self)
+{
+    int err;
+
+    CHECK_ENV_NOT_CLOSED(self);
+
+    MYDB_BEGIN_ALLOW_THREADS
+    err = self->db_env->log_flush(self->db_env, NULL);
+    MYDB_END_ALLOW_THREADS
+
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
 
 static PyObject*
 DBEnv_log_archive(DBEnvObject* self, PyObject* args)
@@ -4588,13 +4921,7 @@ DBEnv_log_archive(DBEnvObject* self, PyObject* args)
 
     CHECK_ENV_NOT_CLOSED(self);
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = self->db_env->log_archive(self->db_env, &log_list, flags);
-#elif (DBVER == 33)
-    err = log_archive(self->db_env, &log_list, flags);
-#else
-    err = log_archive(self->db_env, &log_list, flags, NULL);
-#endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
 
@@ -4608,13 +4935,18 @@ DBEnv_log_archive(DBEnvObject* self, PyObject* args)
     if (log_list) {
         char **log_list_start;
         for (log_list_start = log_list; *log_list != NULL; ++log_list) {
-            item = PyString_FromString (*log_list);
+            item = PyBytes_FromString (*log_list);
             if (item == NULL) {
                 Py_DECREF(list);
                 list = NULL;
                 break;
             }
-            PyList_Append(list, item);
+            if (PyList_Append(list, item)) {
+                Py_DECREF(list);
+                list = NULL;
+                Py_DECREF(item);
+                break;
+            }
             Py_DECREF(item);
         }
         free(log_list_start);
@@ -4636,13 +4968,7 @@ DBEnv_txn_stat(DBEnvObject* self, PyObject* args)
     CHECK_ENV_NOT_CLOSED(self);
 
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = self->db_env->txn_stat(self->db_env, &sp, flags);
-#elif (DBVER == 33)
-    err = txn_stat(self->db_env, &sp);
-#else
-    err = txn_stat(self->db_env, &sp, NULL);
-#endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
 
@@ -4653,21 +4979,31 @@ DBEnv_txn_stat(DBEnvObject* self, PyObject* args)
         return NULL;
     }
 
-#define MAKE_ENTRY(name)  _addIntToDict(d, #name, sp->st_##name)
+#define MAKE_ENTRY(name)        _addIntToDict(d, #name, sp->st_##name)
+#define MAKE_TIME_T_ENTRY(name) _addTimeTToDict(d, #name, sp->st_##name)
+#define MAKE_DB_LSN_ENTRY(name) _addDB_lsnToDict(d, #name, sp->st_##name)
 
-    MAKE_ENTRY(time_ckp);
+    MAKE_DB_LSN_ENTRY(last_ckp);
+    MAKE_TIME_T_ENTRY(time_ckp);
     MAKE_ENTRY(last_txnid);
     MAKE_ENTRY(maxtxns);
     MAKE_ENTRY(nactive);
     MAKE_ENTRY(maxnactive);
+#if (DBVER >= 45)
+    MAKE_ENTRY(nsnapshot);
+    MAKE_ENTRY(maxnsnapshot);
+#endif
     MAKE_ENTRY(nbegins);
     MAKE_ENTRY(naborts);
     MAKE_ENTRY(ncommits);
+    MAKE_ENTRY(nrestores);
     MAKE_ENTRY(regsize);
     MAKE_ENTRY(region_wait);
     MAKE_ENTRY(region_nowait);
 
+#undef MAKE_DB_LSN_ENTRY
 #undef MAKE_ENTRY
+#undef MAKE_TIME_T_ENTRY
     free(sp);
     return d;
 }
@@ -4689,14 +5025,883 @@ DBEnv_set_get_returns_none(DBEnvObject* self, PyObject* args)
         ++oldValue;
     self->moduleFlags.getReturnsNone = (flags >= 1);
     self->moduleFlags.cursorSetReturnsNone = (flags >= 2);
-    return PyInt_FromLong(oldValue);
+    return NUMBER_FromLong(oldValue);
+}
+
+static PyObject*
+DBEnv_get_private(DBEnvObject* self)
+{
+    /* We can give out the private field even if dbenv is closed */
+    Py_INCREF(self->private_obj);
+    return self->private_obj;
+}
+
+static PyObject*
+DBEnv_set_private(DBEnvObject* self, PyObject* private_obj)
+{
+    /* We can set the private field even if dbenv is closed */
+    Py_DECREF(self->private_obj);
+    Py_INCREF(private_obj);
+    self->private_obj = private_obj;
+    RETURN_NONE();
+}
+
+
+static PyObject*
+DBEnv_set_rpc_server(DBEnvObject* self, PyObject* args, PyObject* kwargs)
+{
+    int err;
+    char *host;
+    long cl_timeout=0, sv_timeout=0;
+
+    static char* kwnames[] = { "host", "cl_timeout", "sv_timeout", NULL};
+
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs, "s|ll:set_rpc_server", kwnames,
+                                     &host, &cl_timeout, &sv_timeout))
+        return NULL;
+    CHECK_ENV_NOT_CLOSED(self);
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->set_rpc_server(self->db_env, NULL, host, cl_timeout,
+            sv_timeout, 0);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_set_verbose(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int which, onoff;
+
+    if (!PyArg_ParseTuple(args, "ii:set_verbose", &which, &onoff)) {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->set_verbose(self->db_env, which, onoff);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+#if (DBVER >= 42)
+static PyObject*
+DBEnv_get_verbose(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int which;
+    int verbose;
+
+    if (!PyArg_ParseTuple(args, "i:get_verbose", &which)) {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->get_verbose(self->db_env, which, &verbose);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return PyBool_FromLong(verbose);
+}
+#endif
+
+#if (DBVER >= 45)
+static void
+_dbenv_event_notifyCallback(DB_ENV* db_env, u_int32_t event, void *event_info)
+{
+    DBEnvObject *dbenv;
+    PyObject* callback;
+    PyObject* args;
+    PyObject* result = NULL;
+
+    MYDB_BEGIN_BLOCK_THREADS;
+    dbenv = (DBEnvObject *)db_env->app_private;
+    callback = dbenv->event_notifyCallback;
+    if (callback) {
+        if (event == DB_EVENT_REP_NEWMASTER) {
+            args = Py_BuildValue("(Oii)", dbenv, event, *((int *)event_info));
+        } else {
+            args = Py_BuildValue("(OiO)", dbenv, event, Py_None);
+        }
+        if (args) {
+            result = PyEval_CallObject(callback, args);
+        }
+        if ((!args) || (!result)) {
+            PyErr_Print();
+        }
+        Py_XDECREF(args);
+        Py_XDECREF(result);
+    }
+    MYDB_END_BLOCK_THREADS;
+}
+#endif
+
+#if (DBVER >= 45)
+static PyObject*
+DBEnv_set_event_notify(DBEnvObject* self, PyObject* notifyFunc)
+{
+    int err;
+
+    CHECK_ENV_NOT_CLOSED(self);
+
+    if (!PyCallable_Check(notifyFunc)) {
+            makeTypeError("Callable", notifyFunc);
+            return NULL;
+    }
+
+    Py_XDECREF(self->event_notifyCallback);
+    Py_INCREF(notifyFunc);
+    self->event_notifyCallback = notifyFunc;
+
+    /* This is to workaround a problem with un-initialized threads (see
+       comment in DB_associate) */
+#ifdef WITH_THREAD
+    PyEval_InitThreads();
+#endif
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->set_event_notify(self->db_env, _dbenv_event_notifyCallback);
+    MYDB_END_ALLOW_THREADS;
+
+    if (err) {
+            Py_DECREF(notifyFunc);
+            self->event_notifyCallback = NULL;
+    }
+
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+#endif
+
+
+/* --------------------------------------------------------------------- */
+/* REPLICATION METHODS: Base Replication */
+
+
+static PyObject*
+DBEnv_rep_process_message(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    PyObject *control_py, *rec_py;
+    DBT control, rec;
+    int envid;
+#if (DBVER >= 42)
+    DB_LSN lsn;
+#endif
+
+    if (!PyArg_ParseTuple(args, "OOi:rep_process_message", &control_py,
+                &rec_py, &envid))
+        return NULL;
+    CHECK_ENV_NOT_CLOSED(self);
+
+    if (!make_dbt(control_py, &control))
+        return NULL;
+    if (!make_dbt(rec_py, &rec))
+        return NULL;
+
+    MYDB_BEGIN_ALLOW_THREADS;
+#if (DBVER >= 46)
+    err = self->db_env->rep_process_message(self->db_env, &control, &rec,
+            envid, &lsn);
+#else
+#if (DBVER >= 42)
+    err = self->db_env->rep_process_message(self->db_env, &control, &rec,
+            &envid, &lsn);
+#else
+    err = self->db_env->rep_process_message(self->db_env, &control, &rec,
+            &envid);
+#endif
+#endif
+    MYDB_END_ALLOW_THREADS;
+    switch (err) {
+        case DB_REP_NEWMASTER :
+          return Py_BuildValue("(iO)", envid, Py_None);
+          break;
+
+        case DB_REP_DUPMASTER :
+        case DB_REP_HOLDELECTION :
+#if (DBVER >= 44)
+        case DB_REP_IGNORE :
+        case DB_REP_JOIN_FAILURE :
+#endif
+            return Py_BuildValue("(iO)", err, Py_None);
+            break;
+        case DB_REP_NEWSITE :
+            {
+                PyObject *tmp, *r;
+
+                if (!(tmp = PyBytes_FromStringAndSize(rec.data, rec.size))) {
+                    return NULL;
+                }
+
+                r = Py_BuildValue("(iO)", err, tmp);
+                Py_DECREF(tmp);
+                return r;
+                break;
+            }
+#if (DBVER >= 42)
+        case DB_REP_NOTPERM :
+        case DB_REP_ISPERM :
+            return Py_BuildValue("(i(ll))", err, lsn.file, lsn.offset);
+            break;
+#endif
+    }
+    RETURN_IF_ERR();
+    return Py_BuildValue("(OO)", Py_None, Py_None);
+}
+
+static int
+_DBEnv_rep_transportCallback(DB_ENV* db_env, const DBT* control, const DBT* rec,
+        const DB_LSN *lsn, int envid, u_int32_t flags)
+{
+    DBEnvObject *dbenv;
+    PyObject* rep_transport;
+    PyObject* args;
+    PyObject *a, *b;
+    PyObject* result = NULL;
+    int ret=0;
+
+    MYDB_BEGIN_BLOCK_THREADS;
+    dbenv = (DBEnvObject *)db_env->app_private;
+    rep_transport = dbenv->rep_transport;
+
+    /*
+    ** The errors in 'a' or 'b' are detected in "Py_BuildValue".
+    */
+    a = PyBytes_FromStringAndSize(control->data, control->size);
+    b = PyBytes_FromStringAndSize(rec->data, rec->size);
+
+    args = Py_BuildValue(
+#if (PY_VERSION_HEX >= 0x02040000)
+            "(OOO(ll)iI)",
+#else
+            "(OOO(ll)ii)",
+#endif
+            dbenv,
+            a, b,
+            lsn->file, lsn->offset, envid, flags);
+    if (args) {
+        result = PyEval_CallObject(rep_transport, args);
+    }
+
+    if ((!args) || (!result)) {
+        PyErr_Print();
+        ret = -1;
+    }
+    Py_XDECREF(a);
+    Py_XDECREF(b);
+    Py_XDECREF(args);
+    Py_XDECREF(result);
+    MYDB_END_BLOCK_THREADS;
+    return ret;
+}
+
+#if (DBVER <= 41)
+static int
+_DBEnv_rep_transportCallbackOLD(DB_ENV* db_env, const DBT* control, const DBT* rec,
+        int envid, u_int32_t flags)
+{
+    DB_LSN lsn;
+
+    lsn.file = -1;  /* Dummy values */
+    lsn.offset = -1;
+    return _DBEnv_rep_transportCallback(db_env, control, rec, &lsn, envid,
+            flags);
+}
+#endif
+
+static PyObject*
+DBEnv_rep_set_transport(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int envid;
+    PyObject *rep_transport;
+
+    if (!PyArg_ParseTuple(args, "iO:rep_set_transport", &envid, &rep_transport))
+        return NULL;
+    CHECK_ENV_NOT_CLOSED(self);
+    if (!PyCallable_Check(rep_transport)) {
+        makeTypeError("Callable", rep_transport);
+        return NULL;
+    }
+
+    MYDB_BEGIN_ALLOW_THREADS;
+#if (DBVER >=45)
+    err = self->db_env->rep_set_transport(self->db_env, envid,
+            &_DBEnv_rep_transportCallback);
+#else
+#if (DBVER >= 42)
+    err = self->db_env->set_rep_transport(self->db_env, envid,
+            &_DBEnv_rep_transportCallback);
+#else
+    err = self->db_env->set_rep_transport(self->db_env, envid,
+            &_DBEnv_rep_transportCallbackOLD);
+#endif
+#endif
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+
+    Py_DECREF(self->rep_transport);
+    Py_INCREF(rep_transport);
+    self->rep_transport = rep_transport;
+    RETURN_NONE();
+}
+
+#if (DBVER >= 47)
+static PyObject*
+DBEnv_rep_set_request(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    unsigned int minimum, maximum;
+
+    if (!PyArg_ParseTuple(args,"II:rep_set_request", &minimum, &maximum))
+        return NULL;
+    CHECK_ENV_NOT_CLOSED(self);
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_set_request(self->db_env, minimum, maximum);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_rep_get_request(DBEnvObject* self)
+{
+    int err;
+    u_int32_t minimum, maximum;
+
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_get_request(self->db_env, &minimum, &maximum);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+#if (PY_VERSION_HEX >= 0x02040000)
+    return Py_BuildValue("II", minimum, maximum);
+#else
+    return Py_BuildValue("ii", minimum, maximum);
+#endif
+}
+#endif
+
+#if (DBVER >= 45)
+static PyObject*
+DBEnv_rep_set_limit(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int limit;
+
+    if (!PyArg_ParseTuple(args,"i:rep_set_limit", &limit))
+        return NULL;
+    CHECK_ENV_NOT_CLOSED(self);
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_set_limit(self->db_env, 0, limit);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_rep_get_limit(DBEnvObject* self)
+{
+    int err;
+    u_int32_t gbytes, bytes;
+
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_get_limit(self->db_env, &gbytes, &bytes);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return NUMBER_FromLong(bytes);
+}
+#endif
+
+#if (DBVER >= 44)
+static PyObject*
+DBEnv_rep_set_config(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int which;
+    int onoff;
+
+    if (!PyArg_ParseTuple(args,"ii:rep_set_config", &which, &onoff))
+        return NULL;
+    CHECK_ENV_NOT_CLOSED(self);
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_set_config(self->db_env, which, onoff);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_rep_get_config(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int which;
+    int onoff;
+
+    if (!PyArg_ParseTuple(args, "i:rep_get_config", &which)) {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_get_config(self->db_env, which, &onoff);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return PyBool_FromLong(onoff);
+}
+#endif
+
+#if (DBVER >= 46)
+static PyObject*
+DBEnv_rep_elect(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    u_int32_t nsites, nvotes;
+
+    if (!PyArg_ParseTuple(args, "II:rep_elect", &nsites, &nvotes)) {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_elect(self->db_env, nvotes, nvotes, 0);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+#endif
+
+static PyObject*
+DBEnv_rep_start(DBEnvObject* self, PyObject* args, PyObject* kwargs)
+{
+    int err;
+    PyObject *cdata_py = Py_None;
+    DBT cdata;
+    int flags;
+    static char* kwnames[] = {"flags","cdata", NULL};
+
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs,
+                "i|O:rep_start", kwnames, &flags, &cdata_py))
+    {
+            return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+
+    if (!make_dbt(cdata_py, &cdata))
+        return NULL;
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_start(self->db_env, cdata.size ? &cdata : NULL,
+            flags);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+#if (DBVER >= 44)
+static PyObject*
+DBEnv_rep_sync(DBEnvObject* self)
+{
+    int err;
+
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_sync(self->db_env, 0);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+#endif
+
+
+#if (DBVER >= 45)
+static PyObject*
+DBEnv_rep_set_nsites(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int nsites;
+
+    if (!PyArg_ParseTuple(args, "i:rep_set_nsites", &nsites)) {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_set_nsites(self->db_env, nsites);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_rep_get_nsites(DBEnvObject* self)
+{
+    int err;
+#if (DBVER >= 47)
+    u_int32_t nsites;
+#else
+    int nsites;
+#endif
+
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_get_nsites(self->db_env, &nsites);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return NUMBER_FromLong(nsites);
+}
+
+static PyObject*
+DBEnv_rep_set_priority(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int priority;
+
+    if (!PyArg_ParseTuple(args, "i:rep_set_priority", &priority)) {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_set_priority(self->db_env, priority);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_rep_get_priority(DBEnvObject* self)
+{
+    int err;
+#if (DBVER >= 47)
+    u_int32_t priority;
+#else
+    int priority;
+#endif
+
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_get_priority(self->db_env, &priority);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return NUMBER_FromLong(priority);
+}
+
+static PyObject*
+DBEnv_rep_set_timeout(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int which, timeout;
+
+    if (!PyArg_ParseTuple(args, "ii:rep_set_timeout", &which, &timeout)) {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_set_timeout(self->db_env, which, timeout);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_rep_get_timeout(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int which;
+    u_int32_t timeout;
+
+    if (!PyArg_ParseTuple(args, "i:rep_get_timeout", &which)) {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->rep_get_timeout(self->db_env, which, &timeout);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return NUMBER_FromLong(timeout);
+}
+#endif
+
+/* --------------------------------------------------------------------- */
+/* REPLICATION METHODS: Replication Manager */
+
+#if (DBVER >= 45)
+static PyObject*
+DBEnv_repmgr_start(DBEnvObject* self, PyObject* args, PyObject*
+        kwargs)
+{
+    int err;
+    int nthreads, flags;
+    static char* kwnames[] = {"nthreads","flags", NULL};
+
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs,
+                "ii:repmgr_start", kwnames, &nthreads, &flags))
+    {
+            return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->repmgr_start(self->db_env, nthreads, flags);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_repmgr_set_local_site(DBEnvObject* self, PyObject* args, PyObject*
+        kwargs)
+{
+    int err;
+    char *host;
+    int port;
+    int flags = 0;
+    static char* kwnames[] = {"host", "port", "flags", NULL};
+
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs,
+                "si|i:repmgr_set_local_site", kwnames, &host, &port, &flags))
+    {
+            return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->repmgr_set_local_site(self->db_env, host, port, flags);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_repmgr_add_remote_site(DBEnvObject* self, PyObject* args, PyObject*
+        kwargs)
+{
+    int err;
+    char *host;
+    int port;
+    int flags = 0;
+    int eidp;
+    static char* kwnames[] = {"host", "port", "flags", NULL};
+
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs,
+                "si|i:repmgr_add_remote_site", kwnames, &host, &port, &flags))
+    {
+            return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->repmgr_add_remote_site(self->db_env, host, port, &eidp, flags);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return NUMBER_FromLong(eidp);
+}
+
+static PyObject*
+DBEnv_repmgr_set_ack_policy(DBEnvObject* self, PyObject* args)
+{
+    int err;
+    int ack_policy;
+
+    if (!PyArg_ParseTuple(args, "i:repmgr_set_ack_policy", &ack_policy))
+    {
+            return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->repmgr_set_ack_policy(self->db_env, ack_policy);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
+}
+
+static PyObject*
+DBEnv_repmgr_get_ack_policy(DBEnvObject* self)
+{
+    int err;
+    int ack_policy;
+
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->repmgr_get_ack_policy(self->db_env, &ack_policy);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    return NUMBER_FromLong(ack_policy);
+}
+
+static PyObject*
+DBEnv_repmgr_site_list(DBEnvObject* self)
+{
+    int err;
+    unsigned int countp;
+    DB_REPMGR_SITE *listp;
+    PyObject *stats, *key, *tuple;
+
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->repmgr_site_list(self->db_env, &countp, &listp);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+
+    stats=PyDict_New();
+    if (stats == NULL) {
+        free(listp);
+        return NULL;
+    }
+
+    for(;countp--;) {
+        key=NUMBER_FromLong(listp[countp].eid);
+        if(!key) {
+            Py_DECREF(stats);
+            free(listp);
+            return NULL;
+        }
+#if (PY_VERSION_HEX >= 0x02040000)
+        tuple=Py_BuildValue("(sII)", listp[countp].host,
+                listp[countp].port, listp[countp].status);
+#else
+        tuple=Py_BuildValue("(sii)", listp[countp].host,
+                listp[countp].port, listp[countp].status);
+#endif
+        if(!tuple) {
+            Py_DECREF(key);
+            Py_DECREF(stats);
+            free(listp);
+            return NULL;
+        }
+        if(PyDict_SetItem(stats, key, tuple)) {
+            Py_DECREF(key);
+            Py_DECREF(tuple);
+            Py_DECREF(stats);
+            free(listp);
+            return NULL;
+        }
+        Py_DECREF(key);
+        Py_DECREF(tuple);
+    }
+    free(listp);
+    return stats;
+}
+#endif
+
+#if (DBVER >= 46)
+static PyObject*
+DBEnv_repmgr_stat_print(DBEnvObject* self, PyObject* args, PyObject *kwargs)
+{
+    int err;
+    int flags=0;
+    static char* kwnames[] = { "flags", NULL };
+
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs, "|i:repmgr_stat_print",
+                kwnames, &flags))
+    {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->repmgr_stat_print(self->db_env, flags);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+    RETURN_NONE();
 }
 
+static PyObject*
+DBEnv_repmgr_stat(DBEnvObject* self, PyObject* args, PyObject *kwargs)
+{
+    int err;
+    int flags=0;
+    DB_REPMGR_STAT *statp;
+    PyObject *stats;
+    static char* kwnames[] = { "flags", NULL };
+
+    if (!PyArg_ParseTupleAndKeywords(args, kwargs, "|i:repmgr_stat",
+                kwnames, &flags))
+    {
+        return NULL;
+    }
+    CHECK_ENV_NOT_CLOSED(self);
+    MYDB_BEGIN_ALLOW_THREADS;
+    err = self->db_env->repmgr_stat(self->db_env, &statp, flags);
+    MYDB_END_ALLOW_THREADS;
+    RETURN_IF_ERR();
+
+    stats=PyDict_New();
+    if (stats == NULL) {
+        free(statp);
+        return NULL;
+    }
+
+#define MAKE_ENTRY(name)  _addIntToDict(stats, #name, statp->st_##name)
+
+    MAKE_ENTRY(perm_failed);
+    MAKE_ENTRY(msgs_queued);
+    MAKE_ENTRY(msgs_dropped);
+    MAKE_ENTRY(connection_drop);
+    MAKE_ENTRY(connect_fail);
+
+#undef MAKE_ENTRY
+
+    free(statp);
+    return stats;
+}
+#endif
+
 
 /* --------------------------------------------------------------------- */
 /* DBTxn methods */
 
 
+static void _close_transaction_cursors(DBTxnObject* txn)
+{
+    PyObject *dummy;
+
+    while(txn->children_cursors) {
+        PyErr_Warn(PyExc_RuntimeWarning,
+            "Must close cursors before resolving a transaction.");
+        dummy=DBC_close_internal(txn->children_cursors);
+        Py_XDECREF(dummy);
+    }
+}
+
+static void _promote_transaction_dbs_and_sequences(DBTxnObject *txn)
+{
+    DBObject *db;
+#if (DBVER >= 43)
+    DBSequenceObject *dbs;
+#endif
+
+    while (txn->children_dbs) {
+        db=txn->children_dbs;
+        EXTRACT_FROM_DOUBLE_LINKED_LIST_TXN(db);
+        if (txn->parent_txn) {
+            INSERT_IN_DOUBLE_LINKED_LIST_TXN(txn->parent_txn->children_dbs,db);
+            db->txn=txn->parent_txn;
+        } else {
+            /* The db is already linked to its environment,
+            ** so nothing to do.
+            */
+            db->txn=NULL;
+        }
+    }
+
+#if (DBVER >= 43)
+    while (txn->children_sequences) {
+        dbs=txn->children_sequences;
+        EXTRACT_FROM_DOUBLE_LINKED_LIST_TXN(dbs);
+        if (txn->parent_txn) {
+            INSERT_IN_DOUBLE_LINKED_LIST_TXN(txn->parent_txn->children_sequences,dbs);
+            dbs->txn=txn->parent_txn;
+        } else {
+            /* The sequence is already linked to its
+            ** parent db. Nothing to do.
+            */
+            dbs->txn=NULL;
+        }
+    }
+#endif
+}
+
+
 static PyObject*
 DBTxn_commit(DBTxnObject* self, PyObject* args)
 {
@@ -4706,22 +5911,30 @@ DBTxn_commit(DBTxnObject* self, PyObject* args)
     if (!PyArg_ParseTuple(args, "|i:commit", &flags))
         return NULL;
 
+    _close_transaction_cursors(self);
+
     if (!self->txn) {
         PyObject *t =  Py_BuildValue("(is)", 0, "DBTxn must not be used "
-                                     "after txn_commit or txn_abort");
-        PyErr_SetObject(DBError, t);
-        Py_DECREF(t);
+                                     "after txn_commit, txn_abort "
+                                     "or txn_discard");
+        if (t) {
+            PyErr_SetObject(DBError, t);
+            Py_DECREF(t);
+        }
         return NULL;
     }
+    self->flag_prepare=0;
     txn = self->txn;
     self->txn = NULL;   /* this DB_TXN is no longer valid after this call */
+
+    EXTRACT_FROM_DOUBLE_LINKED_LIST(self);
+
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = txn->commit(txn, flags);
-#else
-    err = txn_commit(txn, flags);
-#endif
     MYDB_END_ALLOW_THREADS;
+
+    _promote_transaction_dbs_and_sequences(self);
+
     RETURN_IF_ERR();
     RETURN_NONE();
 }
@@ -4729,7 +5942,6 @@ DBTxn_commit(DBTxnObject* self, PyObject* args)
 static PyObject*
 DBTxn_prepare(DBTxnObject* self, PyObject* args)
 {
-#if (DBVER >= 33)
     int err;
     char* gid=NULL;
     int   gid_size=0;
@@ -4745,95 +5957,113 @@ DBTxn_prepare(DBTxnObject* self, PyObject* args)
 
     if (!self->txn) {
         PyObject *t = Py_BuildValue("(is)", 0,"DBTxn must not be used "
-                                    "after txn_commit or txn_abort");
-        PyErr_SetObject(DBError, t);
-        Py_DECREF(t);
+                                    "after txn_commit, txn_abort "
+                                    "or txn_discard");
+        if (t) {
+            PyErr_SetObject(DBError, t);
+            Py_DECREF(t);
+        }
         return NULL;
     }
+    self->flag_prepare=1;  /* Prepare state */
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     err = self->txn->prepare(self->txn, (u_int8_t*)gid);
-#else
-    err = txn_prepare(self->txn, (u_int8_t*)gid);
-#endif
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
     RETURN_NONE();
-#else
-    int err;
-
-    if (!PyArg_ParseTuple(args, ":prepare"))
-        return NULL;
-
-    if (!self->txn) {
-        PyObject *t = Py_BuildValue("(is)", 0, "DBTxn must not be used "
-                                    "after txn_commit or txn_abort");
-        PyErr_SetObject(DBError, t);
-        Py_DECREF(t);
-        return NULL;
-    }
-    MYDB_BEGIN_ALLOW_THREADS;
-    err = txn_prepare(self->txn);
-    MYDB_END_ALLOW_THREADS;
-    RETURN_IF_ERR();
-    RETURN_NONE();
-#endif
 }
 
 
 static PyObject*
-DBTxn_abort(DBTxnObject* self, PyObject* args)
+DBTxn_abort_discard_internal(DBTxnObject* self, int discard)
 {
-    int err;
+    PyObject *dummy;
+    int err=0;
     DB_TXN *txn;
 
-    if (!PyArg_ParseTuple(args, ":abort"))
-        return NULL;
-
     if (!self->txn) {
         PyObject *t = Py_BuildValue("(is)", 0, "DBTxn must not be used "
-                                    "after txn_commit or txn_abort");
-        PyErr_SetObject(DBError, t);
-        Py_DECREF(t);
+                                    "after txn_commit, txn_abort "
+                                    "or txn_discard");
+        if (t) {
+            PyErr_SetObject(DBError, t);
+            Py_DECREF(t);
+        }
         return NULL;
     }
     txn = self->txn;
     self->txn = NULL;   /* this DB_TXN is no longer valid after this call */
-    MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
-    err = txn->abort(txn);
-#else
-    err = txn_abort(txn);
+
+    _close_transaction_cursors(self);
+#if (DBVER >= 43)
+    while (self->children_sequences) {
+        dummy=DBSequence_close_internal(self->children_sequences,0,0);
+        Py_XDECREF(dummy);
+    }
 #endif
+    while (self->children_dbs) {
+        dummy=DB_close_internal(self->children_dbs, 0, 0);
+        Py_XDECREF(dummy);
+    }
+
+    EXTRACT_FROM_DOUBLE_LINKED_LIST(self);
+
+    MYDB_BEGIN_ALLOW_THREADS;
+    if (discard) {
+        assert(!self->flag_prepare);
+        err = txn->discard(txn,0);
+    } else {
+        /*
+        ** If the transaction is in the "prepare" or "recover" state,
+        ** we better do not implicitly abort it.
+        */
+        if (!self->flag_prepare) {
+            err = txn->abort(txn);
+        }
+    }
     MYDB_END_ALLOW_THREADS;
     RETURN_IF_ERR();
     RETURN_NONE();
 }
 
+static PyObject*
+DBTxn_abort(DBTxnObject* self)
+{
+    self->flag_prepare=0;
+    _close_transaction_cursors(self);
+
+    return DBTxn_abort_discard_internal(self,0);
+}
 
 static PyObject*
-DBTxn_id(DBTxnObject* self, PyObject* args)
+DBTxn_discard(DBTxnObject* self)
 {
-    int id;
+    self->flag_prepare=0;
+    _close_transaction_cursors(self);
+
+    return DBTxn_abort_discard_internal(self,1);
+}
 
-    if (!PyArg_ParseTuple(args, ":id"))
-        return NULL;
+
+static PyObject*
+DBTxn_id(DBTxnObject* self)
+{
+    int id;
 
     if (!self->txn) {
         PyObject *t = Py_BuildValue("(is)", 0, "DBTxn must not be used "
-                                    "after txn_commit or txn_abort");
-        PyErr_SetObject(DBError, t);
-        Py_DECREF(t);
+                                    "after txn_commit, txn_abort "
+                                    "or txn_discard");
+        if (t) {
+            PyErr_SetObject(DBError, t);
+            Py_DECREF(t);
+        }
         return NULL;
     }
     MYDB_BEGIN_ALLOW_THREADS;
-#if (DBVER >= 40)
     id = self->txn->id(self->txn);
-#else
-    id = txn_id(self->txn);
-#endif
     MYDB_END_ALLOW_THREADS;
-    return PyInt_FromLong(id);
+    return NUMBER_FromLong(id);
 }
 
 #if (DBVER >= 43)
@@ -4842,24 +6072,49 @@ DBTxn_id(DBTxnObject* self, PyObject* args)
 
 
 static PyObject*
-DBSequence_close(DBSequenceObject* self, PyObject* args)
+DBSequence_close_internal(DBSequenceObject* self, int flags, int do_not_close)
 {
-    int err, flags=0;
-    if (!PyArg_ParseTuple(args,"|i:close", &flags))
-        return NULL;
-    CHECK_SEQUENCE_NOT_CLOSED(self)
+    int err=0;
 
-    MYDB_BEGIN_ALLOW_THREADS
-    err = self->sequence->close(self->sequence, flags);
-    self->sequence = NULL;
-    MYDB_END_ALLOW_THREADS
+    if (self->sequence!=NULL) {
+        EXTRACT_FROM_DOUBLE_LINKED_LIST(self);
+        if (self->txn) {
+            EXTRACT_FROM_DOUBLE_LINKED_LIST_TXN(self);
+            self->txn=NULL;
+        }
 
-    RETURN_IF_ERR();
+        /*
+        ** "do_not_close" is used to dispose all related objects in the
+        ** tree, without actually releasing the "root" object.
+        ** This is done, for example, because function calls like
+        ** "DBSequence.remove()" implicitly close the underlying handle. So
+        ** the handle doesn't need to be closed, but related objects
+        ** must be cleaned up.
+        */
+        if (!do_not_close) {
+            MYDB_BEGIN_ALLOW_THREADS
+            err = self->sequence->close(self->sequence, flags);
+            MYDB_END_ALLOW_THREADS
+        }
+        self->sequence = NULL;
+
+        RETURN_IF_ERR();
+    }
 
     RETURN_NONE();
 }
 
 static PyObject*
+DBSequence_close(DBSequenceObject* self, PyObject* args)
+{
+    int flags=0;
+    if (!PyArg_ParseTuple(args,"|i:close", &flags))
+        return NULL;
+
+    return DBSequence_close_internal(self,flags,0);
+}
+
+static PyObject*
 DBSequence_get(DBSequenceObject* self, PyObject* args, PyObject* kwargs)
 {
     int err, flags = 0;
@@ -4881,25 +6136,23 @@ DBSequence_get(DBSequenceObject* self, PyObject* args, PyObject* kwargs)
 
     RETURN_IF_ERR();
     return PyLong_FromLongLong(value);
-
 }
 
 static PyObject*
-DBSequence_get_dbp(DBSequenceObject* self, PyObject* args)
+DBSequence_get_dbp(DBSequenceObject* self)
 {
-    if (!PyArg_ParseTuple(args,":get_dbp"))
-        return NULL;
     CHECK_SEQUENCE_NOT_CLOSED(self)
     Py_INCREF(self->mydb);
     return (PyObject* )self->mydb;
 }
 
 static PyObject*
-DBSequence_get_key(DBSequenceObject* self, PyObject* args)
+DBSequence_get_key(DBSequenceObject* self)
 {
     int err;
     DBT key;
-    PyObject *retval;
+    PyObject *retval = NULL;
+
     key.flags = DB_DBT_MALLOC;
     CHECK_SEQUENCE_NOT_CLOSED(self)
     MYDB_BEGIN_ALLOW_THREADS
@@ -4907,7 +6160,7 @@ DBSequence_get_key(DBSequenceObject* self, PyObject* args)
     MYDB_END_ALLOW_THREADS
 
     if (!err)
-        retval = PyString_FromStringAndSize(key.data, key.size); 
+        retval = Build_PyString(key.data, key.size);
 
     FREE_DBT(key);
     RETURN_IF_ERR();
@@ -4919,13 +6172,15 @@ static PyObject*
 DBSequence_init_value(DBSequenceObject* self, PyObject* args)
 {
     int err;
-    db_seq_t value;
+    PY_LONG_LONG value;
+    db_seq_t value2;
     if (!PyArg_ParseTuple(args,"L:init_value", &value))
         return NULL;
     CHECK_SEQUENCE_NOT_CLOSED(self)
 
+    value2=value; /* If truncation, compiler should show a warning */
     MYDB_BEGIN_ALLOW_THREADS
-    err = self->sequence->initial_value(self->sequence, value);
+    err = self->sequence->initial_value(self->sequence, value2);
     MYDB_END_ALLOW_THREADS
 
     RETURN_IF_ERR();
@@ -4956,15 +6211,21 @@ DBSequence_open(DBSequenceObject* self, PyObject* args, PyObject* kwargs)
     err = self->sequence->open(self->sequence, txn, &key, flags);
     MYDB_END_ALLOW_THREADS
 
-    CLEAR_DBT(key);
+    FREE_DBT(key);
     RETURN_IF_ERR();
 
+    if (txn) {
+        INSERT_IN_DOUBLE_LINKED_LIST_TXN(((DBTxnObject *)txnobj)->children_sequences,self);
+        self->txn=(DBTxnObject *)txnobj;
+    }
+
     RETURN_NONE();
 }
 
 static PyObject*
 DBSequence_remove(DBSequenceObject* self, PyObject* args, PyObject* kwargs)
 {
+    PyObject *dummy;
     int err, flags = 0;
     PyObject *txnobj = NULL;
     DB_TXN *txn = NULL;
@@ -4982,6 +6243,9 @@ DBSequence_remove(DBSequenceObject* self, PyObject* args, PyObject* kwargs)
     err = self->sequence->remove(self->sequence, txn, flags);
     MYDB_END_ALLOW_THREADS
 
+    dummy=DBSequence_close_internal(self,flags,1);
+    Py_XDECREF(dummy);
+
     RETURN_IF_ERR();
     RETURN_NONE();
 }
@@ -5003,11 +6267,10 @@ DBSequence_set_cachesize(DBSequenceObject* self, PyObject* args)
 }
 
 static PyObject*
-DBSequence_get_cachesize(DBSequenceObject* self, PyObject* args)
+DBSequence_get_cachesize(DBSequenceObject* self)
 {
     int err, size;
-    if (!PyArg_ParseTuple(args,":get_cachesize"))
-        return NULL;
+
     CHECK_SEQUENCE_NOT_CLOSED(self)
 
     MYDB_BEGIN_ALLOW_THREADS
@@ -5015,7 +6278,7 @@ DBSequence_get_cachesize(DBSequenceObject* self, PyObject* args)
     MYDB_END_ALLOW_THREADS
 
     RETURN_IF_ERR();
-    return PyInt_FromLong(size);
+    return NUMBER_FromLong(size);
 }
 
 static PyObject*
@@ -5032,16 +6295,14 @@ DBSequence_set_flags(DBSequenceObject* self, PyObject* args)
 
     RETURN_IF_ERR();
     RETURN_NONE();
-
 }
 
 static PyObject*
-DBSequence_get_flags(DBSequenceObject* self, PyObject* args)
+DBSequence_get_flags(DBSequenceObject* self)
 {
     unsigned int flags;
     int err;
-    if (!PyArg_ParseTuple(args,":get_flags"))
-        return NULL;
+
     CHECK_SEQUENCE_NOT_CLOSED(self)
 
     MYDB_BEGIN_ALLOW_THREADS
@@ -5049,20 +6310,23 @@ DBSequence_get_flags(DBSequenceObject* self, PyObject* args)
     MYDB_END_ALLOW_THREADS
 
     RETURN_IF_ERR();
-    return PyInt_FromLong((int)flags);
+    return NUMBER_FromLong((int)flags);
 }
 
 static PyObject*
 DBSequence_set_range(DBSequenceObject* self, PyObject* args)
 {
     int err;
-    db_seq_t min, max;
+    PY_LONG_LONG min, max;
+    db_seq_t min2, max2;
     if (!PyArg_ParseTuple(args,"(LL):set_range", &min, &max))
         return NULL;
     CHECK_SEQUENCE_NOT_CLOSED(self)
 
+    min2=min;  /* If truncation, compiler should show a warning */
+    max2=max;
     MYDB_BEGIN_ALLOW_THREADS
-    err = self->sequence->set_range(self->sequence, min, max);
+    err = self->sequence->set_range(self->sequence, min2, max2);
     MYDB_END_ALLOW_THREADS
 
     RETURN_IF_ERR();
@@ -5070,19 +6334,21 @@ DBSequence_set_range(DBSequenceObject* self, PyObject* args)
 }
 
 static PyObject*
-DBSequence_get_range(DBSequenceObject* self, PyObject* args)
+DBSequence_get_range(DBSequenceObject* self)
 {
     int err;
-    db_seq_t min, max;
-    if (!PyArg_ParseTuple(args,":get_range"))
-        return NULL;
+    PY_LONG_LONG min, max;
+    db_seq_t min2, max2;
+
     CHECK_SEQUENCE_NOT_CLOSED(self)
 
     MYDB_BEGIN_ALLOW_THREADS
-    err = self->sequence->get_range(self->sequence, &min, &max);
+    err = self->sequence->get_range(self->sequence, &min2, &max2);
     MYDB_END_ALLOW_THREADS
 
     RETURN_IF_ERR();
+    min=min2;  /* If truncation, compiler should show a warning */
+    max=max2;
     return Py_BuildValue("(LL)", min, max);
 }
 
@@ -5134,29 +6400,23 @@ DBSequence_stat(DBSequenceObject* self, PyObject* args, PyObject* kwargs)
 /* Method definition tables and type objects */
 
 static PyMethodDef DB_methods[] = {
-    {"append",          (PyCFunction)DB_append,         METH_VARARGS},
-#if (DBVER >= 33)
+    {"append",          (PyCFunction)DB_append,         METH_VARARGS|METH_KEYWORDS},
     {"associate",       (PyCFunction)DB_associate,      METH_VARARGS|METH_KEYWORDS},
-#endif
     {"close",           (PyCFunction)DB_close,          METH_VARARGS},
-#if (DBVER >= 32)
     {"consume",         (PyCFunction)DB_consume,        METH_VARARGS|METH_KEYWORDS},
     {"consume_wait",    (PyCFunction)DB_consume_wait,   METH_VARARGS|METH_KEYWORDS},
-#endif
     {"cursor",          (PyCFunction)DB_cursor,         METH_VARARGS|METH_KEYWORDS},
     {"delete",          (PyCFunction)DB_delete,         METH_VARARGS|METH_KEYWORDS},
-    {"fd",              (PyCFunction)DB_fd,             METH_VARARGS},
+    {"fd",              (PyCFunction)DB_fd,             METH_NOARGS},
     {"get",             (PyCFunction)DB_get,            METH_VARARGS|METH_KEYWORDS},
-#if (DBVER >= 33)
     {"pget",            (PyCFunction)DB_pget,           METH_VARARGS|METH_KEYWORDS},
-#endif
     {"get_both",        (PyCFunction)DB_get_both,       METH_VARARGS|METH_KEYWORDS},
-    {"get_byteswapped", (PyCFunction)DB_get_byteswapped,METH_VARARGS},
+    {"get_byteswapped", (PyCFunction)DB_get_byteswapped,METH_NOARGS},
     {"get_size",        (PyCFunction)DB_get_size,       METH_VARARGS|METH_KEYWORDS},
-    {"get_type",        (PyCFunction)DB_get_type,       METH_VARARGS},
+    {"get_type",        (PyCFunction)DB_get_type,       METH_NOARGS},
     {"join",            (PyCFunction)DB_join,           METH_VARARGS},
     {"key_range",       (PyCFunction)DB_key_range,      METH_VARARGS|METH_KEYWORDS},
-    {"has_key",         (PyCFunction)DB_has_key,        METH_VARARGS},
+    {"has_key",         (PyCFunction)DB_has_key,        METH_VARARGS|METH_KEYWORDS},
     {"items",           (PyCFunction)DB_items,          METH_VARARGS},
     {"keys",            (PyCFunction)DB_keys,           METH_VARARGS},
     {"open",            (PyCFunction)DB_open,           METH_VARARGS|METH_KEYWORDS},
@@ -5164,9 +6424,7 @@ static PyMethodDef DB_methods[] = {
     {"remove",          (PyCFunction)DB_remove,         METH_VARARGS|METH_KEYWORDS},
     {"rename",          (PyCFunction)DB_rename,         METH_VARARGS},
     {"set_bt_minkey",   (PyCFunction)DB_set_bt_minkey,  METH_VARARGS},
-#if (DBVER >= 33)
-    {"set_bt_compare",  (PyCFunction)DB_set_bt_compare, METH_VARARGS},
-#endif
+    {"set_bt_compare",  (PyCFunction)DB_set_bt_compare, METH_O},
     {"set_cachesize",   (PyCFunction)DB_set_cachesize,  METH_VARARGS},
 #if (DBVER >= 41)
     {"set_encrypt",     (PyCFunction)DB_set_encrypt,    METH_VARARGS|METH_KEYWORDS},
@@ -5180,15 +6438,13 @@ static PyMethodDef DB_methods[] = {
     {"set_re_len",      (PyCFunction)DB_set_re_len,     METH_VARARGS},
     {"set_re_pad",      (PyCFunction)DB_set_re_pad,     METH_VARARGS},
     {"set_re_source",   (PyCFunction)DB_set_re_source,  METH_VARARGS},
-#if (DBVER >= 32)
-    {"set_q_extentsize",(PyCFunction)DB_set_q_extentsize,METH_VARARGS},
-#endif
+    {"set_q_extentsize",(PyCFunction)DB_set_q_extentsize, METH_VARARGS},
+    {"set_private",     (PyCFunction)DB_set_private,    METH_O},
+    {"get_private",     (PyCFunction)DB_get_private,    METH_NOARGS},
     {"stat",            (PyCFunction)DB_stat,           METH_VARARGS|METH_KEYWORDS},
     {"sync",            (PyCFunction)DB_sync,           METH_VARARGS},
-#if (DBVER >= 33)
     {"truncate",        (PyCFunction)DB_truncate,       METH_VARARGS|METH_KEYWORDS},
-#endif
-    {"type",            (PyCFunction)DB_get_type,       METH_VARARGS},
+    {"type",            (PyCFunction)DB_get_type,       METH_NOARGS},
     {"upgrade",         (PyCFunction)DB_upgrade,        METH_VARARGS},
     {"values",          (PyCFunction)DB_values,         METH_VARARGS},
     {"verify",          (PyCFunction)DB_verify,         METH_VARARGS|METH_KEYWORDS},
@@ -5205,17 +6461,15 @@ static PyMappingMethods DB_mapping = {
 
 
 static PyMethodDef DBCursor_methods[] = {
-    {"close",           (PyCFunction)DBC_close,         METH_VARARGS},
+    {"close",           (PyCFunction)DBC_close,         METH_NOARGS},
     {"count",           (PyCFunction)DBC_count,         METH_VARARGS},
     {"current",         (PyCFunction)DBC_current,       METH_VARARGS|METH_KEYWORDS},
     {"delete",          (PyCFunction)DBC_delete,        METH_VARARGS},
     {"dup",             (PyCFunction)DBC_dup,           METH_VARARGS},
     {"first",           (PyCFunction)DBC_first,         METH_VARARGS|METH_KEYWORDS},
     {"get",             (PyCFunction)DBC_get,           METH_VARARGS|METH_KEYWORDS},
-#if (DBVER >= 33)
     {"pget",            (PyCFunction)DBC_pget,          METH_VARARGS|METH_KEYWORDS},
-#endif
-    {"get_recno",       (PyCFunction)DBC_get_recno,     METH_VARARGS},
+    {"get_recno",       (PyCFunction)DBC_get_recno,     METH_NOARGS},
     {"last",            (PyCFunction)DBC_last,          METH_VARARGS|METH_KEYWORDS},
     {"next",            (PyCFunction)DBC_next,          METH_VARARGS|METH_KEYWORDS},
     {"prev",            (PyCFunction)DBC_prev,          METH_VARARGS|METH_KEYWORDS},
@@ -5223,7 +6477,7 @@ static PyMethodDef DBCursor_methods[] = {
     {"set",             (PyCFunction)DBC_set,           METH_VARARGS|METH_KEYWORDS},
     {"set_range",       (PyCFunction)DBC_set_range,     METH_VARARGS|METH_KEYWORDS},
     {"get_both",        (PyCFunction)DBC_get_both,      METH_VARARGS},
-    {"get_current_size",(PyCFunction)DBC_get_current_size, METH_VARARGS},
+    {"get_current_size",(PyCFunction)DBC_get_current_size, METH_NOARGS},
     {"set_both",        (PyCFunction)DBC_set_both,      METH_VARARGS},
     {"set_recno",       (PyCFunction)DBC_set_recno,     METH_VARARGS|METH_KEYWORDS},
     {"consume",         (PyCFunction)DBC_consume,       METH_VARARGS|METH_KEYWORDS},
@@ -5244,30 +6498,28 @@ static PyMethodDef DBEnv_methods[] = {
     {"dbrename",        (PyCFunction)DBEnv_dbrename,         METH_VARARGS|METH_KEYWORDS},
     {"set_encrypt",     (PyCFunction)DBEnv_set_encrypt,      METH_VARARGS|METH_KEYWORDS},
 #endif
-#if (DBVER >= 40)
     {"set_timeout",     (PyCFunction)DBEnv_set_timeout,      METH_VARARGS|METH_KEYWORDS},
-#endif
     {"set_shm_key",     (PyCFunction)DBEnv_set_shm_key,      METH_VARARGS},
     {"set_cachesize",   (PyCFunction)DBEnv_set_cachesize,    METH_VARARGS},
     {"set_data_dir",    (PyCFunction)DBEnv_set_data_dir,     METH_VARARGS},
-#if (DBVER >= 32)
     {"set_flags",       (PyCFunction)DBEnv_set_flags,        METH_VARARGS},
+#if (DBVER >= 47)
+    {"log_set_config",  (PyCFunction)DBEnv_log_set_config,   METH_VARARGS},
 #endif
     {"set_lg_bsize",    (PyCFunction)DBEnv_set_lg_bsize,     METH_VARARGS},
     {"set_lg_dir",      (PyCFunction)DBEnv_set_lg_dir,       METH_VARARGS},
     {"set_lg_max",      (PyCFunction)DBEnv_set_lg_max,       METH_VARARGS},
-#if (DBVER >= 33)
-    {"set_lg_regionmax",(PyCFunction)DBEnv_set_lg_regionmax, METH_VARARGS},
+#if (DBVER >= 42)
+    {"get_lg_max",      (PyCFunction)DBEnv_get_lg_max,       METH_NOARGS},
 #endif
+    {"set_lg_regionmax",(PyCFunction)DBEnv_set_lg_regionmax, METH_VARARGS},
     {"set_lk_detect",   (PyCFunction)DBEnv_set_lk_detect,    METH_VARARGS},
 #if (DBVER < 45)
     {"set_lk_max",      (PyCFunction)DBEnv_set_lk_max,       METH_VARARGS},
 #endif
-#if (DBVER >= 32)
     {"set_lk_max_locks", (PyCFunction)DBEnv_set_lk_max_locks, METH_VARARGS},
     {"set_lk_max_lockers", (PyCFunction)DBEnv_set_lk_max_lockers, METH_VARARGS},
     {"set_lk_max_objects", (PyCFunction)DBEnv_set_lk_max_objects, METH_VARARGS},
-#endif
     {"set_mp_mmapsize", (PyCFunction)DBEnv_set_mp_mmapsize,  METH_VARARGS},
     {"set_tmp_dir",     (PyCFunction)DBEnv_set_tmp_dir,      METH_VARARGS},
     {"txn_begin",       (PyCFunction)DBEnv_txn_begin,        METH_VARARGS|METH_KEYWORDS},
@@ -5277,17 +6529,78 @@ static PyMethodDef DBEnv_methods[] = {
     {"set_tx_timestamp", (PyCFunction)DBEnv_set_tx_timestamp, METH_VARARGS},
     {"lock_detect",     (PyCFunction)DBEnv_lock_detect,      METH_VARARGS},
     {"lock_get",        (PyCFunction)DBEnv_lock_get,         METH_VARARGS},
-    {"lock_id",         (PyCFunction)DBEnv_lock_id,          METH_VARARGS},
+    {"lock_id",         (PyCFunction)DBEnv_lock_id,          METH_NOARGS},
+    {"lock_id_free",    (PyCFunction)DBEnv_lock_id_free,     METH_VARARGS},
     {"lock_put",        (PyCFunction)DBEnv_lock_put,         METH_VARARGS},
     {"lock_stat",       (PyCFunction)DBEnv_lock_stat,        METH_VARARGS},
     {"log_archive",     (PyCFunction)DBEnv_log_archive,      METH_VARARGS},
-#if (DBVER >= 40)
+    {"log_flush",       (PyCFunction)DBEnv_log_flush,        METH_NOARGS},
     {"log_stat",        (PyCFunction)DBEnv_log_stat,         METH_VARARGS},
-#endif
 #if (DBVER >= 44)
     {"lsn_reset",       (PyCFunction)DBEnv_lsn_reset,        METH_VARARGS|METH_KEYWORDS},
 #endif
     {"set_get_returns_none",(PyCFunction)DBEnv_set_get_returns_none, METH_VARARGS},
+    {"txn_recover",     (PyCFunction)DBEnv_txn_recover,       METH_NOARGS},
+    {"set_rpc_server",  (PyCFunction)DBEnv_set_rpc_server,
+        METH_VARARGS||METH_KEYWORDS},
+    {"set_verbose",     (PyCFunction)DBEnv_set_verbose,       METH_VARARGS},
+#if (DBVER >= 42)
+    {"get_verbose",     (PyCFunction)DBEnv_get_verbose,       METH_VARARGS},
+#endif
+    {"set_private",     (PyCFunction)DBEnv_set_private,       METH_O},
+    {"get_private",     (PyCFunction)DBEnv_get_private,       METH_NOARGS},
+    {"rep_start",       (PyCFunction)DBEnv_rep_start,
+        METH_VARARGS|METH_KEYWORDS},
+    {"rep_set_transport", (PyCFunction)DBEnv_rep_set_transport, METH_VARARGS},
+    {"rep_process_message", (PyCFunction)DBEnv_rep_process_message,
+        METH_VARARGS},
+#if (DBVER >= 46)
+    {"rep_elect",       (PyCFunction)DBEnv_rep_elect,         METH_VARARGS},
+#endif
+#if (DBVER >= 44)
+    {"rep_set_config",  (PyCFunction)DBEnv_rep_set_config,    METH_VARARGS},
+    {"rep_get_config",  (PyCFunction)DBEnv_rep_get_config,    METH_VARARGS},
+    {"rep_sync",        (PyCFunction)DBEnv_rep_sync,          METH_NOARGS},
+#endif
+#if (DBVER >= 45)
+    {"rep_set_limit",   (PyCFunction)DBEnv_rep_set_limit,     METH_VARARGS},
+    {"rep_get_limit",   (PyCFunction)DBEnv_rep_get_limit,     METH_NOARGS},
+#endif
+#if (DBVER >= 47)
+    {"rep_set_request", (PyCFunction)DBEnv_rep_set_request,   METH_VARARGS},
+    {"rep_get_request", (PyCFunction)DBEnv_rep_get_request,   METH_NOARGS},
+#endif
+#if (DBVER >= 45)
+    {"set_event_notify", (PyCFunction)DBEnv_set_event_notify, METH_O},
+#endif
+#if (DBVER >= 45)
+    {"rep_set_nsites", (PyCFunction)DBEnv_rep_set_nsites, METH_VARARGS},
+    {"rep_get_nsites", (PyCFunction)DBEnv_rep_get_nsites, METH_NOARGS},
+    {"rep_set_priority", (PyCFunction)DBEnv_rep_set_priority, METH_VARARGS},
+    {"rep_get_priority", (PyCFunction)DBEnv_rep_get_priority, METH_NOARGS},
+    {"rep_set_timeout", (PyCFunction)DBEnv_rep_set_timeout, METH_VARARGS},
+    {"rep_get_timeout", (PyCFunction)DBEnv_rep_get_timeout, METH_VARARGS},
+#endif
+#if (DBVER >= 45)
+    {"repmgr_start", (PyCFunction)DBEnv_repmgr_start,
+        METH_VARARGS|METH_KEYWORDS},
+    {"repmgr_set_local_site", (PyCFunction)DBEnv_repmgr_set_local_site,
+        METH_VARARGS|METH_KEYWORDS},
+    {"repmgr_add_remote_site", (PyCFunction)DBEnv_repmgr_add_remote_site,
+        METH_VARARGS|METH_KEYWORDS},
+    {"repmgr_set_ack_policy", (PyCFunction)DBEnv_repmgr_set_ack_policy,
+        METH_VARARGS},
+    {"repmgr_get_ack_policy", (PyCFunction)DBEnv_repmgr_get_ack_policy,
+        METH_NOARGS},
+    {"repmgr_site_list", (PyCFunction)DBEnv_repmgr_site_list,
+        METH_NOARGS},
+#endif
+#if (DBVER >= 46)
+    {"repmgr_stat", (PyCFunction)DBEnv_repmgr_stat,
+        METH_VARARGS|METH_KEYWORDS},
+    {"repmgr_stat_print", (PyCFunction)DBEnv_repmgr_stat_print,
+        METH_VARARGS|METH_KEYWORDS},
+#endif
     {NULL,      NULL}       /* sentinel */
 };
 
@@ -5295,8 +6608,9 @@ static PyMethodDef DBEnv_methods[] = {
 static PyMethodDef DBTxn_methods[] = {
     {"commit",          (PyCFunction)DBTxn_commit,      METH_VARARGS},
     {"prepare",         (PyCFunction)DBTxn_prepare,     METH_VARARGS},
-    {"abort",           (PyCFunction)DBTxn_abort,       METH_VARARGS},
-    {"id",              (PyCFunction)DBTxn_id,          METH_VARARGS},
+    {"discard",         (PyCFunction)DBTxn_discard,     METH_NOARGS},
+    {"abort",           (PyCFunction)DBTxn_abort,       METH_NOARGS},
+    {"id",              (PyCFunction)DBTxn_id,          METH_NOARGS},
     {NULL,      NULL}       /* sentinel */
 };
 
@@ -5305,17 +6619,17 @@ static PyMethodDef DBTxn_methods[] = {
 static PyMethodDef DBSequence_methods[] = {
     {"close",           (PyCFunction)DBSequence_close,          METH_VARARGS},
     {"get",             (PyCFunction)DBSequence_get,            METH_VARARGS|METH_KEYWORDS},
-    {"get_dbp",         (PyCFunction)DBSequence_get_dbp,        METH_VARARGS},
-    {"get_key",         (PyCFunction)DBSequence_get_key,        METH_VARARGS},
+    {"get_dbp",         (PyCFunction)DBSequence_get_dbp,        METH_NOARGS},
+    {"get_key",         (PyCFunction)DBSequence_get_key,        METH_NOARGS},
     {"init_value",      (PyCFunction)DBSequence_init_value,     METH_VARARGS},
     {"open",            (PyCFunction)DBSequence_open,           METH_VARARGS|METH_KEYWORDS},
     {"remove",          (PyCFunction)DBSequence_remove,         METH_VARARGS|METH_KEYWORDS},
     {"set_cachesize",   (PyCFunction)DBSequence_set_cachesize,  METH_VARARGS},
-    {"get_cachesize",   (PyCFunction)DBSequence_get_cachesize,  METH_VARARGS},
+    {"get_cachesize",   (PyCFunction)DBSequence_get_cachesize,  METH_NOARGS},
     {"set_flags",       (PyCFunction)DBSequence_set_flags,      METH_VARARGS},
-    {"get_flags",       (PyCFunction)DBSequence_get_flags,      METH_VARARGS},
+    {"get_flags",       (PyCFunction)DBSequence_get_flags,      METH_NOARGS},
     {"set_range",       (PyCFunction)DBSequence_set_range,      METH_VARARGS},
-    {"get_range",       (PyCFunction)DBSequence_get_range,      METH_VARARGS},
+    {"get_range",       (PyCFunction)DBSequence_get_range,      METH_NOARGS},
     {"stat",            (PyCFunction)DBSequence_stat,           METH_VARARGS|METH_KEYWORDS},
     {NULL,      NULL}       /* sentinel */
 };
@@ -5323,129 +6637,130 @@ static PyMethodDef DBSequence_methods[] = {
 
 
 static PyObject*
-DB_getattr(DBObject* self, char *name)
+DBEnv_db_home_get(DBEnvObject* self)
 {
-    return Py_FindMethod(DB_methods, (PyObject* )self, name);
-}
-
-
-static PyObject*
-DBEnv_getattr(DBEnvObject* self, char *name)
-{
-    if (!strcmp(name, "db_home")) {
-        CHECK_ENV_NOT_CLOSED(self);
-        if (self->db_env->db_home == NULL) {
-            RETURN_NONE();
-        }
-        return PyString_FromString(self->db_env->db_home);
-    }
-
-    return Py_FindMethod(DBEnv_methods, (PyObject* )self, name);
-}
+    const char *home = NULL;
 
+    CHECK_ENV_NOT_CLOSED(self);
 
-static PyObject*
-DBCursor_getattr(DBCursorObject* self, char *name)
-{
-    return Py_FindMethod(DBCursor_methods, (PyObject* )self, name);
-}
+#if (DBVER >= 42)
+    self->db_env->get_home(self->db_env, &home);
+#else
+    home=self->db_env->db_home;
+#endif
 
-static PyObject*
-DBTxn_getattr(DBTxnObject* self, char *name)
-{
-    return Py_FindMethod(DBTxn_methods, (PyObject* )self, name);
+    if (home == NULL) {
+        RETURN_NONE();
+    }
+    return PyBytes_FromString(home);
 }
 
-static PyObject*
-DBLock_getattr(DBLockObject* self, char *name)
-{
-    return NULL;
-}
+static PyGetSetDef DBEnv_getsets[] = {
+    {"db_home", (getter)DBEnv_db_home_get, NULL,},
+    {NULL}
+};
 
-#if (DBVER >= 43)
-static PyObject*
-DBSequence_getattr(DBSequenceObject* self, char *name)
-{
-    return Py_FindMethod(DBSequence_methods, (PyObject* )self, name);
-}
-#endif
 
 statichere PyTypeObject DB_Type = {
+#if (PY_VERSION_HEX < 0x03000000)
     PyObject_HEAD_INIT(NULL)
     0,                  /*ob_size*/
+#else
+    PyVarObject_HEAD_INIT(NULL, 0)
+#endif
     "DB",               /*tp_name*/
     sizeof(DBObject),   /*tp_basicsize*/
     0,                  /*tp_itemsize*/
     /* methods */
     (destructor)DB_dealloc, /*tp_dealloc*/
-    0,                  /*tp_print*/
-    (getattrfunc)DB_getattr, /*tp_getattr*/
-    0,                      /*tp_setattr*/
+    0,          /*tp_print*/
+    0,          /*tp_getattr*/
+    0,          /*tp_setattr*/
     0,          /*tp_compare*/
     0,          /*tp_repr*/
     0,          /*tp_as_number*/
     0,          /*tp_as_sequence*/
     &DB_mapping,/*tp_as_mapping*/
     0,          /*tp_hash*/
-#ifdef HAVE_WEAKREF
-    0,			/* tp_call */
-    0,			/* tp_str */
-    0,  		/* tp_getattro */
-    0,                  /* tp_setattro */
-    0,			/* tp_as_buffer */
+    0,                  /* tp_call */
+    0,                  /* tp_str */
+    0,                  /* tp_getattro */
+    0,          /* tp_setattro */
+    0,                  /* tp_as_buffer */
+#if (PY_VERSION_HEX < 0x03000000)
     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_WEAKREFS,      /* tp_flags */
-    0,                  /* tp_doc */
-    0,		        /* tp_traverse */
-    0,			/* tp_clear */
-    0,			/* tp_richcompare */
-    offsetof(DBObject, in_weakreflist),   /* tp_weaklistoffset */
+#else
+    Py_TPFLAGS_DEFAULT,      /* tp_flags */
 #endif
+    0,          /* tp_doc */
+    0,              /* tp_traverse */
+    0,                  /* tp_clear */
+    0,                  /* tp_richcompare */
+    offsetof(DBObject, in_weakreflist),   /* tp_weaklistoffset */
+    0,          /*tp_iter*/
+    0,          /*tp_iternext*/
+    DB_methods, /*tp_methods*/
+    0, /*tp_members*/
 };
 
 
 statichere PyTypeObject DBCursor_Type = {
+#if (PY_VERSION_HEX < 0x03000000)
     PyObject_HEAD_INIT(NULL)
     0,                  /*ob_size*/
+#else
+    PyVarObject_HEAD_INIT(NULL, 0)
+#endif
     "DBCursor",         /*tp_name*/
     sizeof(DBCursorObject),  /*tp_basicsize*/
-    0,                  /*tp_itemsize*/
+    0,          /*tp_itemsize*/
     /* methods */
     (destructor)DBCursor_dealloc,/*tp_dealloc*/
-    0,                  /*tp_print*/
-    (getattrfunc)DBCursor_getattr, /*tp_getattr*/
-    0,                  /*tp_setattr*/
-    0,                  /*tp_compare*/
-    0,                  /*tp_repr*/
-    0,                  /*tp_as_number*/
-    0,                  /*tp_as_sequence*/
-    0,                  /*tp_as_mapping*/
-    0,                  /*tp_hash*/
-#ifdef HAVE_WEAKREF
-    0,			/* tp_call */
-    0,			/* tp_str */
-    0,  		/* tp_getattro */
-    0,                  /* tp_setattro */
-    0,			/* tp_as_buffer */
+    0,          /*tp_print*/
+    0,          /*tp_getattr*/
+    0,          /*tp_setattr*/
+    0,          /*tp_compare*/
+    0,          /*tp_repr*/
+    0,          /*tp_as_number*/
+    0,          /*tp_as_sequence*/
+    0,          /*tp_as_mapping*/
+    0,          /*tp_hash*/
+    0,          /*tp_call*/
+    0,          /*tp_str*/
+    0,          /*tp_getattro*/
+    0,          /*tp_setattro*/
+    0,          /*tp_as_buffer*/
+#if (PY_VERSION_HEX < 0x03000000)
     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_WEAKREFS,      /* tp_flags */
-    0,                  /* tp_doc */
-    0,		        /* tp_traverse */
-    0,			/* tp_clear */
-    0,			/* tp_richcompare */
-    offsetof(DBCursorObject, in_weakreflist),   /* tp_weaklistoffset */
+#else
+    Py_TPFLAGS_DEFAULT,      /* tp_flags */
 #endif
+    0,          /* tp_doc */
+    0,          /* tp_traverse */
+    0,          /* tp_clear */
+    0,          /* tp_richcompare */
+    offsetof(DBCursorObject, in_weakreflist),   /* tp_weaklistoffset */
+    0,          /*tp_iter*/
+    0,          /*tp_iternext*/
+    DBCursor_methods, /*tp_methods*/
+    0,          /*tp_members*/
 };
 
 
 statichere PyTypeObject DBEnv_Type = {
+#if (PY_VERSION_HEX < 0x03000000)
     PyObject_HEAD_INIT(NULL)
-    0,          /*ob_size*/
+    0,                  /*ob_size*/
+#else
+    PyVarObject_HEAD_INIT(NULL, 0)
+#endif
     "DBEnv",            /*tp_name*/
     sizeof(DBEnvObject),    /*tp_basicsize*/
     0,          /*tp_itemsize*/
     /* methods */
     (destructor)DBEnv_dealloc, /*tp_dealloc*/
     0,          /*tp_print*/
-    (getattrfunc)DBEnv_getattr, /*tp_getattr*/
+    0,          /*tp_getattr*/
     0,          /*tp_setattr*/
     0,          /*tp_compare*/
     0,          /*tp_repr*/
@@ -5453,97 +6768,124 @@ statichere PyTypeObject DBEnv_Type = {
     0,          /*tp_as_sequence*/
     0,          /*tp_as_mapping*/
     0,          /*tp_hash*/
-#ifdef HAVE_WEAKREF
-    0,			/* tp_call */
-    0,			/* tp_str */
-    0,  		/* tp_getattro */
-    0,                  /* tp_setattro */
-    0,			/* tp_as_buffer */
+    0,                  /* tp_call */
+    0,                  /* tp_str */
+    0,                  /* tp_getattro */
+    0,          /* tp_setattro */
+    0,                  /* tp_as_buffer */
+#if (PY_VERSION_HEX < 0x03000000)
     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_WEAKREFS,      /* tp_flags */
-    0,                  /* tp_doc */
-    0,		        /* tp_traverse */
-    0,			/* tp_clear */
-    0,			/* tp_richcompare */
-    offsetof(DBEnvObject, in_weakreflist),   /* tp_weaklistoffset */
+#else
+    Py_TPFLAGS_DEFAULT,      /* tp_flags */
 #endif
+    0,          /* tp_doc */
+    0,              /* tp_traverse */
+    0,                  /* tp_clear */
+    0,                  /* tp_richcompare */
+    offsetof(DBEnvObject, in_weakreflist),   /* tp_weaklistoffset */
+    0,          /* tp_iter */
+    0,          /* tp_iternext */
+    DBEnv_methods,      /* tp_methods */
+    0,          /* tp_members */
+    DBEnv_getsets,      /* tp_getsets */
 };
 
 statichere PyTypeObject DBTxn_Type = {
+#if (PY_VERSION_HEX < 0x03000000)
     PyObject_HEAD_INIT(NULL)
-    0,          /*ob_size*/
+    0,                  /*ob_size*/
+#else
+    PyVarObject_HEAD_INIT(NULL, 0)
+#endif
     "DBTxn",    /*tp_name*/
     sizeof(DBTxnObject),  /*tp_basicsize*/
     0,          /*tp_itemsize*/
     /* methods */
     (destructor)DBTxn_dealloc, /*tp_dealloc*/
     0,          /*tp_print*/
-    (getattrfunc)DBTxn_getattr, /*tp_getattr*/
-    0,                      /*tp_setattr*/
+    0,          /*tp_getattr*/
+    0,          /*tp_setattr*/
     0,          /*tp_compare*/
     0,          /*tp_repr*/
     0,          /*tp_as_number*/
     0,          /*tp_as_sequence*/
     0,          /*tp_as_mapping*/
     0,          /*tp_hash*/
-#ifdef HAVE_WEAKREF
-    0,			/* tp_call */
-    0,			/* tp_str */
-    0,  		/* tp_getattro */
-    0,                  /* tp_setattro */
-    0,			/* tp_as_buffer */
+    0,                  /* tp_call */
+    0,                  /* tp_str */
+    0,                  /* tp_getattro */
+    0,          /* tp_setattro */
+    0,                  /* tp_as_buffer */
+#if (PY_VERSION_HEX < 0x03000000)
     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_WEAKREFS,      /* tp_flags */
-    0,                  /* tp_doc */
-    0,		        /* tp_traverse */
-    0,			/* tp_clear */
-    0,			/* tp_richcompare */
-    offsetof(DBTxnObject, in_weakreflist),   /* tp_weaklistoffset */
+#else
+    Py_TPFLAGS_DEFAULT,      /* tp_flags */
 #endif
+    0,          /* tp_doc */
+    0,          /* tp_traverse */
+    0,                  /* tp_clear */
+    0,                  /* tp_richcompare */
+    offsetof(DBTxnObject, in_weakreflist),   /* tp_weaklistoffset */
+    0,          /*tp_iter*/
+    0,          /*tp_iternext*/
+    DBTxn_methods, /*tp_methods*/
+    0,          /*tp_members*/
 };
 
 
 statichere PyTypeObject DBLock_Type = {
+#if (PY_VERSION_HEX < 0x03000000)
     PyObject_HEAD_INIT(NULL)
-    0,          /*ob_size*/
+    0,                  /*ob_size*/
+#else
+    PyVarObject_HEAD_INIT(NULL, 0)
+#endif
     "DBLock",   /*tp_name*/
     sizeof(DBLockObject),  /*tp_basicsize*/
     0,          /*tp_itemsize*/
     /* methods */
     (destructor)DBLock_dealloc, /*tp_dealloc*/
     0,          /*tp_print*/
-    (getattrfunc)DBLock_getattr, /*tp_getattr*/
-    0,                      /*tp_setattr*/
+    0,          /*tp_getattr*/
+    0,          /*tp_setattr*/
     0,          /*tp_compare*/
     0,          /*tp_repr*/
     0,          /*tp_as_number*/
     0,          /*tp_as_sequence*/
     0,          /*tp_as_mapping*/
     0,          /*tp_hash*/
-#ifdef HAVE_WEAKREF
-    0,			/* tp_call */
-    0,			/* tp_str */
-    0,  		/* tp_getattro */
-    0,                  /* tp_setattro */
-    0,			/* tp_as_buffer */
+    0,                  /* tp_call */
+    0,                  /* tp_str */
+    0,                  /* tp_getattro */
+    0,          /* tp_setattro */
+    0,                  /* tp_as_buffer */
+#if (PY_VERSION_HEX < 0x03000000)
     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_WEAKREFS,      /* tp_flags */
-    0,                  /* tp_doc */
-    0,		        /* tp_traverse */
-    0,			/* tp_clear */
-    0,			/* tp_richcompare */
-    offsetof(DBLockObject, in_weakreflist),   /* tp_weaklistoffset */
+#else
+    Py_TPFLAGS_DEFAULT,      /* tp_flags */
 #endif
+    0,          /* tp_doc */
+    0,              /* tp_traverse */
+    0,                  /* tp_clear */
+    0,                  /* tp_richcompare */
+    offsetof(DBLockObject, in_weakreflist),   /* tp_weaklistoffset */
 };
 
 #if (DBVER >= 43)
 statichere PyTypeObject DBSequence_Type = {
+#if (PY_VERSION_HEX < 0x03000000)
     PyObject_HEAD_INIT(NULL)
-    0,          /*ob_size*/
+    0,                  /*ob_size*/
+#else
+    PyVarObject_HEAD_INIT(NULL, 0)
+#endif
     "DBSequence",                   /*tp_name*/
     sizeof(DBSequenceObject),       /*tp_basicsize*/
     0,          /*tp_itemsize*/
     /* methods */
     (destructor)DBSequence_dealloc, /*tp_dealloc*/
     0,          /*tp_print*/
-    (getattrfunc)DBSequence_getattr,/*tp_getattr*/
+    0,          /*tp_getattr*/
     0,          /*tp_setattr*/
     0,          /*tp_compare*/
     0,          /*tp_repr*/
@@ -5551,19 +6893,25 @@ statichere PyTypeObject DBSequence_Type = {
     0,          /*tp_as_sequence*/
     0,          /*tp_as_mapping*/
     0,          /*tp_hash*/
-#ifdef HAVE_WEAKREF
-    0,			/* tp_call */
-    0,			/* tp_str */
-    0,  		/* tp_getattro */
+    0,                  /* tp_call */
+    0,                  /* tp_str */
+    0,                  /* tp_getattro */
     0,          /* tp_setattro */
-    0,			/* tp_as_buffer */
+    0,                  /* tp_as_buffer */
+#if (PY_VERSION_HEX < 0x03000000)
     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_WEAKREFS,      /* tp_flags */
+#else
+    Py_TPFLAGS_DEFAULT,      /* tp_flags */
+#endif
     0,          /* tp_doc */
-    0,		    /* tp_traverse */
-    0,			/* tp_clear */
-    0,			/* tp_richcompare */
+    0,              /* tp_traverse */
+    0,                  /* tp_clear */
+    0,                  /* tp_richcompare */
     offsetof(DBSequenceObject, in_weakreflist),   /* tp_weaklistoffset */
-#endif
+    0,          /*tp_iter*/
+    0,          /*tp_iternext*/
+    DBSequence_methods, /*tp_methods*/
+    0,          /*tp_members*/
 };
 #endif
 
@@ -5622,30 +6970,31 @@ static char bsddb_version_doc[] =
 underlying DB library.";
 
 static PyObject*
-bsddb_version(PyObject* self, PyObject* args)
+bsddb_version(PyObject* self)
 {
     int major, minor, patch;
 
-        if (!PyArg_ParseTuple(args, ":version"))
-        return NULL;
-        db_version(&major, &minor, &patch);
-        return Py_BuildValue("(iii)", major, minor, patch);
+    db_version(&major, &minor, &patch);
+    return Py_BuildValue("(iii)", major, minor, patch);
 }
 
 
 /* List of functions defined in the module */
-
 static PyMethodDef bsddb_methods[] = {
     {"DB",          (PyCFunction)DB_construct,          METH_VARARGS | METH_KEYWORDS },
     {"DBEnv",       (PyCFunction)DBEnv_construct,       METH_VARARGS},
-#if (DBVER >= 43)    
+#if (DBVER >= 43)
     {"DBSequence",  (PyCFunction)DBSequence_construct,  METH_VARARGS | METH_KEYWORDS },
-#endif    
-    {"version",     (PyCFunction)bsddb_version,         METH_VARARGS, bsddb_version_doc},
+#endif
+    {"version",     (PyCFunction)bsddb_version,         METH_NOARGS, bsddb_version_doc},
     {NULL,      NULL}       /* sentinel */
 };
 
 
+/* API structure */
+static BSDDB_api bsddb_api;
+
+
 /* --------------------------------------------------------------------- */
 /* Module initialization */
 
@@ -5658,25 +7007,51 @@ static PyMethodDef bsddb_methods[] = {
 #define MODULE_NAME_MAX_LEN     11
 static char _bsddbModuleName[MODULE_NAME_MAX_LEN+1] = "_bsddb";
 
+#if (PY_VERSION_HEX >= 0x03000000)
+static struct PyModuleDef bsddbmodule = {
+    PyModuleDef_HEAD_INIT,
+    _bsddbModuleName,   /* Name of module */
+    NULL,               /* module documentation, may be NULL */
+    -1,                 /* size of per-interpreter state of the module,
+                            or -1 if the module keeps state in global variables. */
+    bsddb_methods,
+    NULL,   /* Reload */
+    NULL,   /* Traverse */
+    NULL,   /* Clear */
+    NULL    /* Free */
+};
+#endif
+
+
+#if (PY_VERSION_HEX < 0x03000000)
 DL_EXPORT(void) init_bsddb(void)
+#else
+PyMODINIT_FUNC  PyInit__bsddb(void)    /* Note the two underscores */
+#endif
 {
     PyObject* m;
     PyObject* d;
-    PyObject* pybsddb_version_s = PyString_FromString( PY_BSDDB_VERSION );
-    PyObject* db_version_s = PyString_FromString( DB_VERSION_STRING );
-    PyObject* cvsid_s = PyString_FromString( rcs_id );
-
-    /* Initialize the type of the new type objects here; doing it here
-       is required for portability to Windows without requiring C++. */
-    DB_Type.ob_type = &PyType_Type;
-    DBCursor_Type.ob_type = &PyType_Type;
-    DBEnv_Type.ob_type = &PyType_Type;
-    DBTxn_Type.ob_type = &PyType_Type;
-    DBLock_Type.ob_type = &PyType_Type;
-#if (DBVER >= 43)    
-    DBSequence_Type.ob_type = &PyType_Type;
-#endif    
-
+    PyObject* pybsddb_version_s = PyBytes_FromString( PY_BSDDB_VERSION );
+    PyObject* db_version_s = PyBytes_FromString( DB_VERSION_STRING );
+    PyObject* cvsid_s = PyBytes_FromString( rcs_id );
+    PyObject* py_api;
+
+    /* Initialize object types */
+    if ((PyType_Ready(&DB_Type) < 0)
+        || (PyType_Ready(&DBCursor_Type) < 0)
+        || (PyType_Ready(&DBEnv_Type) < 0)
+        || (PyType_Ready(&DBTxn_Type) < 0)
+        || (PyType_Ready(&DBLock_Type) < 0)
+#if (DBVER >= 43)
+        || (PyType_Ready(&DBSequence_Type) < 0)
+#endif
+        ) {
+#if (PY_VERSION_HEX < 0x03000000)
+        return;
+#else
+        return NULL;
+#endif
+    }
 
 #if defined(WITH_THREAD) && !defined(MYDB_USE_GILSTATE)
     /* Save the current interpreter, so callbacks can do the right thing. */
@@ -5684,9 +7059,18 @@ DL_EXPORT(void) init_bsddb(void)
 #endif
 
     /* Create the module and add the functions */
+#if (PY_VERSION_HEX < 0x03000000)
     m = Py_InitModule(_bsddbModuleName, bsddb_methods);
-    if (m == NULL)
-    	return;
+#else
+    m=PyModule_Create(&bsddbmodule);
+#endif
+    if (m == NULL) {
+#if (PY_VERSION_HEX < 0x03000000)
+        return;
+#else
+        return NULL;
+#endif
+    }
 
     /* Add some symbolic constants to the module */
     d = PyModule_GetDict(m);
@@ -5711,7 +7095,7 @@ DL_EXPORT(void) init_bsddb(void)
     ADD_INT(d, DB_RPCCLIENT);
 #else
     ADD_INT(d, DB_CLIENT);
-    /* allow apps to be written using DB_RPCCLIENT on older BerkeleyDB */
+    /* allow apps to be written using DB_RPCCLIENT on older Berkeley DB */
     _addIntToDict(d, "DB_RPCCLIENT", DB_CLIENT);
 #endif
     ADD_INT(d, DB_XA_CREATE);
@@ -5719,6 +7103,9 @@ DL_EXPORT(void) init_bsddb(void)
     ADD_INT(d, DB_CREATE);
     ADD_INT(d, DB_NOMMAP);
     ADD_INT(d, DB_THREAD);
+#if (DBVER >= 45)
+    ADD_INT(d, DB_MULTIVERSION);
+#endif
 
     ADD_INT(d, DB_FORCE);
     ADD_INT(d, DB_INIT_CDB);
@@ -5726,9 +7113,9 @@ DL_EXPORT(void) init_bsddb(void)
     ADD_INT(d, DB_INIT_LOG);
     ADD_INT(d, DB_INIT_MPOOL);
     ADD_INT(d, DB_INIT_TXN);
-#if (DBVER >= 32)
     ADD_INT(d, DB_JOINENV);
-#endif
+
+    ADD_INT(d, DB_XIDDATASIZE);
 
     ADD_INT(d, DB_RECOVER);
     ADD_INT(d, DB_RECOVER_FATAL);
@@ -5749,21 +7136,16 @@ DL_EXPORT(void) init_bsddb(void)
     ADD_INT(d, DB_RDWRMASTER);
     ADD_INT(d, DB_RDONLY);
     ADD_INT(d, DB_TRUNCATE);
-#if (DBVER >= 32)
     ADD_INT(d, DB_EXTENT);
     ADD_INT(d, DB_CDB_ALLDB);
     ADD_INT(d, DB_VERIFY);
-#endif
     ADD_INT(d, DB_UPGRADE);
 
     ADD_INT(d, DB_AGGRESSIVE);
     ADD_INT(d, DB_NOORDERCHK);
     ADD_INT(d, DB_ORDERCHKONLY);
     ADD_INT(d, DB_PR_PAGE);
-#if ! (DBVER >= 33)
-    ADD_INT(d, DB_VRFY_FLAGMASK);
-    ADD_INT(d, DB_PR_HEADERS);
-#endif
+
     ADD_INT(d, DB_PR_RECOVERYTEST);
     ADD_INT(d, DB_SALVAGE);
 
@@ -5772,19 +7154,16 @@ DL_EXPORT(void) init_bsddb(void)
     ADD_INT(d, DB_LOCK_OLDEST);
     ADD_INT(d, DB_LOCK_RANDOM);
     ADD_INT(d, DB_LOCK_YOUNGEST);
-#if (DBVER >= 33)
     ADD_INT(d, DB_LOCK_MAXLOCKS);
     ADD_INT(d, DB_LOCK_MINLOCKS);
     ADD_INT(d, DB_LOCK_MINWRITE);
-#endif
 
+    ADD_INT(d, DB_LOCK_EXPIRE);
+#if (DBVER >= 43)
+    ADD_INT(d, DB_LOCK_MAXWRITE);
+#endif
 
-#if (DBVER >= 33)
-    /* docs say to use zero instead */
     _addIntToDict(d, "DB_LOCK_CONFLICT", 0);
-#else
-    ADD_INT(d, DB_LOCK_CONFLICT);
-#endif
 
     ADD_INT(d, DB_LOCK_DUMP);
     ADD_INT(d, DB_LOCK_GET);
@@ -5797,47 +7176,35 @@ DL_EXPORT(void) init_bsddb(void)
     ADD_INT(d, DB_LOCK_READ);
     ADD_INT(d, DB_LOCK_WRITE);
     ADD_INT(d, DB_LOCK_NOWAIT);
-#if (DBVER >= 32)
     ADD_INT(d, DB_LOCK_WAIT);
-#endif
     ADD_INT(d, DB_LOCK_IWRITE);
     ADD_INT(d, DB_LOCK_IREAD);
     ADD_INT(d, DB_LOCK_IWR);
-#if (DBVER >= 33)
 #if (DBVER < 44)
     ADD_INT(d, DB_LOCK_DIRTY);
 #else
     ADD_INT(d, DB_LOCK_READ_UNCOMMITTED);  /* renamed in 4.4 */
 #endif
     ADD_INT(d, DB_LOCK_WWRITE);
-#endif
 
     ADD_INT(d, DB_LOCK_RECORD);
     ADD_INT(d, DB_LOCK_UPGRADE);
-#if (DBVER >= 32)
     ADD_INT(d, DB_LOCK_SWITCH);
-#endif
-#if (DBVER >= 33)
     ADD_INT(d, DB_LOCK_UPGRADE_WRITE);
-#endif
 
     ADD_INT(d, DB_LOCK_NOWAIT);
     ADD_INT(d, DB_LOCK_RECORD);
     ADD_INT(d, DB_LOCK_UPGRADE);
 
-#if (DBVER >= 33)
     ADD_INT(d, DB_LSTAT_ABORTED);
 #if (DBVER < 43)
     ADD_INT(d, DB_LSTAT_ERR);
 #endif
     ADD_INT(d, DB_LSTAT_FREE);
     ADD_INT(d, DB_LSTAT_HELD);
-#if (DBVER == 33)
-    ADD_INT(d, DB_LSTAT_NOGRANT);
-#endif
+
     ADD_INT(d, DB_LSTAT_PENDING);
     ADD_INT(d, DB_LSTAT_WAITING);
-#endif
 
     ADD_INT(d, DB_ARCH_ABS);
     ADD_INT(d, DB_ARCH_DATA);
@@ -5867,23 +7234,20 @@ DL_EXPORT(void) init_bsddb(void)
 #if (DBVER < 45)
     ADD_INT(d, DB_CACHED_COUNTS);
 #endif
+
 #if (DBVER >= 41)
     _addIntToDict(d, "DB_CHECKPOINT", 0);
 #else
     ADD_INT(d, DB_CHECKPOINT);
     ADD_INT(d, DB_CURLSN);
 #endif
-#if ((DBVER >= 33) && (DBVER <= 41))
+#if (DBVER <= 41)
     ADD_INT(d, DB_COMMIT);
 #endif
     ADD_INT(d, DB_CONSUME);
-#if (DBVER >= 32)
     ADD_INT(d, DB_CONSUME_WAIT);
-#endif
     ADD_INT(d, DB_CURRENT);
-#if (DBVER >= 33)
     ADD_INT(d, DB_FAST_STAT);
-#endif
     ADD_INT(d, DB_FIRST);
     ADD_INT(d, DB_FLUSH);
     ADD_INT(d, DB_GET_BOTH);
@@ -5911,20 +7275,16 @@ DL_EXPORT(void) init_bsddb(void)
 
     ADD_INT(d, DB_OPFLAGS_MASK);
     ADD_INT(d, DB_RMW);
-#if (DBVER >= 33)
     ADD_INT(d, DB_DIRTY_READ);
     ADD_INT(d, DB_MULTIPLE);
     ADD_INT(d, DB_MULTIPLE_KEY);
-#endif
 
 #if (DBVER >= 44)
     ADD_INT(d, DB_READ_UNCOMMITTED);    /* replaces DB_DIRTY_READ in 4.4 */
     ADD_INT(d, DB_READ_COMMITTED);
 #endif
 
-#if (DBVER >= 33)
     ADD_INT(d, DB_DONOTINDEX);
-#endif
 
 #if (DBVER >= 41)
     _addIntToDict(d, "DB_INCOMPLETE", 0);
@@ -5942,44 +7302,139 @@ DL_EXPORT(void) init_bsddb(void)
     ADD_INT(d, DB_OLD_VERSION);
     ADD_INT(d, DB_RUNRECOVERY);
     ADD_INT(d, DB_VERIFY_BAD);
-#if (DBVER >= 33)
     ADD_INT(d, DB_PAGE_NOTFOUND);
     ADD_INT(d, DB_SECONDARY_BAD);
-#endif
-#if (DBVER >= 40)
     ADD_INT(d, DB_STAT_CLEAR);
     ADD_INT(d, DB_REGION_INIT);
     ADD_INT(d, DB_NOLOCKING);
     ADD_INT(d, DB_YIELDCPU);
     ADD_INT(d, DB_PANIC_ENVIRONMENT);
     ADD_INT(d, DB_NOPANIC);
+
+#if (DBVER >= 41)
+    ADD_INT(d, DB_OVERWRITE);
+#endif
+
+#ifdef DB_REGISTER
+    ADD_INT(d, DB_REGISTER);
 #endif
 
 #if (DBVER >= 42)
     ADD_INT(d, DB_TIME_NOTGRANTED);
     ADD_INT(d, DB_TXN_NOT_DURABLE);
     ADD_INT(d, DB_TXN_WRITE_NOSYNC);
-    ADD_INT(d, DB_LOG_AUTOREMOVE);
-    ADD_INT(d, DB_DIRECT_LOG);
     ADD_INT(d, DB_DIRECT_DB);
     ADD_INT(d, DB_INIT_REP);
     ADD_INT(d, DB_ENCRYPT);
     ADD_INT(d, DB_CHKSUM);
 #endif
 
+#if (DBVER >= 42) && (DBVER < 47)
+    ADD_INT(d, DB_LOG_AUTOREMOVE);
+    ADD_INT(d, DB_DIRECT_LOG);
+#endif
+
+#if (DBVER >= 47)
+    ADD_INT(d, DB_LOG_DIRECT);
+    ADD_INT(d, DB_LOG_DSYNC);
+    ADD_INT(d, DB_LOG_IN_MEMORY);
+    ADD_INT(d, DB_LOG_AUTO_REMOVE);
+    ADD_INT(d, DB_LOG_ZERO);
+#endif
+
+#if (DBVER >= 44)
+    ADD_INT(d, DB_DSYNC_DB);
+#endif
+
+#if (DBVER >= 45)
+    ADD_INT(d, DB_TXN_SNAPSHOT);
+#endif
+
+    ADD_INT(d, DB_VERB_DEADLOCK);
+#if (DBVER >= 46)
+    ADD_INT(d, DB_VERB_FILEOPS);
+    ADD_INT(d, DB_VERB_FILEOPS_ALL);
+#endif
+    ADD_INT(d, DB_VERB_RECOVERY);
+#if (DBVER >= 44)
+    ADD_INT(d, DB_VERB_REGISTER);
+#endif
+    ADD_INT(d, DB_VERB_REPLICATION);
+    ADD_INT(d, DB_VERB_WAITSFOR);
+
+#if (DBVER >= 45)
+    ADD_INT(d, DB_EVENT_PANIC);
+    ADD_INT(d, DB_EVENT_REP_CLIENT);
+#if (DBVER >= 46)
+    ADD_INT(d, DB_EVENT_REP_ELECTED);
+#endif
+    ADD_INT(d, DB_EVENT_REP_MASTER);
+    ADD_INT(d, DB_EVENT_REP_NEWMASTER);
+#if (DBVER >= 46)
+    ADD_INT(d, DB_EVENT_REP_PERM_FAILED);
+#endif
+    ADD_INT(d, DB_EVENT_REP_STARTUPDONE);
+    ADD_INT(d, DB_EVENT_WRITE_FAILED);
+#endif
+
+    ADD_INT(d, DB_REP_DUPMASTER);
+    ADD_INT(d, DB_REP_HOLDELECTION);
+#if (DBVER >= 44)
+    ADD_INT(d, DB_REP_IGNORE);
+    ADD_INT(d, DB_REP_JOIN_FAILURE);
+#endif
+#if (DBVER >= 42)
+    ADD_INT(d, DB_REP_ISPERM);
+    ADD_INT(d, DB_REP_NOTPERM);
+#endif
+    ADD_INT(d, DB_REP_NEWSITE);
+
+    ADD_INT(d, DB_REP_MASTER);
+    ADD_INT(d, DB_REP_CLIENT);
+#if (DBVER >= 45)
+    ADD_INT(d, DB_REP_ELECTION);
+
+    ADD_INT(d, DB_REP_ACK_TIMEOUT);
+    ADD_INT(d, DB_REP_CONNECTION_RETRY);
+    ADD_INT(d, DB_REP_ELECTION_TIMEOUT);
+    ADD_INT(d, DB_REP_ELECTION_RETRY);
+#endif
+#if (DBVER >= 46)
+    ADD_INT(d, DB_REP_CHECKPOINT_DELAY);
+    ADD_INT(d, DB_REP_FULL_ELECTION_TIMEOUT);
+#endif
+
+#if (DBVER >= 45)
+    ADD_INT(d, DB_REPMGR_PEER);
+    ADD_INT(d, DB_REPMGR_ACKS_ALL);
+    ADD_INT(d, DB_REPMGR_ACKS_ALL_PEERS);
+    ADD_INT(d, DB_REPMGR_ACKS_NONE);
+    ADD_INT(d, DB_REPMGR_ACKS_ONE);
+    ADD_INT(d, DB_REPMGR_ACKS_ONE_PEER);
+    ADD_INT(d, DB_REPMGR_ACKS_QUORUM);
+    ADD_INT(d, DB_REPMGR_CONNECTED);
+    ADD_INT(d, DB_REPMGR_DISCONNECTED);
+    ADD_INT(d, DB_STAT_CLEAR);
+    ADD_INT(d, DB_STAT_ALL);
+#endif
+
 #if (DBVER >= 43)
-    ADD_INT(d, DB_LOG_INMEMORY);
     ADD_INT(d, DB_BUFFER_SMALL);
     ADD_INT(d, DB_SEQ_DEC);
     ADD_INT(d, DB_SEQ_INC);
     ADD_INT(d, DB_SEQ_WRAP);
 #endif
 
+#if (DBVER >= 43) && (DBVER < 47)
+    ADD_INT(d, DB_LOG_INMEMORY);
+    ADD_INT(d, DB_DSYNC_LOG);
+#endif
+
 #if (DBVER >= 41)
     ADD_INT(d, DB_ENCRYPT_AES);
     ADD_INT(d, DB_AUTO_COMMIT);
 #else
-    /* allow berkeleydb 4.1 aware apps to run on older versions */
+    /* allow Berkeley DB 4.1 aware apps to run on older versions */
     _addIntToDict(d, "DB_AUTO_COMMIT", 0);
 #endif
 
@@ -5993,10 +7448,8 @@ DL_EXPORT(void) init_bsddb(void)
     ADD_INT(d, ENOENT);
     ADD_INT(d, EPERM);
 
-#if (DBVER >= 40)
     ADD_INT(d, DB_SET_LOCK_TIMEOUT);
     ADD_INT(d, DB_SET_TXN_TIMEOUT);
-#endif
 
     /* The exception name must be correct for pickled exception *
      * objects to unpickle properly.                            */
@@ -6014,16 +7467,37 @@ DL_EXPORT(void) init_bsddb(void)
     DBError = NULL;     /* used in MAKE_EX so that it derives from nothing */
     MAKE_EX(DBError);
 
+#if (PY_VERSION_HEX < 0x03000000)
     /* Some magic to make DBNotFoundError and DBKeyEmptyError derive
      * from both DBError and KeyError, since the API only supports
      * using one base class. */
     PyDict_SetItemString(d, "KeyError", PyExc_KeyError);
     PyRun_String("class DBNotFoundError(DBError, KeyError): pass\n"
-	         "class DBKeyEmptyError(DBError, KeyError): pass",
+                 "class DBKeyEmptyError(DBError, KeyError): pass",
                  Py_file_input, d, d);
     DBNotFoundError = PyDict_GetItemString(d, "DBNotFoundError");
     DBKeyEmptyError = PyDict_GetItemString(d, "DBKeyEmptyError");
     PyDict_DelItemString(d, "KeyError");
+#else
+    /* Since Python 2.5, PyErr_NewException() accepts a tuple, to be able to
+    ** derive from several classes. We use this new API only for Python 3.0,
+    ** though.
+    */
+    {
+        PyObject* bases;
+
+        bases = PyTuple_Pack(2, DBError, PyExc_KeyError);
+
+#define MAKE_EX2(name)   name = PyErr_NewException(PYBSDDB_EXCEPTION_BASE #name, bases, NULL); \
+                         PyDict_SetItemString(d, #name, name)
+        MAKE_EX2(DBNotFoundError);
+        MAKE_EX2(DBKeyEmptyError);
+
+#undef MAKE_EX2
+
+        Py_XDECREF(bases);
+    }
+#endif
 
 
 #if !INCOMPLETE_IS_WARNING
@@ -6040,10 +7514,8 @@ DL_EXPORT(void) init_bsddb(void)
     MAKE_EX(DBNoServerError);
     MAKE_EX(DBNoServerHomeError);
     MAKE_EX(DBNoServerIDError);
-#if (DBVER >= 33)
     MAKE_EX(DBPageNotFoundError);
     MAKE_EX(DBSecondaryBadError);
-#endif
 
     MAKE_EX(DBInvalidArgError);
     MAKE_EX(DBAccessError);
@@ -6055,20 +7527,56 @@ DL_EXPORT(void) init_bsddb(void)
     MAKE_EX(DBNoSuchFileError);
     MAKE_EX(DBPermissionsError);
 
+#if (DBVER >= 42)
+    MAKE_EX(DBRepHandleDeadError);
+#endif
+
+    MAKE_EX(DBRepUnavailError);
+
 #undef MAKE_EX
 
+    /* Initiliase the C API structure and add it to the module */
+    bsddb_api.db_type         = &DB_Type;
+    bsddb_api.dbcursor_type   = &DBCursor_Type;
+    bsddb_api.dbenv_type      = &DBEnv_Type;
+    bsddb_api.dbtxn_type      = &DBTxn_Type;
+    bsddb_api.dblock_type     = &DBLock_Type;
+#if (DBVER >= 43)
+    bsddb_api.dbsequence_type = &DBSequence_Type;
+#endif
+    bsddb_api.makeDBError     = makeDBError;
+
+    py_api = PyCObject_FromVoidPtr((void*)&bsddb_api, NULL);
+    PyDict_SetItemString(d, "api", py_api);
+    Py_DECREF(py_api);
+
     /* Check for errors */
     if (PyErr_Occurred()) {
         PyErr_Print();
-        Py_FatalError("can't initialize module _bsddb");
+        Py_FatalError("can't initialize module _bsddb/_pybsddb");
+        Py_DECREF(m);
+        m = NULL;
     }
+#if (PY_VERSION_HEX < 0x03000000)
+    return;
+#else
+    return m;
+#endif
 }
 
 /* allow this module to be named _pybsddb so that it can be installed
  * and imported on top of python >= 2.3 that includes its own older
  * copy of the library named _bsddb without importing the old version. */
+#if (PY_VERSION_HEX < 0x03000000)
 DL_EXPORT(void) init_pybsddb(void)
+#else
+PyMODINIT_FUNC PyInit__pybsddb(void)  /* Note the two underscores */
+#endif
 {
     strncpy(_bsddbModuleName, "_pybsddb", MODULE_NAME_MAX_LEN);
+#if (PY_VERSION_HEX < 0x03000000)
     init_bsddb();
+#else
+    return PyInit__bsddb();   /* Note the two underscores */
+#endif
 }
diff --git a/Modules/bsddb.h b/Modules/bsddb.h
new file mode 100644
index 0000000..673f5fc
--- /dev/null
+++ b/Modules/bsddb.h
@@ -0,0 +1,273 @@
+/*----------------------------------------------------------------------
+  Copyright (c) 1999-2001, Digital Creations, Fredericksburg, VA, USA
+  and Andrew Kuchling. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions are
+  met:
+
+    o Redistributions of source code must retain the above copyright
+      notice, this list of conditions, and the disclaimer that follows.
+
+    o Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions, and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+
+    o Neither the name of Digital Creations nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY DIGITAL CREATIONS AND CONTRIBUTORS *AS
+  IS* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
+  TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
+  PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL DIGITAL
+  CREATIONS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
+  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+  DAMAGE.
+------------------------------------------------------------------------*/
+
+
+/*
+ * Handwritten code to wrap version 3.x of the Berkeley DB library,
+ * written to replace a SWIG-generated file.  It has since been updated
+ * to compile with Berkeley DB versions 3.2 through 4.2.
+ *
+ * This module was started by Andrew Kuchling to remove the dependency
+ * on SWIG in a package by Gregory P. Smith who based his work on a
+ * similar package by Robin Dunn <robin@alldunn.com> which wrapped
+ * Berkeley DB 2.7.x.
+ *
+ * Development of this module then returned full circle back to Robin Dunn
+ * who worked on behalf of Digital Creations to complete the wrapping of
+ * the DB 3.x API and to build a solid unit test suite.  Robin has
+ * since gone onto other projects (wxPython).
+ *
+ * Gregory P. Smith <greg@krypto.org> is once again the maintainer.
+ *
+ * Use the pybsddb-users@lists.sf.net mailing list for all questions.
+ * Things can change faster than the header of this file is updated.  This
+ * file is shared with the PyBSDDB project at SourceForge:
+ *
+ * http://pybsddb.sf.net
+ *
+ * This file should remain backward compatible with Python 2.1, but see PEP
+ * 291 for the most current backward compatibility requirements:
+ *
+ * http://www.python.org/peps/pep-0291.html
+ *
+ * This module contains 6 types:
+ *
+ * DB           (Database)
+ * DBCursor     (Database Cursor)
+ * DBEnv        (database environment)
+ * DBTxn        (An explicit database transaction)
+ * DBLock       (A lock handle)
+ * DBSequence   (Sequence)
+ *
+ */
+
+/* --------------------------------------------------------------------- */
+
+/*
+ * Portions of this module, associated unit tests and build scripts are the
+ * result of a contract with The Written Word (http://thewrittenword.com/)
+ * Many thanks go out to them for causing me to raise the bar on quality and
+ * functionality, resulting in a better bsddb3 package for all of us to use.
+ *
+ * --Robin
+ */
+
+/* --------------------------------------------------------------------- */
+
+/*
+ * Work to split it up into a separate header and to add a C API was
+ * contributed by Duncan Grisby <duncan@tideway.com>.   See here:
+ *  http://sourceforge.net/tracker/index.php?func=detail&aid=1551895&group_id=13900&atid=313900
+ */
+
+/* --------------------------------------------------------------------- */
+
+#ifndef _BSDDB_H_
+#define _BSDDB_H_
+
+#include <db.h>
+
+
+/* 40 = 4.0, 33 = 3.3; this will break if the minor revision is > 9 */
+#define DBVER (DB_VERSION_MAJOR * 10 + DB_VERSION_MINOR)
+#if DB_VERSION_MINOR > 9
+#error "eek! DBVER can't handle minor versions > 9"
+#endif
+
+#define PY_BSDDB_VERSION "4.7.3"
+
+/* Python object definitions */
+
+struct behaviourFlags {
+    /* What is the default behaviour when DB->get or DBCursor->get returns a
+       DB_NOTFOUND || DB_KEYEMPTY error?  Return None or raise an exception? */
+    unsigned int getReturnsNone : 1;
+    /* What is the default behaviour for DBCursor.set* methods when DBCursor->get
+     * returns a DB_NOTFOUND || DB_KEYEMPTY  error?  Return None or raise? */
+    unsigned int cursorSetReturnsNone : 1;
+};
+
+
+
+struct DBObject;          /* Forward declaration */
+struct DBCursorObject;    /* Forward declaration */
+struct DBTxnObject;       /* Forward declaration */
+struct DBSequenceObject;  /* Forward declaration */
+
+typedef struct {
+    PyObject_HEAD
+    DB_ENV*     db_env;
+    u_int32_t   flags;             /* saved flags from open() */
+    int         closed;
+    struct behaviourFlags moduleFlags;
+    PyObject*       event_notifyCallback;
+    struct DBObject *children_dbs;
+    struct DBTxnObject *children_txns;
+    PyObject        *private_obj;
+    PyObject        *rep_transport;
+    PyObject        *in_weakreflist; /* List of weak references */
+} DBEnvObject;
+
+typedef struct DBObject {
+    PyObject_HEAD
+    DB*             db;
+    DBEnvObject*    myenvobj;  /* PyObject containing the DB_ENV */
+    u_int32_t       flags;     /* saved flags from open() */
+    u_int32_t       setflags;  /* saved flags from set_flags() */
+    int             haveStat;
+    struct behaviourFlags moduleFlags;
+    struct DBTxnObject *txn;
+    struct DBCursorObject *children_cursors;
+#if (DBVER >=43)
+    struct DBSequenceObject *children_sequences;
+#endif
+    struct DBObject **sibling_prev_p;
+    struct DBObject *sibling_next;
+    struct DBObject **sibling_prev_p_txn;
+    struct DBObject *sibling_next_txn;
+    PyObject*       associateCallback;
+    PyObject*       btCompareCallback;
+    int             primaryDBType;
+    PyObject        *private_obj;
+    PyObject        *in_weakreflist; /* List of weak references */
+} DBObject;
+
+
+typedef struct DBCursorObject {
+    PyObject_HEAD
+    DBC*            dbc;
+    struct DBCursorObject **sibling_prev_p;
+    struct DBCursorObject *sibling_next;
+    struct DBCursorObject **sibling_prev_p_txn;
+    struct DBCursorObject *sibling_next_txn;
+    DBObject*       mydb;
+    struct DBTxnObject *txn;
+    PyObject        *in_weakreflist; /* List of weak references */
+} DBCursorObject;
+
+
+typedef struct DBTxnObject {
+    PyObject_HEAD
+    DB_TXN*         txn;
+    DBEnvObject*    env;
+    int             flag_prepare;
+    struct DBTxnObject *parent_txn;
+    struct DBTxnObject **sibling_prev_p;
+    struct DBTxnObject *sibling_next;
+    struct DBTxnObject *children_txns;
+    struct DBObject *children_dbs;
+    struct DBSequenceObject *children_sequences;
+    struct DBCursorObject *children_cursors;
+    PyObject        *in_weakreflist; /* List of weak references */
+} DBTxnObject;
+
+
+typedef struct {
+    PyObject_HEAD
+    DB_LOCK         lock;
+    PyObject        *in_weakreflist; /* List of weak references */
+} DBLockObject;
+
+
+#if (DBVER >= 43)
+typedef struct DBSequenceObject {
+    PyObject_HEAD
+    DB_SEQUENCE*     sequence;
+    DBObject*        mydb;
+    struct DBTxnObject *txn;
+    struct DBSequenceObject **sibling_prev_p;
+    struct DBSequenceObject *sibling_next;
+    struct DBSequenceObject **sibling_prev_p_txn;
+    struct DBSequenceObject *sibling_next_txn;
+    PyObject        *in_weakreflist; /* List of weak references */
+} DBSequenceObject;
+#endif
+
+
+/* API structure for use by C code */
+
+/* To access the structure from an external module, use code like the
+   following (error checking missed out for clarity):
+
+     BSDDB_api* bsddb_api;
+     PyObject*  mod;
+     PyObject*  cobj;
+
+     mod  = PyImport_ImportModule("bsddb._bsddb");
+     // Use "bsddb3._pybsddb" if you're using the standalone pybsddb add-on.
+     cobj = PyObject_GetAttrString(mod, "api");
+     api  = (BSDDB_api*)PyCObject_AsVoidPtr(cobj);
+     Py_DECREF(cobj);
+     Py_DECREF(mod);
+
+   The structure's members must not be changed.
+*/
+
+typedef struct {
+    /* Type objects */
+    PyTypeObject* db_type;
+    PyTypeObject* dbcursor_type;
+    PyTypeObject* dbenv_type;
+    PyTypeObject* dbtxn_type;
+    PyTypeObject* dblock_type;
+#if (DBVER >= 43)
+    PyTypeObject* dbsequence_type;
+#endif
+
+    /* Functions */
+    int (*makeDBError)(int err);
+
+} BSDDB_api;
+
+
+#ifndef COMPILING_BSDDB_C
+
+/* If not inside _bsddb.c, define type check macros that use the api
+   structure.  The calling code must have a value named bsddb_api
+   pointing to the api structure.
+*/
+
+#define DBObject_Check(v)       ((v)->ob_type == bsddb_api->db_type)
+#define DBCursorObject_Check(v) ((v)->ob_type == bsddb_api->dbcursor_type)
+#define DBEnvObject_Check(v)    ((v)->ob_type == bsddb_api->dbenv_type)
+#define DBTxnObject_Check(v)    ((v)->ob_type == bsddb_api->dbtxn_type)
+#define DBLockObject_Check(v)   ((v)->ob_type == bsddb_api->dblock_type)
+#if (DBVER >= 43)
+#define DBSequenceObject_Check(v)  ((v)->ob_type == bsddb_api->dbsequence_type)
+#endif
+
+#endif /* COMPILING_BSDDB_C */
+
+
+#endif /* _BSDDB_H_ */
diff --git a/Modules/bsddbmodule.c b/Modules/bsddbmodule.c
index 61c6564..5fd4fb1 100644
--- a/Modules/bsddbmodule.c
+++ b/Modules/bsddbmodule.c
@@ -30,12 +30,12 @@
    (it messes up the info required in the Setup file) */
 
 typedef struct {
-	PyObject_HEAD
-	DB *di_bsddb;
-	int di_size;	/* -1 means recompute */
-	int di_type;
+    PyObject_HEAD
+    DB *di_bsddb;
+    int di_size;        /* -1 means recompute */
+    int di_type;
 #ifdef WITH_THREAD
-	PyThread_type_lock di_lock;
+    PyThread_type_lock di_lock;
 #endif
 } bsddbobject;
 
@@ -44,815 +44,819 @@ static PyTypeObject Bsddbtype;
 #define is_bsddbobject(v) ((v)->ob_type == &Bsddbtype)
 #define check_bsddbobject_open(v, r) if ((v)->di_bsddb == NULL) \
                { PyErr_SetString(BsddbError, \
-				 "BSDDB object has already been closed"); \
+                                 "BSDDB object has already been closed"); \
                  return r; }
 
 static PyObject *BsddbError;
 
 static PyObject *
 newdbhashobject(char *file, int flags, int mode,
-		int bsize, int ffactor, int nelem, int cachesize,
-		int hash, int lorder)
+                int bsize, int ffactor, int nelem, int cachesize,
+                int hash, int lorder)
 {
-	bsddbobject *dp;
-	HASHINFO info;
+    bsddbobject *dp;
+    HASHINFO info;
 
-	if ((dp = PyObject_New(bsddbobject, &Bsddbtype)) == NULL)
-		return NULL;
+    if ((dp = PyObject_New(bsddbobject, &Bsddbtype)) == NULL)
+        return NULL;
 
-	info.bsize = bsize;
-	info.ffactor = ffactor;
-	info.nelem = nelem;
-	info.cachesize = cachesize;
-	info.hash = NULL; /* XXX should derive from hash argument */
-	info.lorder = lorder;
+    info.bsize = bsize;
+    info.ffactor = ffactor;
+    info.nelem = nelem;
+    info.cachesize = cachesize;
+    info.hash = NULL; /* XXX should derive from hash argument */
+    info.lorder = lorder;
 
 #ifdef O_BINARY
-	flags |= O_BINARY;
+    flags |= O_BINARY;
 #endif
-	Py_BEGIN_ALLOW_THREADS
-	dp->di_bsddb = dbopen(file, flags, mode, DB_HASH, &info);
-	Py_END_ALLOW_THREADS
-	if (dp->di_bsddb == NULL) {
-		PyErr_SetFromErrno(BsddbError);
+    Py_BEGIN_ALLOW_THREADS
+    dp->di_bsddb = dbopen(file, flags, mode, DB_HASH, &info);
+    Py_END_ALLOW_THREADS
+    if (dp->di_bsddb == NULL) {
+        PyErr_SetFromErrno(BsddbError);
 #ifdef WITH_THREAD
-		dp->di_lock = NULL;
+        dp->di_lock = NULL;
 #endif
-		Py_DECREF(dp);
-		return NULL;
-	}
+        Py_DECREF(dp);
+        return NULL;
+    }
 
-	dp->di_size = -1;
-	dp->di_type = DB_HASH;
+    dp->di_size = -1;
+    dp->di_type = DB_HASH;
 
 #ifdef WITH_THREAD
-	dp->di_lock = PyThread_allocate_lock();
-	if (dp->di_lock == NULL) {
-		PyErr_SetString(BsddbError, "can't allocate lock");
-		Py_DECREF(dp);
-		return NULL;
-	}
+    dp->di_lock = PyThread_allocate_lock();
+    if (dp->di_lock == NULL) {
+        PyErr_SetString(BsddbError, "can't allocate lock");
+        Py_DECREF(dp);
+        return NULL;
+    }
 #endif
 
-	return (PyObject *)dp;
+    return (PyObject *)dp;
 }
 
 static PyObject *
 newdbbtobject(char *file, int flags, int mode,
-	      int btflags, int cachesize, int maxkeypage,
-	      int minkeypage, int psize, int lorder)
+              int btflags, int cachesize, int maxkeypage,
+              int minkeypage, int psize, int lorder)
 {
-	bsddbobject *dp;
-	BTREEINFO info;
+    bsddbobject *dp;
+    BTREEINFO info;
 
-	if ((dp = PyObject_New(bsddbobject, &Bsddbtype)) == NULL)
-		return NULL;
+    if ((dp = PyObject_New(bsddbobject, &Bsddbtype)) == NULL)
+        return NULL;
 
-	info.flags = btflags;
-	info.cachesize = cachesize;
-	info.maxkeypage = maxkeypage;
-	info.minkeypage = minkeypage;
-	info.psize = psize;
-	info.lorder = lorder;
-	info.compare = 0; /* Use default comparison functions, for now..*/
-	info.prefix = 0;
+    info.flags = btflags;
+    info.cachesize = cachesize;
+    info.maxkeypage = maxkeypage;
+    info.minkeypage = minkeypage;
+    info.psize = psize;
+    info.lorder = lorder;
+    info.compare = 0; /* Use default comparison functions, for now..*/
+    info.prefix = 0;
 
 #ifdef O_BINARY
-	flags |= O_BINARY;
+    flags |= O_BINARY;
 #endif
-	Py_BEGIN_ALLOW_THREADS
-	dp->di_bsddb = dbopen(file, flags, mode, DB_BTREE, &info);
-	Py_END_ALLOW_THREADS
-	if (dp->di_bsddb == NULL) {
-		PyErr_SetFromErrno(BsddbError);
+    Py_BEGIN_ALLOW_THREADS
+    dp->di_bsddb = dbopen(file, flags, mode, DB_BTREE, &info);
+    Py_END_ALLOW_THREADS
+    if (dp->di_bsddb == NULL) {
+        PyErr_SetFromErrno(BsddbError);
 #ifdef WITH_THREAD
-		dp->di_lock = NULL;
+        dp->di_lock = NULL;
 #endif
-		Py_DECREF(dp);
-		return NULL;
-	}
+        Py_DECREF(dp);
+        return NULL;
+    }
 
-	dp->di_size = -1;
-	dp->di_type = DB_BTREE;
+    dp->di_size = -1;
+    dp->di_type = DB_BTREE;
 
 #ifdef WITH_THREAD
-	dp->di_lock = PyThread_allocate_lock();
-	if (dp->di_lock == NULL) {
-		PyErr_SetString(BsddbError, "can't allocate lock");
-		Py_DECREF(dp);
-		return NULL;
-	}
+    dp->di_lock = PyThread_allocate_lock();
+    if (dp->di_lock == NULL) {
+        PyErr_SetString(BsddbError, "can't allocate lock");
+        Py_DECREF(dp);
+        return NULL;
+    }
 #endif
 
-	return (PyObject *)dp;
+    return (PyObject *)dp;
 }
 
 static PyObject *
 newdbrnobject(char *file, int flags, int mode,
-	      int rnflags, int cachesize, int psize, int lorder,
-	      size_t reclen, u_char bval, char *bfname)
+              int rnflags, int cachesize, int psize, int lorder,
+              size_t reclen, u_char bval, char *bfname)
 {
-	bsddbobject *dp;
-	RECNOINFO info;
-	int fd;
+    bsddbobject *dp;
+    RECNOINFO info;
+    int fd;
 
-	if ((dp = PyObject_New(bsddbobject, &Bsddbtype)) == NULL)
-		return NULL;
+    if ((dp = PyObject_New(bsddbobject, &Bsddbtype)) == NULL)
+        return NULL;
 
-	info.flags = rnflags;
-	info.cachesize = cachesize;
-	info.psize = psize;
-	info.lorder = lorder;
-	info.reclen = reclen;
-	info.bval = bval;
-	info.bfname = bfname;
+    info.flags = rnflags;
+    info.cachesize = cachesize;
+    info.psize = psize;
+    info.lorder = lorder;
+    info.reclen = reclen;
+    info.bval = bval;
+    info.bfname = bfname;
 
 #ifdef O_BINARY
-	flags |= O_BINARY;
+    flags |= O_BINARY;
 #endif
-	/* This is a hack to avoid a dbopen() bug that happens when
-	 * it fails. */
-	fd = open(file, flags);
-	if (fd == -1) {
-		dp->di_bsddb = NULL;
-	}
-	else {
-		close(fd);
-		Py_BEGIN_ALLOW_THREADS
-		dp->di_bsddb = dbopen(file, flags, mode, DB_RECNO, &info);
-		Py_END_ALLOW_THREADS
-	}
-	if (dp->di_bsddb == NULL) {
-		PyErr_SetFromErrno(BsddbError);
+    /* This is a hack to avoid a dbopen() bug that happens when
+     * it fails. */
+    fd = open(file, flags);
+    if (fd == -1) {
+        dp->di_bsddb = NULL;
+    }
+    else {
+        close(fd);
+        Py_BEGIN_ALLOW_THREADS
+        dp->di_bsddb = dbopen(file, flags, mode, DB_RECNO, &info);
+        Py_END_ALLOW_THREADS
+    }
+    if (dp->di_bsddb == NULL) {
+        PyErr_SetFromErrno(BsddbError);
 #ifdef WITH_THREAD
-		dp->di_lock = NULL;
+        dp->di_lock = NULL;
 #endif
-		Py_DECREF(dp);
-		return NULL;
-	}
+        Py_DECREF(dp);
+        return NULL;
+    }
 
-	dp->di_size = -1;
-	dp->di_type = DB_RECNO;
+    dp->di_size = -1;
+    dp->di_type = DB_RECNO;
 
 #ifdef WITH_THREAD
-	dp->di_lock = PyThread_allocate_lock();
-	if (dp->di_lock == NULL) {
-		PyErr_SetString(BsddbError, "can't allocate lock");
-		Py_DECREF(dp);
-		return NULL;
-	}
+    dp->di_lock = PyThread_allocate_lock();
+    if (dp->di_lock == NULL) {
+        PyErr_SetString(BsddbError, "can't allocate lock");
+        Py_DECREF(dp);
+        return NULL;
+    }
 #endif
 
-	return (PyObject *)dp;
+    return (PyObject *)dp;
 }
 
 static void
 bsddb_dealloc(bsddbobject *dp)
 {
 #ifdef WITH_THREAD
-	if (dp->di_lock) {
-		PyThread_acquire_lock(dp->di_lock, 0);
-		PyThread_release_lock(dp->di_lock);
-		PyThread_free_lock(dp->di_lock);
-		dp->di_lock = NULL;
-	}
+    if (dp->di_lock) {
+        PyThread_acquire_lock(dp->di_lock, 0);
+        PyThread_release_lock(dp->di_lock);
+        PyThread_free_lock(dp->di_lock);
+        dp->di_lock = NULL;
+    }
 #endif
-	if (dp->di_bsddb != NULL) {
-		int status;
-		Py_BEGIN_ALLOW_THREADS
-		status = (dp->di_bsddb->close)(dp->di_bsddb);
-		Py_END_ALLOW_THREADS
-		if (status != 0)
-			fprintf(stderr,
-				"Python bsddb: close errno %d in dealloc\n",
-				errno);
-	}
-	PyObject_Del(dp);
+    if (dp->di_bsddb != NULL) {
+        int status;
+        Py_BEGIN_ALLOW_THREADS
+        status = (dp->di_bsddb->close)(dp->di_bsddb);
+        Py_END_ALLOW_THREADS
+        if (status != 0)
+            fprintf(stderr,
+                "Python bsddb: close errno %d in dealloc\n",
+                errno);
+    }
+    PyObject_Del(dp);
 }
 
 #ifdef WITH_THREAD
 #define BSDDB_BGN_SAVE(_dp) \
-	Py_BEGIN_ALLOW_THREADS PyThread_acquire_lock(_dp->di_lock,1);
+    Py_BEGIN_ALLOW_THREADS PyThread_acquire_lock(_dp->di_lock,1);
 #define BSDDB_END_SAVE(_dp) \
-	PyThread_release_lock(_dp->di_lock); Py_END_ALLOW_THREADS
+    PyThread_release_lock(_dp->di_lock); Py_END_ALLOW_THREADS
 #else
-#define BSDDB_BGN_SAVE(_dp) Py_BEGIN_ALLOW_THREADS 
+#define BSDDB_BGN_SAVE(_dp) Py_BEGIN_ALLOW_THREADS
 #define BSDDB_END_SAVE(_dp) Py_END_ALLOW_THREADS
 #endif
 
 static Py_ssize_t
 bsddb_length(bsddbobject *dp)
 {
-	check_bsddbobject_open(dp, -1);
-	if (dp->di_size < 0) {
-		DBT krec, drec;
-		int status;
-		int size = 0;
-		BSDDB_BGN_SAVE(dp)
-		for (status = (dp->di_bsddb->seq)(dp->di_bsddb,
-						  &krec, &drec,R_FIRST);
-		     status == 0;
-		     status = (dp->di_bsddb->seq)(dp->di_bsddb,
-						  &krec, &drec, R_NEXT))
-			size++;
-		BSDDB_END_SAVE(dp)
-		if (status < 0) {
-			PyErr_SetFromErrno(BsddbError);
-			return -1;
-		}
-		dp->di_size = size;
-	}
-	return dp->di_size;
+    check_bsddbobject_open(dp, -1);
+    if (dp->di_size < 0) {
+        DBT krec, drec;
+        int status;
+        int size = 0;
+        BSDDB_BGN_SAVE(dp)
+        for (status = (dp->di_bsddb->seq)(dp->di_bsddb,
+                                          &krec, &drec,R_FIRST);
+             status == 0;
+             status = (dp->di_bsddb->seq)(dp->di_bsddb,
+                                          &krec, &drec, R_NEXT))
+            size++;
+        BSDDB_END_SAVE(dp)
+        if (status < 0) {
+            PyErr_SetFromErrno(BsddbError);
+            return -1;
+        }
+        dp->di_size = size;
+    }
+    return dp->di_size;
 }
 
 static PyObject *
 bsddb_subscript(bsddbobject *dp, PyObject *key)
 {
-	int status;
-	DBT krec, drec;
-	char *data,buf[4096];
-	int size;
-	PyObject *result;
-	recno_t recno;
-	
-	if (dp->di_type == DB_RECNO) {
-		if (!PyArg_Parse(key, "i", &recno)) {
-			PyErr_SetString(PyExc_TypeError,
-					"key type must be integer");
-			return NULL;
-		}
-		krec.data = &recno;
-		krec.size = sizeof(recno);
-	}
-	else {
-		if (!PyArg_Parse(key, "s#", &data, &size)) {
-			PyErr_SetString(PyExc_TypeError,
-					"key type must be string");
-			return NULL;
-		}
-		krec.data = data;
-		krec.size = size;
-	}
-        check_bsddbobject_open(dp, NULL);
-
-	BSDDB_BGN_SAVE(dp)
-	status = (dp->di_bsddb->get)(dp->di_bsddb, &krec, &drec, 0);
-	if (status == 0) {
-		if (drec.size > sizeof(buf)) data = malloc(drec.size);
-		else data = buf;
-		if (data!=NULL) memcpy(data,drec.data,drec.size);
-	}
-	BSDDB_END_SAVE(dp)
-	if (data==NULL) return PyErr_NoMemory();
-	if (status != 0) {
-		if (status < 0)
-			PyErr_SetFromErrno(BsddbError);
-		else
-			PyErr_SetObject(PyExc_KeyError, key);
-		return NULL;
-	}
-
-	result = PyString_FromStringAndSize(data, (int)drec.size);
-	if (data != buf) free(data);
-	return result;
+    int status;
+    DBT krec, drec;
+    char *data,buf[4096];
+    int size;
+    PyObject *result;
+    recno_t recno;
+
+    if (dp->di_type == DB_RECNO) {
+        if (!PyArg_Parse(key, "i", &recno)) {
+            PyErr_SetString(PyExc_TypeError,
+                            "key type must be integer");
+            return NULL;
+        }
+        krec.data = &recno;
+        krec.size = sizeof(recno);
+    }
+    else {
+        if (!PyArg_Parse(key, "s#", &data, &size)) {
+            PyErr_SetString(PyExc_TypeError,
+                            "key type must be string");
+            return NULL;
+        }
+        krec.data = data;
+        krec.size = size;
+    }
+    check_bsddbobject_open(dp, NULL);
+
+    BSDDB_BGN_SAVE(dp)
+    status = (dp->di_bsddb->get)(dp->di_bsddb, &krec, &drec, 0);
+    if (status == 0) {
+        if (drec.size > sizeof(buf)) data = malloc(drec.size);
+        else data = buf;
+        if (data!=NULL) memcpy(data,drec.data,drec.size);
+    }
+    BSDDB_END_SAVE(dp)
+    if (data==NULL) return PyErr_NoMemory();
+    if (status != 0) {
+        if (status < 0)
+            PyErr_SetFromErrno(BsddbError);
+        else
+            PyErr_SetObject(PyExc_KeyError, key);
+        return NULL;
+    }
+
+    result = PyString_FromStringAndSize(data, (int)drec.size);
+    if (data != buf) free(data);
+    return result;
 }
 
 static int
 bsddb_ass_sub(bsddbobject *dp, PyObject *key, PyObject *value)
 {
-	int status;
-	DBT krec, drec;
-	char *data;
-	int size;
-	recno_t recno;
-
-	if (dp->di_type == DB_RECNO) {
-		if (!PyArg_Parse(key, "i", &recno)) {
-			PyErr_SetString(PyExc_TypeError,
-					"bsddb key type must be integer");
-			return -1;
-		}
-		krec.data = &recno;
-		krec.size = sizeof(recno);
-	}
-	else {
-		if (!PyArg_Parse(key, "s#", &data, &size)) {
-			PyErr_SetString(PyExc_TypeError,
-					"bsddb key type must be string");
-			return -1;
-		}
-		krec.data = data;
-		krec.size = size;
-	}
-	check_bsddbobject_open(dp, -1);
-	dp->di_size = -1;
-	if (value == NULL) {
-		BSDDB_BGN_SAVE(dp)
-		status = (dp->di_bsddb->del)(dp->di_bsddb, &krec, 0);
-		BSDDB_END_SAVE(dp)
-	}
-	else {
-		if (!PyArg_Parse(value, "s#", &data, &size)) {
-			PyErr_SetString(PyExc_TypeError,
-					"bsddb value type must be string");
-			return -1;
-		}
-		drec.data = data;
-		drec.size = size;
-		BSDDB_BGN_SAVE(dp)
-		status = (dp->di_bsddb->put)(dp->di_bsddb, &krec, &drec, 0);
-		BSDDB_END_SAVE(dp)
-	}
-	if (status != 0) {
-		if (status < 0)
-			PyErr_SetFromErrno(BsddbError);
-		else
-			PyErr_SetObject(PyExc_KeyError, key);
-		return -1;
-	}
-	return 0;
+    int status;
+    DBT krec, drec;
+    char *data;
+    int size;
+    recno_t recno;
+
+    if (dp->di_type == DB_RECNO) {
+        if (!PyArg_Parse(key, "i", &recno)) {
+            PyErr_SetString(PyExc_TypeError,
+                            "bsddb key type must be integer");
+            return -1;
+        }
+        krec.data = &recno;
+        krec.size = sizeof(recno);
+    }
+    else {
+        if (!PyArg_Parse(key, "s#", &data, &size)) {
+            PyErr_SetString(PyExc_TypeError,
+                            "bsddb key type must be string");
+            return -1;
+        }
+        krec.data = data;
+        krec.size = size;
+    }
+    check_bsddbobject_open(dp, -1);
+    dp->di_size = -1;
+    if (value == NULL) {
+        BSDDB_BGN_SAVE(dp)
+        status = (dp->di_bsddb->del)(dp->di_bsddb, &krec, 0);
+        BSDDB_END_SAVE(dp)
+    }
+    else {
+        if (!PyArg_Parse(value, "s#", &data, &size)) {
+            PyErr_SetString(PyExc_TypeError,
+                            "bsddb value type must be string");
+            return -1;
+        }
+        drec.data = data;
+        drec.size = size;
+        BSDDB_BGN_SAVE(dp)
+        status = (dp->di_bsddb->put)(dp->di_bsddb, &krec, &drec, 0);
+        BSDDB_END_SAVE(dp)
+    }
+    if (status != 0) {
+        if (status < 0)
+            PyErr_SetFromErrno(BsddbError);
+        else
+            PyErr_SetObject(PyExc_KeyError, key);
+        return -1;
+    }
+    return 0;
 }
 
 static PyMappingMethods bsddb_as_mapping = {
-	(lenfunc)bsddb_length,		/*mp_length*/
-	(binaryfunc)bsddb_subscript,	/*mp_subscript*/
-	(objobjargproc)bsddb_ass_sub,	/*mp_ass_subscript*/
+    (lenfunc)bsddb_length,              /*mp_length*/
+    (binaryfunc)bsddb_subscript,        /*mp_subscript*/
+    (objobjargproc)bsddb_ass_sub,       /*mp_ass_subscript*/
 };
 
 static PyObject *
 bsddb_close(bsddbobject *dp)
 {
-	if (dp->di_bsddb != NULL) {
-		int status;
-		BSDDB_BGN_SAVE(dp)
-		status = (dp->di_bsddb->close)(dp->di_bsddb);
-		BSDDB_END_SAVE(dp)
-		if (status != 0) {
-			dp->di_bsddb = NULL;
-			PyErr_SetFromErrno(BsddbError);
-			return NULL;
-		}
-	}
-	dp->di_bsddb = NULL;
-	Py_INCREF(Py_None);
-	return Py_None;
+    if (dp->di_bsddb != NULL) {
+        int status;
+        BSDDB_BGN_SAVE(dp)
+        status = (dp->di_bsddb->close)(dp->di_bsddb);
+        BSDDB_END_SAVE(dp)
+        if (status != 0) {
+            dp->di_bsddb = NULL;
+            PyErr_SetFromErrno(BsddbError);
+            return NULL;
+        }
+    }
+    dp->di_bsddb = NULL;
+    Py_INCREF(Py_None);
+    return Py_None;
 }
 
 static PyObject *
 bsddb_keys(bsddbobject *dp)
 {
-	PyObject *list, *item=NULL;
-	DBT krec, drec;
-	char *data=NULL,buf[4096];
-	int status;
-	int err;
-
-	check_bsddbobject_open(dp, NULL);
-	list = PyList_New(0);
-	if (list == NULL)
-		return NULL;
-	BSDDB_BGN_SAVE(dp)
-	status = (dp->di_bsddb->seq)(dp->di_bsddb, &krec, &drec, R_FIRST);
-	if (status == 0) {
-		if (krec.size > sizeof(buf)) data = malloc(krec.size);
-		else data = buf;
-		if (data != NULL) memcpy(data,krec.data,krec.size);
-	}
-	BSDDB_END_SAVE(dp)
-	if (status == 0 && data==NULL) return PyErr_NoMemory();
-	while (status == 0) {
-		if (dp->di_type == DB_RECNO)
-			item = PyInt_FromLong(*((int*)data));
-		else
-			item = PyString_FromStringAndSize(data,
-							  (int)krec.size);
-		if (data != buf) free(data);
-		if (item == NULL) {
-			Py_DECREF(list);
-			return NULL;
-		}
-		err = PyList_Append(list, item);
-		Py_DECREF(item);
-		if (err != 0) {
-			Py_DECREF(list);
-			return NULL;
-		}
-		BSDDB_BGN_SAVE(dp)
-		status = (dp->di_bsddb->seq)
-			(dp->di_bsddb, &krec, &drec, R_NEXT);
-		if (status == 0) {
-			if (krec.size > sizeof(buf))
-				data = malloc(krec.size);
-			else data = buf;
-			if (data != NULL)
-				memcpy(data,krec.data,krec.size);
-		}
-		BSDDB_END_SAVE(dp)
-		if (data == NULL) return PyErr_NoMemory();
-	}
-	if (status < 0) {
-		PyErr_SetFromErrno(BsddbError);
-		Py_DECREF(list);
-		return NULL;
-	}
-	if (dp->di_size < 0)
-		dp->di_size = PyList_Size(list); /* We just did the work */
-	return list;
+    PyObject *list, *item=NULL;
+    DBT krec, drec;
+    char *data=NULL,buf[4096];
+    int status;
+    int err;
+
+    check_bsddbobject_open(dp, NULL);
+    list = PyList_New(0);
+    if (list == NULL)
+        return NULL;
+    BSDDB_BGN_SAVE(dp)
+    status = (dp->di_bsddb->seq)(dp->di_bsddb, &krec, &drec, R_FIRST);
+    if (status == 0) {
+        if (krec.size > sizeof(buf)) data = malloc(krec.size);
+        else data = buf;
+        if (data != NULL) memcpy(data,krec.data,krec.size);
+    }
+    BSDDB_END_SAVE(dp)
+    if (status == 0 && data==NULL) return PyErr_NoMemory();
+    while (status == 0) {
+        if (dp->di_type == DB_RECNO)
+            item = PyInt_FromLong(*((int*)data));
+        else
+            item = PyString_FromStringAndSize(data,
+                                              (int)krec.size);
+        if (data != buf) free(data);
+        if (item == NULL) {
+            Py_DECREF(list);
+            return NULL;
+        }
+        err = PyList_Append(list, item);
+        Py_DECREF(item);
+        if (err != 0) {
+            Py_DECREF(list);
+            return NULL;
+        }
+        BSDDB_BGN_SAVE(dp)
+        status = (dp->di_bsddb->seq)
+            (dp->di_bsddb, &krec, &drec, R_NEXT);
+        if (status == 0) {
+            if (krec.size > sizeof(buf))
+                data = malloc(krec.size);
+            else data = buf;
+            if (data != NULL)
+                memcpy(data,krec.data,krec.size);
+        }
+        BSDDB_END_SAVE(dp)
+        if (data == NULL) return PyErr_NoMemory();
+    }
+    if (status < 0) {
+        PyErr_SetFromErrno(BsddbError);
+        Py_DECREF(list);
+        return NULL;
+    }
+    if (dp->di_size < 0)
+        dp->di_size = PyList_Size(list); /* We just did the work */
+    return list;
 }
 
 static PyObject *
 bsddb_has_key(bsddbobject *dp, PyObject *args)
 {
-	DBT krec, drec;
-	int status;
-	char *data;
-	int size;
-	recno_t recno;
-
-	if (dp->di_type == DB_RECNO) {
-		if (!PyArg_ParseTuple(args, "i;key type must be integer",
-				      &recno)) {
-			return NULL;
-		}
-		krec.data = &recno;
-		krec.size = sizeof(recno);
-	}
-	else {
-		if (!PyArg_ParseTuple(args, "s#;key type must be string",
-				      &data, &size)) {
-			return NULL;
-		}
-		krec.data = data;
-		krec.size = size;
-	}
-	check_bsddbobject_open(dp, NULL);
-
-	BSDDB_BGN_SAVE(dp)
-	status = (dp->di_bsddb->get)(dp->di_bsddb, &krec, &drec, 0);
-	BSDDB_END_SAVE(dp)
-	if (status < 0) {
-		PyErr_SetFromErrno(BsddbError);
-		return NULL;
-	}
-
-	return PyInt_FromLong(status == 0);
+    DBT krec, drec;
+    int status;
+    char *data;
+    int size;
+    recno_t recno;
+
+    if (dp->di_type == DB_RECNO) {
+        if (!PyArg_ParseTuple(args, "i;key type must be integer",
+                              &recno)) {
+            return NULL;
+        }
+        krec.data = &recno;
+        krec.size = sizeof(recno);
+    }
+    else {
+        if (!PyArg_ParseTuple(args, "s#;key type must be string",
+                              &data, &size)) {
+            return NULL;
+        }
+        krec.data = data;
+        krec.size = size;
+    }
+    check_bsddbobject_open(dp, NULL);
+
+    BSDDB_BGN_SAVE(dp)
+    status = (dp->di_bsddb->get)(dp->di_bsddb, &krec, &drec, 0);
+    BSDDB_END_SAVE(dp)
+    if (status < 0) {
+        PyErr_SetFromErrno(BsddbError);
+        return NULL;
+    }
+
+    return PyInt_FromLong(status == 0);
 }
 
 static PyObject *
 bsddb_set_location(bsddbobject *dp, PyObject *key)
 {
-	int status;
-	DBT krec, drec;
-	char *data,buf[4096];
-	int size;
-	PyObject *result;
-	recno_t recno;
-
-	if (dp->di_type == DB_RECNO) {
-		if (!PyArg_ParseTuple(key, "i;key type must be integer",
-				      &recno)) {
-			return NULL;
-		}
-		krec.data = &recno;
-		krec.size = sizeof(recno);
-	}
-	else {
-		if (!PyArg_ParseTuple(key, "s#;key type must be string",
-				      &data, &size)) {
-			return NULL;
-		}
-		krec.data = data;
-		krec.size = size;
-	}
-	check_bsddbobject_open(dp, NULL);
-
-	BSDDB_BGN_SAVE(dp)
-	status = (dp->di_bsddb->seq)(dp->di_bsddb, &krec, &drec, R_CURSOR);
-	if (status == 0) {
-		if (drec.size > sizeof(buf)) data = malloc(drec.size);
-		else data = buf;
-		if (data!=NULL) memcpy(data,drec.data,drec.size);
-	}
-	BSDDB_END_SAVE(dp)
-	if (data==NULL) return PyErr_NoMemory();
-	if (status != 0) {
-		if (status < 0)
-			PyErr_SetFromErrno(BsddbError);
-		else
-			PyErr_SetObject(PyExc_KeyError, key);
-		return NULL;
-	}
-
-	if (dp->di_type == DB_RECNO)
-		result = Py_BuildValue("is#", *((int*)krec.data),
-				       data, drec.size);
-	else
-		result = Py_BuildValue("s#s#", krec.data, krec.size,
-				       data, drec.size);
-	if (data != buf) free(data);
-	return result;
+    int status;
+    DBT krec, drec;
+    char *data,buf[4096];
+    int size;
+    PyObject *result;
+    recno_t recno;
+
+    if (dp->di_type == DB_RECNO) {
+        if (!PyArg_ParseTuple(key, "i;key type must be integer",
+                              &recno)) {
+            return NULL;
+        }
+        krec.data = &recno;
+        krec.size = sizeof(recno);
+    }
+    else {
+        if (!PyArg_ParseTuple(key, "s#;key type must be string",
+                              &data, &size)) {
+            return NULL;
+        }
+        krec.data = data;
+        krec.size = size;
+    }
+    check_bsddbobject_open(dp, NULL);
+
+    BSDDB_BGN_SAVE(dp)
+    status = (dp->di_bsddb->seq)(dp->di_bsddb, &krec, &drec, R_CURSOR);
+    if (status == 0) {
+        if (drec.size > sizeof(buf)) data = malloc(drec.size);
+        else data = buf;
+        if (data!=NULL) memcpy(data,drec.data,drec.size);
+    }
+    BSDDB_END_SAVE(dp)
+    if (data==NULL) return PyErr_NoMemory();
+    if (status != 0) {
+        if (status < 0)
+            PyErr_SetFromErrno(BsddbError);
+        else
+            PyErr_SetObject(PyExc_KeyError, key);
+        return NULL;
+    }
+
+    if (dp->di_type == DB_RECNO)
+        result = Py_BuildValue("is#", *((int*)krec.data),
+                               data, drec.size);
+    else
+        result = Py_BuildValue("s#s#", krec.data, krec.size,
+                               data, drec.size);
+    if (data != buf) free(data);
+    return result;
 }
 
 static PyObject *
 bsddb_seq(bsddbobject *dp, int sequence_request)
 {
-	int status;
-	DBT krec, drec;
-	char *kdata=NULL,kbuf[4096];
-	char *ddata=NULL,dbuf[4096];
-	PyObject *result;
-
-	check_bsddbobject_open(dp, NULL);
-	krec.data = 0;
-	krec.size = 0;
-
-	BSDDB_BGN_SAVE(dp)
-	status = (dp->di_bsddb->seq)(dp->di_bsddb, &krec,
-				     &drec, sequence_request);
-	if (status == 0) {
-		if (krec.size > sizeof(kbuf)) kdata = malloc(krec.size);
-		else kdata = kbuf;
-		if (kdata != NULL) memcpy(kdata,krec.data,krec.size);
-		if (drec.size > sizeof(dbuf)) ddata = malloc(drec.size);
-		else ddata = dbuf;
-		if (ddata != NULL) memcpy(ddata,drec.data,drec.size);
-	}
-	BSDDB_END_SAVE(dp)
-	if (status == 0) {
-		if ((kdata == NULL) || (ddata == NULL)) 
-			return PyErr_NoMemory();
-	}
-	else { 
-		/* (status != 0) */  
-		if (status < 0)
-			PyErr_SetFromErrno(BsddbError);
-		else
-			PyErr_SetString(PyExc_KeyError, "no key/data pairs");
-		return NULL;
-	}
-
-	if (dp->di_type == DB_RECNO)
-		result = Py_BuildValue("is#", *((int*)kdata),
-				       ddata, drec.size);
-	else
-		result = Py_BuildValue("s#s#", kdata, krec.size,
-				       ddata, drec.size);
-	if (kdata != kbuf) free(kdata);
-	if (ddata != dbuf) free(ddata);
-	return result;
+    int status;
+    DBT krec, drec;
+    char *kdata=NULL,kbuf[4096];
+    char *ddata=NULL,dbuf[4096];
+    PyObject *result;
+
+    check_bsddbobject_open(dp, NULL);
+    krec.data = 0;
+    krec.size = 0;
+
+    BSDDB_BGN_SAVE(dp)
+    status = (dp->di_bsddb->seq)(dp->di_bsddb, &krec,
+                                 &drec, sequence_request);
+    if (status == 0) {
+        if (krec.size > sizeof(kbuf)) kdata = malloc(krec.size);
+        else kdata = kbuf;
+        if (kdata != NULL) memcpy(kdata,krec.data,krec.size);
+        if (drec.size > sizeof(dbuf)) ddata = malloc(drec.size);
+        else ddata = dbuf;
+        if (ddata != NULL) memcpy(ddata,drec.data,drec.size);
+    }
+    BSDDB_END_SAVE(dp)
+    if (status == 0) {
+        if ((kdata == NULL) || (ddata == NULL))
+            return PyErr_NoMemory();
+    }
+    else {
+        /* (status != 0) */
+        if (status < 0)
+            PyErr_SetFromErrno(BsddbError);
+        else
+            PyErr_SetString(PyExc_KeyError, "no key/data pairs");
+        return NULL;
+    }
+
+    if (dp->di_type == DB_RECNO)
+        result = Py_BuildValue("is#", *((int*)kdata),
+                               ddata, drec.size);
+    else
+        result = Py_BuildValue("s#s#", kdata, krec.size,
+                               ddata, drec.size);
+    if (kdata != kbuf) free(kdata);
+    if (ddata != dbuf) free(ddata);
+    return result;
 }
 
 static PyObject *
 bsddb_next(bsddbobject *dp)
 {
-	return bsddb_seq(dp, R_NEXT);
+    return bsddb_seq(dp, R_NEXT);
 }
 static PyObject *
 bsddb_previous(bsddbobject *dp)
 {
-	return bsddb_seq(dp, R_PREV);
+    return bsddb_seq(dp, R_PREV);
 }
 static PyObject *
 bsddb_first(bsddbobject *dp)
 {
-	return bsddb_seq(dp, R_FIRST);
+    return bsddb_seq(dp, R_FIRST);
 }
 static PyObject *
 bsddb_last(bsddbobject *dp)
 {
-	return bsddb_seq(dp, R_LAST);
+    return bsddb_seq(dp, R_LAST);
 }
 static PyObject *
 bsddb_sync(bsddbobject *dp)
 {
-	int status;
-
-	check_bsddbobject_open(dp, NULL);
-	BSDDB_BGN_SAVE(dp)
-	status = (dp->di_bsddb->sync)(dp->di_bsddb, 0);
-	BSDDB_END_SAVE(dp)
-	if (status != 0) {
-		PyErr_SetFromErrno(BsddbError);
-		return NULL;
-	}
-	return PyInt_FromLong(status = 0);
+    int status;
+
+    check_bsddbobject_open(dp, NULL);
+    BSDDB_BGN_SAVE(dp)
+    status = (dp->di_bsddb->sync)(dp->di_bsddb, 0);
+    BSDDB_END_SAVE(dp)
+    if (status != 0) {
+        PyErr_SetFromErrno(BsddbError);
+        return NULL;
+    }
+    return PyInt_FromLong(status = 0);
 }
 static PyMethodDef bsddb_methods[] = {
-	{"close",		(PyCFunction)bsddb_close, METH_NOARGS},
-	{"keys",		(PyCFunction)bsddb_keys, METH_NOARGS},
-	{"has_key",		(PyCFunction)bsddb_has_key, METH_VARARGS},
-	{"set_location",	(PyCFunction)bsddb_set_location, METH_VARARGS},
-	{"next",		(PyCFunction)bsddb_next, METH_NOARGS},
-	{"previous",	(PyCFunction)bsddb_previous, METH_NOARGS},
-	{"first",		(PyCFunction)bsddb_first, METH_NOARGS},
-	{"last",		(PyCFunction)bsddb_last, METH_NOARGS},
-	{"sync",		(PyCFunction)bsddb_sync, METH_NOARGS},
-	{NULL,	       	NULL}		/* sentinel */
+    {"close",                   (PyCFunction)bsddb_close, METH_NOARGS},
+    {"keys",                    (PyCFunction)bsddb_keys, METH_NOARGS},
+    {"has_key",                 (PyCFunction)bsddb_has_key, METH_VARARGS},
+    {"set_location",            (PyCFunction)bsddb_set_location, METH_VARARGS},
+    {"next",                    (PyCFunction)bsddb_next, METH_NOARGS},
+    {"previous",        (PyCFunction)bsddb_previous, METH_NOARGS},
+    {"first",                   (PyCFunction)bsddb_first, METH_NOARGS},
+    {"last",                    (PyCFunction)bsddb_last, METH_NOARGS},
+    {"sync",                    (PyCFunction)bsddb_sync, METH_NOARGS},
+    {NULL,              NULL}           /* sentinel */
 };
 
 static PyObject *
 bsddb_getattr(PyObject *dp, char *name)
 {
-	return Py_FindMethod(bsddb_methods, dp, name);
+    return Py_FindMethod(bsddb_methods, dp, name);
 }
 
 static PyTypeObject Bsddbtype = {
-	PyObject_HEAD_INIT(NULL)
-	0,
-	"bsddb.bsddb",
-	sizeof(bsddbobject),
-	0,
-	(destructor)bsddb_dealloc, /*tp_dealloc*/
-	0,			/*tp_print*/
-	(getattrfunc)bsddb_getattr, /*tp_getattr*/
-	0,			/*tp_setattr*/
-	0,			/*tp_compare*/
-	0,			/*tp_repr*/
-	0,			/*tp_as_number*/
-	0,			/*tp_as_sequence*/
-	&bsddb_as_mapping,	/*tp_as_mapping*/
+    PyObject_HEAD_INIT(NULL)
+    0,
+    "bsddb.bsddb",
+    sizeof(bsddbobject),
+    0,
+    (destructor)bsddb_dealloc, /*tp_dealloc*/
+    0,                          /*tp_print*/
+    (getattrfunc)bsddb_getattr, /*tp_getattr*/
+    0,                          /*tp_setattr*/
+    0,                          /*tp_compare*/
+    0,                          /*tp_repr*/
+    0,                          /*tp_as_number*/
+    0,                          /*tp_as_sequence*/
+    &bsddb_as_mapping,          /*tp_as_mapping*/
 };
 
 static PyObject *
 bsdhashopen(PyObject *self, PyObject *args)
 {
-	char *file;
-	char *flag = NULL;
-	int flags = O_RDONLY;
-	int mode = 0666;
-	int bsize = 0;
-	int ffactor = 0;
-	int nelem = 0;
-	int cachesize = 0;
-	int hash = 0; /* XXX currently ignored */
-	int lorder = 0;
-
-	if (!PyArg_ParseTuple(args, "z|siiiiiii:hashopen",
-			      &file, &flag, &mode,
-			      &bsize, &ffactor, &nelem, &cachesize,
-			      &hash, &lorder))
-		return NULL;
-	if (flag != NULL) {
-		/* XXX need to pass O_EXCL, O_EXLOCK, O_NONBLOCK, O_SHLOCK */
-		if (flag[0] == 'r')
-			flags = O_RDONLY;
-		else if (flag[0] == 'w')
-			flags = O_RDWR;
-		else if (flag[0] == 'c')
-			flags = O_RDWR|O_CREAT;
-		else if (flag[0] == 'n')
-			flags = O_RDWR|O_CREAT|O_TRUNC;
-		else {
-			PyErr_SetString(BsddbError,
-				"Flag should begin with 'r', 'w', 'c' or 'n'");
-			return NULL;
-		}
-		if (flag[1] == 'l') {
+    char *file;
+    char *flag = NULL;
+    int flags = O_RDONLY;
+    int mode = 0666;
+    int bsize = 0;
+    int ffactor = 0;
+    int nelem = 0;
+    int cachesize = 0;
+    int hash = 0; /* XXX currently ignored */
+    int lorder = 0;
+
+    if (!PyArg_ParseTuple(args, "z|siiiiiii:hashopen",
+                          &file, &flag, &mode,
+                          &bsize, &ffactor, &nelem, &cachesize,
+                          &hash, &lorder))
+        return NULL;
+    if (flag != NULL) {
+        /* XXX need to pass O_EXCL, O_EXLOCK, O_NONBLOCK, O_SHLOCK */
+        if (flag[0] == 'r')
+            flags = O_RDONLY;
+        else if (flag[0] == 'w')
+            flags = O_RDWR;
+        else if (flag[0] == 'c')
+            flags = O_RDWR|O_CREAT;
+        else if (flag[0] == 'n')
+            flags = O_RDWR|O_CREAT|O_TRUNC;
+        else {
+            PyErr_SetString(BsddbError,
+                "Flag should begin with 'r', 'w', 'c' or 'n'");
+            return NULL;
+        }
+        if (flag[1] == 'l') {
 #if defined(O_EXLOCK) && defined(O_SHLOCK)
-			if (flag[0] == 'r')
-				flags |= O_SHLOCK;
-			else
-				flags |= O_EXLOCK;
+            if (flag[0] == 'r')
+                flags |= O_SHLOCK;
+            else
+                flags |= O_EXLOCK;
 #else
-			PyErr_SetString(BsddbError,
-				     "locking not supported on this platform");
-			return NULL;
+            PyErr_SetString(BsddbError,
+                         "locking not supported on this platform");
+            return NULL;
 #endif
-		}
-	}
-	return newdbhashobject(file, flags, mode,
-			       bsize, ffactor, nelem, cachesize, hash, lorder);
+        }
+    }
+    return newdbhashobject(file, flags, mode,
+                           bsize, ffactor, nelem, cachesize, hash, lorder);
 }
 
 static PyObject *
 bsdbtopen(PyObject *self, PyObject *args)
 {
-	char *file;
-	char *flag = NULL;
-	int flags = O_RDONLY;
-	int mode = 0666;
-	int cachesize = 0;
-	int maxkeypage = 0;
-	int minkeypage = 0;
-	int btflags = 0;
-	unsigned int psize = 0;
-	int lorder = 0;
-
-	if (!PyArg_ParseTuple(args, "z|siiiiiii:btopen",
-			      &file, &flag, &mode,
-			      &btflags, &cachesize, &maxkeypage, &minkeypage,
-			      &psize, &lorder))
-		return NULL;
-	if (flag != NULL) {
-		/* XXX need to pass O_EXCL, O_EXLOCK, O_NONBLOCK, O_SHLOCK */
-		if (flag[0] == 'r')
-			flags = O_RDONLY;
-		else if (flag[0] == 'w')
-			flags = O_RDWR;
-		else if (flag[0] == 'c')
-			flags = O_RDWR|O_CREAT;
-		else if (flag[0] == 'n')
-			flags = O_RDWR|O_CREAT|O_TRUNC;
-		else {
-			PyErr_SetString(BsddbError,
-			       "Flag should begin with 'r', 'w', 'c' or 'n'");
-			return NULL;
-		}
-		if (flag[1] == 'l') {
+    char *file;
+    char *flag = NULL;
+    int flags = O_RDONLY;
+    int mode = 0666;
+    int cachesize = 0;
+    int maxkeypage = 0;
+    int minkeypage = 0;
+    int btflags = 0;
+    unsigned int psize = 0;
+    int lorder = 0;
+
+    if (!PyArg_ParseTuple(args, "z|siiiiiii:btopen",
+                          &file, &flag, &mode,
+                          &btflags, &cachesize, &maxkeypage, &minkeypage,
+                          &psize, &lorder))
+        return NULL;
+    if (flag != NULL) {
+        /* XXX need to pass O_EXCL, O_EXLOCK, O_NONBLOCK, O_SHLOCK */
+        if (flag[0] == 'r')
+            flags = O_RDONLY;
+        else if (flag[0] == 'w')
+            flags = O_RDWR;
+        else if (flag[0] == 'c')
+            flags = O_RDWR|O_CREAT;
+        else if (flag[0] == 'n')
+            flags = O_RDWR|O_CREAT|O_TRUNC;
+        else {
+            PyErr_SetString(BsddbError,
+                   "Flag should begin with 'r', 'w', 'c' or 'n'");
+            return NULL;
+        }
+        if (flag[1] == 'l') {
 #if defined(O_EXLOCK) && defined(O_SHLOCK)
-			if (flag[0] == 'r')
-				flags |= O_SHLOCK;
-			else
-				flags |= O_EXLOCK;
+            if (flag[0] == 'r')
+                flags |= O_SHLOCK;
+            else
+                flags |= O_EXLOCK;
 #else
-			PyErr_SetString(BsddbError,
-				    "locking not supported on this platform");
-			return NULL;
+            PyErr_SetString(BsddbError,
+                        "locking not supported on this platform");
+            return NULL;
 #endif
-		}
-	}
-	return newdbbtobject(file, flags, mode,
-			     btflags, cachesize, maxkeypage, minkeypage,
-			     psize, lorder);
+        }
+    }
+    return newdbbtobject(file, flags, mode,
+                         btflags, cachesize, maxkeypage, minkeypage,
+                         psize, lorder);
 }
 
 static PyObject *
 bsdrnopen(PyObject *self, PyObject *args)
 {
-	char *file;
-	char *flag = NULL;
-	int flags = O_RDONLY;
-	int mode = 0666;
-	int cachesize = 0;
-	int rnflags = 0;
-	unsigned int psize = 0;
-	int lorder = 0;
-	size_t reclen = 0;
-	char  *bval = "";
-	char *bfname = NULL;
-
-	if (!PyArg_ParseTuple(args, "z|siiiiiiss:rnopen",
-			      &file, &flag, &mode,
-			      &rnflags, &cachesize, &psize, &lorder,
-			      &reclen, &bval, &bfname))
-		return NULL;
-
-	if (flag != NULL) {
-		/* XXX need to pass O_EXCL, O_EXLOCK, O_NONBLOCK, O_SHLOCK */
-		if (flag[0] == 'r')
-			flags = O_RDONLY;
-		else if (flag[0] == 'w')
-			flags = O_RDWR;
-		else if (flag[0] == 'c')
-			flags = O_RDWR|O_CREAT;
-		else if (flag[0] == 'n')
-			flags = O_RDWR|O_CREAT|O_TRUNC;
-		else {
-			PyErr_SetString(BsddbError,
-			       "Flag should begin with 'r', 'w', 'c' or 'n'");
-			return NULL;
-		}
-		if (flag[1] == 'l') {
+    char *file;
+    char *flag = NULL;
+    int flags = O_RDONLY;
+    int mode = 0666;
+    int cachesize = 0;
+    int rnflags = 0;
+    unsigned int psize = 0;
+    int lorder = 0;
+    size_t reclen = 0;
+    char  *bval = "";
+    char *bfname = NULL;
+
+    if (!PyArg_ParseTuple(args, "z|siiiiiiss:rnopen",
+                          &file, &flag, &mode,
+                          &rnflags, &cachesize, &psize, &lorder,
+                          &reclen, &bval, &bfname))
+        return NULL;
+
+    if (flag != NULL) {
+        /* XXX need to pass O_EXCL, O_EXLOCK, O_NONBLOCK, O_SHLOCK */
+        if (flag[0] == 'r')
+            flags = O_RDONLY;
+        else if (flag[0] == 'w')
+            flags = O_RDWR;
+        else if (flag[0] == 'c')
+            flags = O_RDWR|O_CREAT;
+        else if (flag[0] == 'n')
+            flags = O_RDWR|O_CREAT|O_TRUNC;
+        else {
+            PyErr_SetString(BsddbError,
+                   "Flag should begin with 'r', 'w', 'c' or 'n'");
+            return NULL;
+        }
+        if (flag[1] == 'l') {
 #if defined(O_EXLOCK) && defined(O_SHLOCK)
-			if (flag[0] == 'r')
-				flags |= O_SHLOCK;
-			else
-				flags |= O_EXLOCK;
+            if (flag[0] == 'r')
+                flags |= O_SHLOCK;
+            else
+                flags |= O_EXLOCK;
 #else
-			PyErr_SetString(BsddbError,
-				    "locking not supported on this platform");
-			return NULL;
+            PyErr_SetString(BsddbError,
+                        "locking not supported on this platform");
+            return NULL;
 #endif
-		}
-		else if (flag[1] != '\0') {
-			PyErr_SetString(BsddbError,
-				       "Flag char 2 should be 'l' or absent");
-			return NULL;
-		}
-	}
-	return newdbrnobject(file, flags, mode, rnflags, cachesize,
-			     psize, lorder, reclen, bval[0], bfname);
+        }
+        else if (flag[1] != '\0') {
+            PyErr_SetString(BsddbError,
+                           "Flag char 2 should be 'l' or absent");
+            return NULL;
+        }
+    }
+    return newdbrnobject(file, flags, mode, rnflags, cachesize,
+                         psize, lorder, reclen, bval[0], bfname);
 }
 
 static PyMethodDef bsddbmodule_methods[] = {
-	{"hashopen",	(PyCFunction)bsdhashopen, METH_VARARGS},
-	{"btopen",	(PyCFunction)bsdbtopen, METH_VARARGS},
-	{"rnopen",	(PyCFunction)bsdrnopen, METH_VARARGS},
-	/* strictly for use by dbhhash!!! */
-	{"open",	(PyCFunction)bsdhashopen, METH_VARARGS},
-	{0,		0},
+    {"hashopen",        (PyCFunction)bsdhashopen, METH_VARARGS},
+    {"btopen",          (PyCFunction)bsdbtopen, METH_VARARGS},
+    {"rnopen",          (PyCFunction)bsdrnopen, METH_VARARGS},
+    /* strictly for use by dbhhash!!! */
+    {"open",            (PyCFunction)bsdhashopen, METH_VARARGS},
+    {0,                 0},
 };
 
 PyMODINIT_FUNC
 initbsddb185(void) {
-	PyObject *m, *d;
-
-	Bsddbtype.ob_type = &PyType_Type;
-	m = Py_InitModule("bsddb185", bsddbmodule_methods);
-	if (m == NULL)
-		return;
-	d = PyModule_GetDict(m);
-	BsddbError = PyErr_NewException("bsddb.error", NULL, NULL);
-	if (BsddbError != NULL)
-		PyDict_SetItemString(d, "error", BsddbError);
+    PyObject *m, *d;
+
+    if (PyErr_WarnPy3k("the bsddb185 module has been removed in "
+                       "Python 3.0", 2) < 0)
+    return;
+
+    Bsddbtype.ob_type = &PyType_Type;
+    m = Py_InitModule("bsddb185", bsddbmodule_methods);
+    if (m == NULL)
+        return;
+    d = PyModule_GetDict(m);
+    BsddbError = PyErr_NewException("bsddb.error", NULL, NULL);
+    if (BsddbError != NULL)
+        PyDict_SetItemString(d, "error", BsddbError);
 }
-- 
1.7.1

